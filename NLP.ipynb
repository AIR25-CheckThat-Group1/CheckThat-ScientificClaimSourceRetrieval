{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d406c3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gokayyil/checkthatenv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#Necessary imports\n",
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import re\n",
    "import torch\n",
    "from torch.nn.functional import cosine_similarity\n",
    "from torch.nn.functional import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "000cc8e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: 12853 train tweets, 1400 dev tweets, 7718 papers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2r/b056w9_x2r7_hv60_h769b180000gn/T/ipykernel_31903/4108614059.py:4: DeprecationWarning: numpy.core.numeric is deprecated and has been renamed to numpy._core.numeric. The numpy._core namespace contains private NumPy internals and its use is discouraged, as NumPy internals can change without warning in any release. In practice, most real-world usage of numpy.core is to access functionality in the public NumPy API. If that is the case, use the public NumPy API. If not, you are using NumPy internals. If you would still like to access an internal attribute, use numpy._core.numeric._frombuffer.\n",
      "  papers_df = pickle.load(f)\n"
     ]
    }
   ],
   "source": [
    "# Load train & dev queries, and paper collection\n",
    "# Load paper metadata\n",
    "with open(\"subtask4b_collection_data.pkl\", \"rb\") as f:\n",
    "    papers_df = pickle.load(f)\n",
    "\n",
    "papers_df[\"text\"] = papers_df[\"title\"] + \". \" + papers_df[\"abstract\"]\n",
    "\n",
    "# Load tweet queries\n",
    "train_df = pd.read_csv(\"subtask4b_query_tweets_train.tsv\", sep=\"\\t\")\n",
    "dev_df = pd.read_csv(\"subtask4b_query_tweets_dev.tsv\", sep=\"\\t\")\n",
    "\n",
    "print(f\"Loaded: {len(train_df)} train tweets, {len(dev_df)} dev tweets, {len(papers_df)} papers.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "173d7f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load SBERT model\n",
    "\n",
    "#model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "#model = SentenceTransformer('multi-qa-MiniLM-L6-cos-v1')\n",
    "#model = SentenceTransformer('multi-qa-MiniLM-L6-dot-v1')\n",
    "#model = SentenceTransformer('allenai/specter')\n",
    "#model = SentenceTransformer('msmarco-distilbert-base-tas-b')\n",
    "#model = SentenceTransformer(\"intfloat/e5-base-v2\")\n",
    "#model = SentenceTransformer(\"intfloat/e5-large-v2\") (way too slow and didn't work at the end)\n",
    "#“This model uses contextualized embeddings from BERT as fixed-length representations of queries and documents. \n",
    "# These representations are used for similarity-based retrieval, making this an NLP representation learning approach.”\n",
    "#--> model = SentenceTransformer('multi-qa-mpnet-base-cos-v1') # This model has been used to fine-tune and below is the path to the fine-tuned model.\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer(\"fine_tuned_gte_b16_e4\")  # change as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "afaccc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define cleaning function. This one is a bit agressive cleaning so result got worsen\n",
    "#def clean_text(text):\n",
    "#    text = text.lower()\n",
    "#    text = re.sub(r\"http\\\\S+|www\\\\S+\", \"\", text)\n",
    "#    text = re.sub(r\"[@#]\\\\w+\", \"\", text)\n",
    "#    text = re.sub(r\"[^a-z0-9\\\\s]\", \"\", text)\n",
    "#    return text.strip()\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"http\\S+|www\\S+\", \"\", text)         # remove URLs\n",
    "    text = re.sub(r\"[@#]\\w+\", \"\", text)                # remove @mentions and #hashtags\n",
    "    text = re.sub(r\"[^\\w\\s\\-\\/]\", \"\", text)            # keep alphanum + dash/slash\n",
    "    return text.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9492913f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply cleaning\n",
    "#train_df[\"clean_tweet_text\"] = train_df[\"tweet_text\"].apply(clean_text)\n",
    "#dev_df[\"clean_tweet_text\"] = dev_df[\"tweet_text\"].apply(clean_text)\n",
    "\n",
    "# Clean tweets\n",
    "dev_df[\"clean_tweet_text\"] = dev_df[\"tweet_text\"].apply(clean_text)\n",
    "train_df[\"clean_tweet_text\"] = train_df[\"tweet_text\"].apply(clean_text)\n",
    "\n",
    "# Clean papers\n",
    "papers_df[\"text\"] = papers_df[\"title\"] + \". \" + papers_df[\"abstract\"]\n",
    "papers_df[\"clean_text\"] = papers_df[\"text\"].apply(clean_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2df21db7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|████████████████████████████████| 402/402 [04:32<00:00,  1.48it/s]\n",
      "Batches: 100%|██████████████████████████████████| 44/44 [00:28<00:00,  1.54it/s]\n",
      "Batches: 100%|████████████████████████████████| 242/242 [23:25<00:00,  5.81s/it]\n"
     ]
    }
   ],
   "source": [
    "# Encode train queries\n",
    "train_query_embeddings = model.encode(\n",
    "    train_df[\"clean_tweet_text\"].tolist(),\n",
    "    convert_to_tensor=True,\n",
    "    show_progress_bar=True\n",
    ")\n",
    "\n",
    "# Encode dev queries\n",
    "dev_query_embeddings = model.encode(\n",
    "    dev_df[\"clean_tweet_text\"].tolist(),\n",
    "    convert_to_tensor=True,\n",
    "    show_progress_bar=True\n",
    ")\n",
    "\n",
    "# Encode papers (passages)\n",
    "paper_embeddings = model.encode(\n",
    "    papers_df[\"clean_text\"].tolist(),\n",
    "    convert_to_tensor=True,\n",
    "    show_progress_bar=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7e99bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode document collection\n",
    "paper_embeddings = model.encode(papers_df[\"text\"].tolist(), show_progress_bar=True, convert_to_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "212d152b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save paper embeddings to avoid recomputing in future runs\n",
    "#torch.save(paper_embeddings, \"paper_embeddings.pt\")\n",
    "\n",
    "# To load later:\n",
    "paper_embeddings = torch.load(\"paper_embeddings.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1187206f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topk_predictions_batched(query_embeddings, paper_embeddings, papers_df, top_k=5, batch_size=16):\n",
    "    paper_norm = normalize(paper_embeddings, p=2, dim=1)\n",
    "    paper_ids = papers_df[\"cord_uid\"].tolist()  # store once for speed\n",
    "    predictions = []\n",
    "\n",
    "    for start_idx in range(0, len(query_embeddings), batch_size):\n",
    "        end_idx = min(start_idx + batch_size, len(query_embeddings))\n",
    "        query_batch = query_embeddings[start_idx:end_idx]\n",
    "        query_norm = normalize(query_batch, p=2, dim=1)\n",
    "\n",
    "        # 🔧 Fix device mismatch\n",
    "        paper_norm_device = paper_norm.to(query_norm.device)\n",
    "\n",
    "        similarity_matrix = torch.matmul(query_norm, paper_norm_device.T)\n",
    "        top_k_indices = similarity_matrix.topk(k=top_k, dim=1).indices  # shape: [batch_size, top_k]\n",
    "\n",
    "        for indices in top_k_indices:\n",
    "            preds = [paper_ids[i] for i in indices.tolist()]\n",
    "            predictions.append(preds)\n",
    "\n",
    "    return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cf5283e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run predictions default\n",
    "#train_df[\"preds\"] = get_topk_predictions_from_embeddings(train_query_embeddings)\n",
    "#dev_df[\"preds\"] = get_topk_predictions_from_embeddings(dev_query_embeddings)\n",
    "\n",
    "train_df[\"preds\"] = get_topk_predictions_batched(train_query_embeddings, paper_embeddings, papers_df, top_k=5)\n",
    "dev_df[\"preds\"] = get_topk_predictions_batched(dev_query_embeddings, paper_embeddings, papers_df, top_k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65895ac7",
   "metadata": {},
   "source": [
    "Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cdfc21a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate MRR\n",
    "def get_performance_mrr(data, col_gold, col_pred, list_k=[1, 5, 10]):\n",
    "    d_performance = {}\n",
    "    for k in list_k:\n",
    "        scores = []\n",
    "        for _, row in data.iterrows():\n",
    "            gold = row[col_gold]\n",
    "            preds = row[col_pred]\n",
    "            if isinstance(preds, str):\n",
    "                try:\n",
    "                    preds = eval(preds)\n",
    "                except:\n",
    "                    preds = []\n",
    "            if gold in preds[:k]:\n",
    "                rank = preds[:k].index(gold) + 1\n",
    "                scores.append(1.0 / rank)\n",
    "            else:\n",
    "                scores.append(0.0)\n",
    "        d_performance[k] = sum(scores) / len(scores) if scores else 0.0\n",
    "    return d_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "34876725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train MRR: {1: 7.780284758422158e-05, 5: 0.00024248554163749058, 10: 0.00024248554163749058}\n",
      "Dev MRR: {1: 0.0, 5: 0.0, 10: 0.0}\n"
     ]
    }
   ],
   "source": [
    "# Print results default\n",
    "print(\"Train MRR:\", get_performance_mrr(train_df, \"cord_uid\", \"preds\"))\n",
    "print(\"Dev MRR:\", get_performance_mrr(dev_df, \"cord_uid\", \"preds\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11d3bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predictions to TSV file\n",
    "with open(\"predictions.tsv\", \"w\", newline='') as f:\n",
    "    writer = csv.writer(f, delimiter=\"\\t\")\n",
    "    writer.writerow([\"post_id\", \"preds\"]) \n",
    "\n",
    "    for _, row in dev_df.iterrows():\n",
    "        post_id = row[\"post_id\"]\n",
    "        preds = str(row[\"preds\"])\n",
    "        writer.writerow([post_id, preds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ac80ff-d39f-409c-ab36-9f18b90ab17a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a018de1a-a6c8-4ad5-8693-b8b73c3919e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
