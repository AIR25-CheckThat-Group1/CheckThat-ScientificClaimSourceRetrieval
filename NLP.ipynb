{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d406c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Necessary imports\n",
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import re\n",
    "import torch\n",
    "from torch.nn.functional import cosine_similarity\n",
    "from torch.nn.functional import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000cc8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load train & dev queries, and paper collection\n",
    "# Load paper metadata\n",
    "with open(\"subtask4b_collection_data.pkl\", \"rb\") as f:\n",
    "    papers_df = pickle.load(f)\n",
    "\n",
    "papers_df[\"text\"] = papers_df[\"title\"] + \". \" + papers_df[\"abstract\"]\n",
    "\n",
    "# Load tweet queries\n",
    "train_df = pd.read_csv(\"subtask4b_query_tweets_train.tsv\", sep=\"\\t\")\n",
    "dev_df = pd.read_csv(\"subtask4b_query_tweets_dev.tsv\", sep=\"\\t\")\n",
    "\n",
    "print(f\"Loaded: {len(train_df)} train tweets, {len(dev_df)} dev tweets, {len(papers_df)} papers.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173d7f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load SBERT model\n",
    "\n",
    "#model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "#model = SentenceTransformer('multi-qa-MiniLM-L6-cos-v1')\n",
    "#model = SentenceTransformer('multi-qa-MiniLM-L6-dot-v1')\n",
    "#model = SentenceTransformer('allenai/specter')\n",
    "#model = SentenceTransformer('msmarco-distilbert-base-tas-b')\n",
    "\n",
    "#“This model uses contextualized embeddings from BERT as fixed-length representations of queries and documents. \n",
    "# These representations are used for similarity-based retrieval, making this an NLP representation learning approach.”\n",
    "#--> model = SentenceTransformer('multi-qa-mpnet-base-cos-v1') # This model has been used to fine-tune and below is the path to the fine-tuned model.\n",
    "\n",
    "# Load the fine-tuned model\n",
    "model = SentenceTransformer(\"multi-qa-mpnet-base-cos-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afaccc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub(r\"http\\S+\", \"\", text)  # Remove URLs\n",
    "    text = re.sub(r\"@\\w+\", \"\", text)     # Remove mentions\n",
    "    text = re.sub(r\"#\\w+\", \"\", text)     # Remove hashtags\n",
    "    text = re.sub(r\"\\s+\", \" \", text)     # Normalize whitespace\n",
    "    return text.strip()\n",
    "\n",
    "dev_df[\"clean_tweet_text\"] = dev_df[\"tweet_text\"].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b855df59",
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_embeddings = torch.load(\"paper_embeddings.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9492913f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_query_embeddings = model.encode(\n",
    "    dev_df[\"clean_tweet_text\"].tolist(),\n",
    "    show_progress_bar=True,\n",
    "    convert_to_tensor=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df21db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import cosine_similarity\n",
    "\n",
    "# Ensure tensors are on the same device\n",
    "dev_query_embeddings = dev_query_embeddings.to(\"cpu\")\n",
    "paper_embeddings = paper_embeddings.to(\"cpu\")\n",
    "\n",
    "# Compute cosine similarities: shape = [#queries, #papers]\n",
    "similarity_scores = cosine_similarity(\n",
    "    dev_query_embeddings.unsqueeze(1),  # shape: [Q, 1, D]\n",
    "    paper_embeddings.unsqueeze(0)       # shape: [1, P, D]\n",
    ")\n",
    "\n",
    "# Get top 5 similar papers for each dev query\n",
    "top_k = torch.topk(similarity_scores, k=5, dim=1)\n",
    "top_k_indices = top_k.indices  # indices of top papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7e99bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):  # check first 3 tweets\n",
    "    tweet_id = dev_df.loc[i, \"post_id\"]\n",
    "    tweet_text = dev_df.loc[i, \"tweet_text\"]\n",
    "    top_paper_ids = [papers_df.iloc[pid.item()][\"cord_uid\"] for pid in top_k_indices[i]]\n",
    "    \n",
    "    print(f\"\\nTweet {i+1} — ID: {tweet_id}\")\n",
    "    print(\"Tweet:\", tweet_text)\n",
    "    print(\"Top 5 paper IDs:\", top_paper_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212d152b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_reciprocal_rank_at_k(topk_indices, ground_truth_ids, paper_df, k=5):\n",
    "    ranks = []\n",
    "    for i, topk in enumerate(topk_indices):\n",
    "        true_pid = ground_truth_ids[i]\n",
    "        topk_cord_uids = [paper_df.iloc[pid.item()][\"cord_uid\"] for pid in topk[:k]]\n",
    "        \n",
    "        try:\n",
    "            rank = topk_cord_uids.index(true_pid) + 1  # ranks are 1-based\n",
    "            reciprocal_rank = 1.0 / rank\n",
    "        except ValueError:\n",
    "            reciprocal_rank = 0.0  # true document not in top-k\n",
    "\n",
    "        ranks.append(reciprocal_rank)\n",
    "\n",
    "    return sum(ranks) / len(ranks)\n",
    "\n",
    "# Evaluate\n",
    "mrr5 = mean_reciprocal_rank_at_k(top_k_indices, dev_df[\"cord_uid\"].tolist(), papers_df, k=5)\n",
    "print(f\"📊 MRR@5 on dev set: {mrr5:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1187206f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#default\n",
    "#def get_topk_predictions_from_embeddings(query_embeddings, top_k=5):\n",
    "#    results = []\n",
    "#    for query_emb in query_embeddings:\n",
    "#        cos_scores = cosine_similarity(query_emb.unsqueeze(0), paper_embeddings).squeeze()\n",
    "#        top_indices = torch.topk(cos_scores, k=min(top_k, len(paper_embeddings))).indices.tolist()\n",
    "#        top_cord_uids = papers_df.iloc[top_indices][\"cord_uid\"].tolist()\n",
    "#        results.append(top_cord_uids)\n",
    "#    return results\n",
    "\n",
    "# Batched version\n",
    "def get_topk_predictions_batched(query_embeddings, paper_embeddings, papers_df, top_k=5, batch_size=16):\n",
    "    paper_norm = normalize(paper_embeddings, p=2, dim=1)\n",
    "    paper_ids = papers_df[\"cord_uid\"].tolist()  # store once for speed\n",
    "    predictions = []\n",
    "\n",
    "    for start_idx in range(0, len(query_embeddings), batch_size):\n",
    "        end_idx = min(start_idx + batch_size, len(query_embeddings))\n",
    "        query_batch = query_embeddings[start_idx:end_idx]\n",
    "        query_norm = normalize(query_batch, p=2, dim=1)\n",
    "\n",
    "        similarity_matrix = torch.matmul(query_norm, paper_norm.T)\n",
    "        top_k_indices = similarity_matrix.topk(k=top_k, dim=1).indices  # shape: [batch_size, top_k]\n",
    "\n",
    "        for indices in top_k_indices:\n",
    "            preds = [paper_ids[i] for i in indices.tolist()]\n",
    "            predictions.append(preds)\n",
    "\n",
    "    return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5283e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run predictions default\n",
    "#train_df[\"preds\"] = get_topk_predictions_from_embeddings(train_query_embeddings)\n",
    "#dev_df[\"preds\"] = get_topk_predictions_from_embeddings(dev_query_embeddings)\n",
    "\n",
    "train_df[\"preds\"] = get_topk_predictions_batched(train_query_embeddings, paper_embeddings, papers_df, top_k=5)\n",
    "dev_df[\"preds\"] = get_topk_predictions_batched(dev_query_embeddings, paper_embeddings, papers_df, top_k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65895ac7",
   "metadata": {},
   "source": [
    "Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdfc21a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate MRR\n",
    "def get_performance_mrr(data, col_gold, col_pred, list_k=[1, 5, 10]):\n",
    "    d_performance = {}\n",
    "    for k in list_k:\n",
    "        scores = []\n",
    "        for _, row in data.iterrows():\n",
    "            gold = row[col_gold]\n",
    "            preds = row[col_pred]\n",
    "            if isinstance(preds, str):\n",
    "                try:\n",
    "                    preds = eval(preds)\n",
    "                except:\n",
    "                    preds = []\n",
    "            if gold in preds[:k]:\n",
    "                rank = preds[:k].index(gold) + 1\n",
    "                scores.append(1.0 / rank)\n",
    "            else:\n",
    "                scores.append(0.0)\n",
    "        d_performance[k] = sum(scores) / len(scores) if scores else 0.0\n",
    "    return d_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34876725",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print results default\n",
    "print(\"Train MRR:\", get_performance_mrr(train_df, \"cord_uid\", \"preds\"))\n",
    "print(\"Dev MRR:\", get_performance_mrr(dev_df, \"cord_uid\", \"preds\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11d3bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predictions to TSV file\n",
    "with open(\"predictions.tsv\", \"w\", newline='') as f:\n",
    "    writer = csv.writer(f, delimiter=\"\\t\")\n",
    "    writer.writerow([\"post_id\", \"preds\"]) \n",
    "\n",
    "    for _, row in dev_df.iterrows():\n",
    "        post_id = row[\"post_id\"]\n",
    "        preds = str(row[\"preds\"])\n",
    "        writer.writerow([post_id, preds])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
