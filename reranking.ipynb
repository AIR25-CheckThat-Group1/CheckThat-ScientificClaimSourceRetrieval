{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58e2003b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vscode/.local/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import bm25s\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from tqdm import tqdm\n",
    "from mxbai_rerank import MxbaiRerankV2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9384a35a",
   "metadata": {},
   "source": [
    "# Neural Reranking\n",
    "This notebooks houses our finetuning and evaluation code for the neural reranking approach. A diverse set of pretrained reranker models were tested, including Alibabaâ€™s gte-reranker-modernbert-base, multilingual versions, and others like Electra and MiniLM. This diversity allowed us to investigate which architectures and training schemes work best for our target dataset. We also investigated how an ensemble of these models perform in reranking_ensemble.ipynb.\n",
    "\n",
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d91b9f90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce RTX 2070'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28ddfe89",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path('data/')\n",
    "\n",
    "collection_data_path = data_path / 'subtask4b_collection_data.pkl' \n",
    "query_dev_data_path = data_path / 'subtask4b_query_tweets_dev.tsv'\n",
    "query_train_data_path = data_path / 'subtask4b_query_tweets_train.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6cfb2779",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cord_uid</th>\n",
       "      <th>source_x</th>\n",
       "      <th>title</th>\n",
       "      <th>doi</th>\n",
       "      <th>pmcid</th>\n",
       "      <th>pubmed_id</th>\n",
       "      <th>license</th>\n",
       "      <th>abstract</th>\n",
       "      <th>publish_time</th>\n",
       "      <th>authors</th>\n",
       "      <th>journal</th>\n",
       "      <th>mag_id</th>\n",
       "      <th>who_covidence_id</th>\n",
       "      <th>arxiv_id</th>\n",
       "      <th>label</th>\n",
       "      <th>time</th>\n",
       "      <th>timet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>umvrwgaw</td>\n",
       "      <td>PMC</td>\n",
       "      <td>Professional and Home-Made Face Masks Reduce E...</td>\n",
       "      <td>10.1371/journal.pone.0002618</td>\n",
       "      <td>PMC2440799</td>\n",
       "      <td>18612429</td>\n",
       "      <td>cc-by</td>\n",
       "      <td>BACKGROUND: Governments are preparing for a po...</td>\n",
       "      <td>2008-07-09</td>\n",
       "      <td>van der Sande, Marianne; Teunis, Peter; Sabel,...</td>\n",
       "      <td>PLoS One</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>umvrwgaw</td>\n",
       "      <td>2008-07-09</td>\n",
       "      <td>1215561600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611</th>\n",
       "      <td>spiud6ok</td>\n",
       "      <td>PMC</td>\n",
       "      <td>The Failure of R (0)</td>\n",
       "      <td>10.1155/2011/527610</td>\n",
       "      <td>PMC3157160</td>\n",
       "      <td>21860658</td>\n",
       "      <td>cc-by</td>\n",
       "      <td>The basic reproductive ratio, R (0), is one of...</td>\n",
       "      <td>2011-08-16</td>\n",
       "      <td>Li, Jing; Blakeley, Daniel; Smith?, Robert J.</td>\n",
       "      <td>Comput Math Methods Med</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>spiud6ok</td>\n",
       "      <td>2011-08-16</td>\n",
       "      <td>1313452800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>918</th>\n",
       "      <td>aclzp3iy</td>\n",
       "      <td>PMC</td>\n",
       "      <td>Pulmonary sequelae in a patient recovered from...</td>\n",
       "      <td>10.4103/0970-2113.99118</td>\n",
       "      <td>PMC3424870</td>\n",
       "      <td>22919170</td>\n",
       "      <td>cc-by-nc-sa</td>\n",
       "      <td>The pandemic of swine flu (H1N1) influenza spr...</td>\n",
       "      <td>2012</td>\n",
       "      <td>Singh, Virendra; Sharma, Bharat Bhushan; Patel...</td>\n",
       "      <td>Lung India</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>aclzp3iy</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>1325376000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>ycxyn2a2</td>\n",
       "      <td>PMC</td>\n",
       "      <td>What was the primary mode of smallpox transmis...</td>\n",
       "      <td>10.3389/fcimb.2012.00150</td>\n",
       "      <td>PMC3509329</td>\n",
       "      <td>23226686</td>\n",
       "      <td>cc-by</td>\n",
       "      <td>The mode of infection transmission has profoun...</td>\n",
       "      <td>2012-11-29</td>\n",
       "      <td>Milton, Donald K.</td>\n",
       "      <td>Front Cell Infect Microbiol</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ycxyn2a2</td>\n",
       "      <td>2012-11-29</td>\n",
       "      <td>1354147200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1053</th>\n",
       "      <td>zxe95qy9</td>\n",
       "      <td>PMC</td>\n",
       "      <td>Lessons from the History of Quarantine, from P...</td>\n",
       "      <td>10.3201/eid1902.120312</td>\n",
       "      <td>PMC3559034</td>\n",
       "      <td>23343512</td>\n",
       "      <td>no-cc</td>\n",
       "      <td>In the new millennium, the centuries-old strat...</td>\n",
       "      <td>2013-02-03</td>\n",
       "      <td>Tognotti, Eugenia</td>\n",
       "      <td>Emerg Infect Dis</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>zxe95qy9</td>\n",
       "      <td>2013-02-03</td>\n",
       "      <td>1359849600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      cord_uid source_x                                              title  \\\n",
       "162   umvrwgaw      PMC  Professional and Home-Made Face Masks Reduce E...   \n",
       "611   spiud6ok      PMC                               The Failure of R (0)   \n",
       "918   aclzp3iy      PMC  Pulmonary sequelae in a patient recovered from...   \n",
       "993   ycxyn2a2      PMC  What was the primary mode of smallpox transmis...   \n",
       "1053  zxe95qy9      PMC  Lessons from the History of Quarantine, from P...   \n",
       "\n",
       "                               doi       pmcid pubmed_id      license  \\\n",
       "162   10.1371/journal.pone.0002618  PMC2440799  18612429        cc-by   \n",
       "611            10.1155/2011/527610  PMC3157160  21860658        cc-by   \n",
       "918        10.4103/0970-2113.99118  PMC3424870  22919170  cc-by-nc-sa   \n",
       "993       10.3389/fcimb.2012.00150  PMC3509329  23226686        cc-by   \n",
       "1053        10.3201/eid1902.120312  PMC3559034  23343512        no-cc   \n",
       "\n",
       "                                               abstract publish_time  \\\n",
       "162   BACKGROUND: Governments are preparing for a po...   2008-07-09   \n",
       "611   The basic reproductive ratio, R (0), is one of...   2011-08-16   \n",
       "918   The pandemic of swine flu (H1N1) influenza spr...         2012   \n",
       "993   The mode of infection transmission has profoun...   2012-11-29   \n",
       "1053  In the new millennium, the centuries-old strat...   2013-02-03   \n",
       "\n",
       "                                                authors  \\\n",
       "162   van der Sande, Marianne; Teunis, Peter; Sabel,...   \n",
       "611       Li, Jing; Blakeley, Daniel; Smith?, Robert J.   \n",
       "918   Singh, Virendra; Sharma, Bharat Bhushan; Patel...   \n",
       "993                                   Milton, Donald K.   \n",
       "1053                                  Tognotti, Eugenia   \n",
       "\n",
       "                          journal  mag_id who_covidence_id arxiv_id     label  \\\n",
       "162                      PLoS One     NaN              NaN      NaN  umvrwgaw   \n",
       "611       Comput Math Methods Med     NaN              NaN      NaN  spiud6ok   \n",
       "918                    Lung India     NaN              NaN      NaN  aclzp3iy   \n",
       "993   Front Cell Infect Microbiol     NaN              NaN      NaN  ycxyn2a2   \n",
       "1053             Emerg Infect Dis     NaN              NaN      NaN  zxe95qy9   \n",
       "\n",
       "           time       timet  \n",
       "162  2008-07-09  1215561600  \n",
       "611  2011-08-16  1313452800  \n",
       "918  2012-01-01  1325376000  \n",
       "993  2012-11-29  1354147200  \n",
       "1053 2013-02-03  1359849600  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_collection = pd.read_pickle(collection_data_path)\n",
    "df_collection.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02fe1d0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>cord_uid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16</td>\n",
       "      <td>covid recovery: this study from the usa reveal...</td>\n",
       "      <td>3qvh482o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>69</td>\n",
       "      <td>\"Among 139 clients exposed to two symptomatic ...</td>\n",
       "      <td>r58aohnu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>73</td>\n",
       "      <td>I recall early on reading that researchers who...</td>\n",
       "      <td>sts48u9i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>93</td>\n",
       "      <td>You know you're credible when NIH website has ...</td>\n",
       "      <td>3sr2exq9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>96</td>\n",
       "      <td>Resistance to antifungal medications is a grow...</td>\n",
       "      <td>ybwwmyqy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1395</th>\n",
       "      <td>14193</td>\n",
       "      <td>Residents at high risk of covid-19: effectiven...</td>\n",
       "      <td>0gn3b98n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1396</th>\n",
       "      <td>14196</td>\n",
       "      <td>61% of teenagers hospitalized for covid were \"...</td>\n",
       "      <td>25bdifv6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1397</th>\n",
       "      <td>14203</td>\n",
       "      <td>\"fresh evidence backing melatonin against covi...</td>\n",
       "      <td>qn6wawxk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1398</th>\n",
       "      <td>14233</td>\n",
       "      <td>the vaccine doesn't halt the spread, it is pro...</td>\n",
       "      <td>3u3i5myh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1399</th>\n",
       "      <td>14236</td>\n",
       "      <td>\"Great commentary from K. Carvalho,  black pre...</td>\n",
       "      <td>nih4l4ok</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1400 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      post_id                                         tweet_text  cord_uid\n",
       "0          16  covid recovery: this study from the usa reveal...  3qvh482o\n",
       "1          69  \"Among 139 clients exposed to two symptomatic ...  r58aohnu\n",
       "2          73  I recall early on reading that researchers who...  sts48u9i\n",
       "3          93  You know you're credible when NIH website has ...  3sr2exq9\n",
       "4          96  Resistance to antifungal medications is a grow...  ybwwmyqy\n",
       "...       ...                                                ...       ...\n",
       "1395    14193  Residents at high risk of covid-19: effectiven...  0gn3b98n\n",
       "1396    14196  61% of teenagers hospitalized for covid were \"...  25bdifv6\n",
       "1397    14203  \"fresh evidence backing melatonin against covi...  qn6wawxk\n",
       "1398    14233  the vaccine doesn't halt the spread, it is pro...  3u3i5myh\n",
       "1399    14236  \"Great commentary from K. Carvalho,  black pre...  nih4l4ok\n",
       "\n",
       "[1400 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>cord_uid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Oral care in rehabilitation medicine: oral vul...</td>\n",
       "      <td>htlvpvz5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>this study isn't receiving sufficient attentio...</td>\n",
       "      <td>4kfl29ul</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>thanks, xi jinping. a reminder that this study...</td>\n",
       "      <td>jtwb17u8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Taiwan - a population of 23 million has had ju...</td>\n",
       "      <td>0w9k8iy1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Obtaining a diagnosis of autism in lower incom...</td>\n",
       "      <td>tiqksd69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12848</th>\n",
       "      <td>14248</td>\n",
       "      <td>\"evidence on covid-19 reveals a growing body o...</td>\n",
       "      <td>9169o29b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12849</th>\n",
       "      <td>14249</td>\n",
       "      <td>Outdoor lighting has detrimental impacts on lo...</td>\n",
       "      <td>s2bpha8l</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12850</th>\n",
       "      <td>14250</td>\n",
       "      <td>26/ and influenza virus (and other pathogens, ...</td>\n",
       "      <td>atloc9th</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12851</th>\n",
       "      <td>14251</td>\n",
       "      <td>does it?'sars-cov-2-naÃ¯ve vaccinees had a 13.0...</td>\n",
       "      <td>t4y1ylb3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12852</th>\n",
       "      <td>14252</td>\n",
       "      <td>when \"the airway immune cells of children are ...</td>\n",
       "      <td>nlsv8bin</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12853 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       post_id                                         tweet_text  cord_uid\n",
       "0            0  Oral care in rehabilitation medicine: oral vul...  htlvpvz5\n",
       "1            1  this study isn't receiving sufficient attentio...  4kfl29ul\n",
       "2            2  thanks, xi jinping. a reminder that this study...  jtwb17u8\n",
       "3            3  Taiwan - a population of 23 million has had ju...  0w9k8iy1\n",
       "4            4  Obtaining a diagnosis of autism in lower incom...  tiqksd69\n",
       "...        ...                                                ...       ...\n",
       "12848    14248  \"evidence on covid-19 reveals a growing body o...  9169o29b\n",
       "12849    14249  Outdoor lighting has detrimental impacts on lo...  s2bpha8l\n",
       "12850    14250  26/ and influenza virus (and other pathogens, ...  atloc9th\n",
       "12851    14251  does it?'sars-cov-2-naÃ¯ve vaccinees had a 13.0...  t4y1ylb3\n",
       "12852    14252  when \"the airway immune cells of children are ...  nlsv8bin\n",
       "\n",
       "[12853 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_query_dev = pd.read_csv(query_dev_data_path, sep='\\t')\n",
    "df_query_train = pd.read_csv(query_train_data_path, sep='\\t')\n",
    "display(df_query_dev)\n",
    "display(df_query_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4391f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_query_test = pd.read_csv(data_path / 'subtask4b_query_tweets_test.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a720417a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>cord_uid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16</td>\n",
       "      <td>covid recovery: this study from the usa reveal...</td>\n",
       "      <td>3qvh482o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>69</td>\n",
       "      <td>\"Among 139 clients exposed to two symptomatic ...</td>\n",
       "      <td>r58aohnu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>73</td>\n",
       "      <td>I recall early on reading that researchers who...</td>\n",
       "      <td>sts48u9i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>93</td>\n",
       "      <td>You know you're credible when NIH website has ...</td>\n",
       "      <td>3sr2exq9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>96</td>\n",
       "      <td>Resistance to antifungal medications is a grow...</td>\n",
       "      <td>ybwwmyqy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14248</th>\n",
       "      <td>14248</td>\n",
       "      <td>\"evidence on covid-19 reveals a growing body o...</td>\n",
       "      <td>9169o29b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14249</th>\n",
       "      <td>14249</td>\n",
       "      <td>Outdoor lighting has detrimental impacts on lo...</td>\n",
       "      <td>s2bpha8l</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14250</th>\n",
       "      <td>14250</td>\n",
       "      <td>26/ and influenza virus (and other pathogens, ...</td>\n",
       "      <td>atloc9th</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14251</th>\n",
       "      <td>14251</td>\n",
       "      <td>does it?'sars-cov-2-naÃ¯ve vaccinees had a 13.0...</td>\n",
       "      <td>t4y1ylb3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14252</th>\n",
       "      <td>14252</td>\n",
       "      <td>when \"the airway immune cells of children are ...</td>\n",
       "      <td>nlsv8bin</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14253 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       post_id                                         tweet_text  cord_uid\n",
       "0           16  covid recovery: this study from the usa reveal...  3qvh482o\n",
       "1           69  \"Among 139 clients exposed to two symptomatic ...  r58aohnu\n",
       "2           73  I recall early on reading that researchers who...  sts48u9i\n",
       "3           93  You know you're credible when NIH website has ...  3sr2exq9\n",
       "4           96  Resistance to antifungal medications is a grow...  ybwwmyqy\n",
       "...        ...                                                ...       ...\n",
       "14248    14248  \"evidence on covid-19 reveals a growing body o...  9169o29b\n",
       "14249    14249  Outdoor lighting has detrimental impacts on lo...  s2bpha8l\n",
       "14250    14250  26/ and influenza virus (and other pathogens, ...  atloc9th\n",
       "14251    14251  does it?'sars-cov-2-naÃ¯ve vaccinees had a 13.0...  t4y1ylb3\n",
       "14252    14252  when \"the airway immune cells of children are ...  nlsv8bin\n",
       "\n",
       "[14253 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_query_combined = pd.concat([df_query_dev, df_query_train], ignore_index=True)\n",
    "df_query_combined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98bbfe1",
   "metadata": {},
   "source": [
    "Based on the basic_data_analysis.ipynb author last names and publication year might also carry important information so we extract this information from the raw data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a66f44e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_collection['last_names'] = df_collection['authors'].str.split(';').apply(\n",
    "    lambda authors: [author.split(',')[0].strip() for author in authors] if isinstance(authors, list) else authors\n",
    ")\n",
    "df_collection['last_names'] = df_collection['last_names'].apply(\n",
    "    lambda x: '; '.join(x) if isinstance(x, list) else x\n",
    ")\n",
    "df_collection['publish_year'] = df_collection['publish_time'].str.split('-').str[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1050e9b",
   "metadata": {},
   "source": [
    "We investigate a neural reranking approach. This means we need a solid and very efficient baseline that we can then rerank. We used the best performing BM25 model from the traditional_approach.ipynb for this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10c6aa4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_bm25(corpus: list[str], cord_uids:list[str], k1=1.5, b=0.75, method='lucene', stemmer=None):\n",
    "    tokenized_corpus = bm25s.tokenize(corpus, stemmer=stemmer)\n",
    "    bm25 = bm25s.BM25(corpus=cord_uids, k1=k1, b=b, method=method)\n",
    "    bm25.index(tokenized_corpus)\n",
    "    return bm25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "33950172",
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment_single_bm25(df_collection, df_query, k1=1.5, b=0.75, stemmer=None, k=10):\n",
    "    corpus = df_collection.apply(\n",
    "        lambda x: f\"{x['title']} {x['abstract']} {x['last_names']} {x['journal']} {x['publish_year']}\", axis=1\n",
    "    ).tolist()\n",
    "    bm25 = initialize_bm25(corpus, df_collection['cord_uid'].tolist(), k1, b, stemmer=stemmer)\n",
    "    tokenized_queries = bm25s.tokenize(df_query['tweet_text'], stemmer=stemmer)\n",
    "    doc_scores = bm25.retrieve(tokenized_queries, n_threads=-1, k=k)\n",
    "    df_query['bm25_topk'] = doc_scores.documents.tolist()\n",
    "    \n",
    "    return df_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1d4677d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_performance_mrr(data, col_gold, col_pred, list_k = [1, 5, 10]):\n",
    "    d_performance = {}\n",
    "    for k in list_k:\n",
    "        data[\"in_topx\"] = data.apply(lambda x: (1/([i for i in x[col_pred][:k]].index(x[col_gold]) + 1) if x[col_gold] in [i for i in x[col_pred][:k]] else 0), axis=1)\n",
    "        d_performance[k] = data[\"in_topx\"].mean()\n",
    "        print(f\"{k = }\")\n",
    "        in_topx = data[\"in_topx\"] > 0\n",
    "        print(f\"Number of queries in top {k}: {in_topx.sum()}\")\n",
    "        print(f\"Number of queries not in top {k}: {len(data) - in_topx.sum()}\")\n",
    "    return d_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a580058",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_experiment(df_query_train, df_query_dev, experiment_name, list_k=[1, 5, 10]):\n",
    "    results = get_performance_mrr(df_query_train, 'cord_uid', 'bm25_topk', list_k)\n",
    "    print(f\"Results for {experiment_name}, train: {results}\")\n",
    "    results = get_performance_mrr(df_query_dev, 'cord_uid', 'bm25_topk', list_k)\n",
    "    print(f\"Results for {experiment_name}, dev: {results}\")\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6f7008",
   "metadata": {},
   "source": [
    "We also wanted to know how many documents are necessary from BM25 to get the best possible reranking results. This is why we investigated how many documents the reranker should rerank for the final submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dfb72d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 1\n",
      "Number of queries in top 1: 7542\n",
      "Number of queries not in top 1: 5311\n",
      "k = 5\n",
      "Number of queries in top 5: 9094\n",
      "Number of queries not in top 5: 3759\n",
      "k = 10\n",
      "Number of queries in top 10: 9630\n",
      "Number of queries not in top 10: 3223\n",
      "k = 100\n",
      "Number of queries in top 100: 11156\n",
      "Number of queries not in top 100: 1697\n",
      "k = 200\n",
      "Number of queries in top 200: 11512\n",
      "Number of queries not in top 200: 1341\n",
      "k = 500\n",
      "Number of queries in top 500: 11956\n",
      "Number of queries not in top 500: 897\n",
      "k = 700\n",
      "Number of queries in top 700: 12089\n",
      "Number of queries not in top 700: 764\n",
      "k = 1000\n",
      "Number of queries in top 1000: 12210\n",
      "Number of queries not in top 1000: 643\n",
      "k = 2000\n",
      "Number of queries in top 2000: 12210\n",
      "Number of queries not in top 2000: 643\n",
      "k = 5000\n",
      "Number of queries in top 5000: 12210\n",
      "Number of queries not in top 5000: 643\n",
      "Results for Single BM25 with all features, train: {1: 0.5867890764801992, 5: 0.6347999170102959, 10: 0.6403735648153294, 100: 0.6449850219400036, 200: 0.6451818481542875, 500: 0.6452949090641488, 700: 0.6453125327422509, 1000: 0.6453238189817004, 2000: 0.6453238189817004, 5000: 0.6453238189817004}\n",
      "k = 1\n",
      "Number of queries in top 1: 829\n",
      "Number of queries not in top 1: 571\n",
      "k = 5\n",
      "Number of queries in top 5: 1004\n",
      "Number of queries not in top 5: 396\n",
      "k = 10\n",
      "Number of queries in top 10: 1060\n",
      "Number of queries not in top 10: 340\n",
      "k = 100\n",
      "Number of queries in top 100: 1222\n",
      "Number of queries not in top 100: 178\n",
      "k = 200\n",
      "Number of queries in top 200: 1266\n",
      "Number of queries not in top 200: 134\n",
      "k = 500\n",
      "Number of queries in top 500: 1300\n",
      "Number of queries not in top 500: 100\n",
      "k = 700\n",
      "Number of queries in top 700: 1323\n",
      "Number of queries not in top 700: 77\n",
      "k = 1000\n",
      "Number of queries in top 1000: 1336\n",
      "Number of queries not in top 1000: 64\n",
      "k = 2000\n",
      "Number of queries in top 2000: 1336\n",
      "Number of queries not in top 2000: 64\n",
      "k = 5000\n",
      "Number of queries in top 5000: 1336\n",
      "Number of queries not in top 5000: 64\n",
      "Results for Single BM25 with all features, dev: {1: 0.5921428571428572, 5: 0.6397619047619048, 10: 0.6450986394557824, 100: 0.6495240324689373, 200: 0.6497567832248164, 500: 0.6498352020281756, 700: 0.6498638803520272, 1000: 0.6498750349577517, 2000: 0.6498750349577517, 5000: 0.6498750349577517}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{1: 0.5921428571428572,\n",
       " 5: 0.6397619047619048,\n",
       " 10: 0.6450986394557824,\n",
       " 100: 0.6495240324689373,\n",
       " 200: 0.6497567832248164,\n",
       " 500: 0.6498352020281756,\n",
       " 700: 0.6498638803520272,\n",
       " 1000: 0.6498750349577517,\n",
       " 2000: 0.6498750349577517,\n",
       " 5000: 0.6498750349577517}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer = None\n",
    "df_query_train_single = experiment_single_bm25(df_collection, df_query_train, stemmer=stemmer, k=1000)\n",
    "df_query_dev_single = experiment_single_bm25(df_collection, df_query_dev, stemmer=stemmer, k=1000)\n",
    "evaluate_experiment(df_query_train_single, df_query_dev_single, \"Single BM25 with all features\", list_k=[1, 5, 10, 100, 200, 500, 700, 1000, 2000, 5000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975a0b66",
   "metadata": {},
   "source": [
    "The experiment above shows us that there is no improvement after the first 1k (doesnt matter whether we take top 1k or top 2k etc.) -> so for each query we will prefilter the documents with BM25 to the top 1k and then the reranker will take over. As reranking 1k documents is very expensive for the more computationlly intensive methods, we only do this for the final submission."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94222d60",
   "metadata": {},
   "source": [
    "## Reranking Inference code\n",
    "\n",
    "We use the transformers library to do the inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eefbf4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_reranker(model_name, torch_dtype=torch.float16):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        model_name, trust_remote_code=True, torch_dtype=torch.float16\n",
    "    )\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"Using GPU\")\n",
    "        model = model.to('cuda')\n",
    "    model.eval()\n",
    "    return tokenizer, model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87cd436",
   "metadata": {},
   "source": [
    "We feed (query, document) pairs into the model. For each pair we compute the score and use this to rerank the documents based on the score. Our documents are represented by the title, abstract, journal and author last names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "25058bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rerank_with_alibaba(df_query, df_collection, tokenizer, model, k=10, max_length=512, batch_size=32):\n",
    "    reranked_results = []\n",
    "    reranked_scores = []\n",
    "    reranked_docs = []\n",
    "\n",
    "    for _, row in tqdm(df_query.iterrows(), total=len(df_query), desc=\"Reranking\"):\n",
    "        query_text = row['tweet_text']\n",
    "        topk_docs = row['bm25_topk'] \n",
    "\n",
    "        pairs = [\n",
    "            [\n",
    "                query_text, \n",
    "                df_collection.loc[df_collection['cord_uid'] == doc_id, 'title'].values[0] + \" \" + \n",
    "                df_collection.loc[df_collection['cord_uid'] == doc_id, 'abstract'].values[0] + \" \" +\n",
    "                str(df_collection.loc[df_collection['cord_uid'] == doc_id, 'journal'].values[0]) + \" \" +\n",
    "                str(df_collection.loc[df_collection['cord_uid'] == doc_id, 'last_names'].values[0]) \n",
    "            ]\n",
    "            for doc_id in topk_docs\n",
    "        ]\n",
    "        \n",
    "        batch_scores = []\n",
    "        batch_docs = []\n",
    "\n",
    "        for i in range(0, len(pairs), batch_size):\n",
    "            batch_pairs = pairs[i:i + batch_size]\n",
    "            with torch.no_grad():\n",
    "                inputs = tokenizer(batch_pairs, padding=True, truncation=True, return_tensors='pt', max_length=max_length)\n",
    "                if torch.cuda.is_available():\n",
    "                    inputs = {key: value.to('cuda') for key, value in inputs.items()}\n",
    "                scores = model(**inputs, return_dict=True).logits.view(-1).float()\n",
    "\n",
    "            batch_scores.extend(scores.tolist())\n",
    "            batch_docs.extend(topk_docs[i:i+batch_size])\n",
    "\n",
    "\n",
    "        reranked = sorted(zip(batch_docs, batch_scores), key=lambda x: x[1], reverse=True)\n",
    "        reranked_results.append([doc_id for doc_id, _ in reranked[:k]])\n",
    "        reranked_scores.append([score for _, score in reranked])\n",
    "        reranked_docs.append([doc_id for doc_id, _ in reranked])\n",
    "\n",
    "    df_query['reranked_topk'] = reranked_results\n",
    "    df_query['reranked_docs'] = reranked_docs\n",
    "    df_query['reranked_scores'] = reranked_scores\n",
    "    return df_query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e83197",
   "metadata": {},
   "source": [
    "The Mxbai model comes with its own library and API. The code does the same as the one above, but its rewritten according to the API. Unfortunately the library offers no entry point for finetuning the model, so we can only run inference with it (relevant for later)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e360937c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rerank_mxbai(df_query, df_collection, model_name, k=10, batch_size=1):\n",
    "    reranked_results = []    \n",
    "    reranked_scores = []\n",
    "\n",
    "    model = MxbaiRerankV2(model_name, torch_dtype=torch.float16)\n",
    "\n",
    "    for _, row in tqdm(df_query.iterrows(), total=len(df_query), desc=\"Reranking\"):\n",
    "        query_text = row['tweet_text']\n",
    "        topk_docs = row['bm25_topk']  # Get top-k BM25 results for the query\n",
    "\n",
    "        documents = [\n",
    "            [\n",
    "                df_collection.loc[df_collection['cord_uid'] == doc_id, 'title'].values[0] + \" \" + \n",
    "                df_collection.loc[df_collection['cord_uid'] == doc_id, 'abstract'].values[0] + \" \" +\n",
    "                str(df_collection.loc[df_collection['cord_uid'] == doc_id, 'journal'].values[0]) + \" \" +\n",
    "                str(df_collection.loc[df_collection['cord_uid'] == doc_id, 'last_names'].values[0]) \n",
    "            ]\n",
    "            for doc_id in topk_docs\n",
    "        ]\n",
    "\n",
    "        results = model.rank(query_text, documents, return_documents=True, top_k=k, batch_size=batch_size)\n",
    "        reranked = [topk_docs[result.index] for result in results]\n",
    "        reranked_score = [result.score for result in results]\n",
    "\n",
    "        reranked_results.append(reranked)\n",
    "        reranked_scores.append(reranked_score)\n",
    "\n",
    "    df_query['reranked_topk'] = reranked_results\n",
    "    df_query['reranked_docs'] = reranked_results\n",
    "    df_query['reranked_scores'] = reranked_scores\n",
    "    \n",
    "    return df_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4f96d6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_reranked_results(df_query, col_gold='cord_uid', col_pred='reranked_topk', list_k=[1, 5, 10]):\n",
    "    return get_performance_mrr(df_query, col_gold, col_pred, list_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0ec103",
   "metadata": {},
   "source": [
    "## Experiments with the Baseline\n",
    "To see whether our finetuning works we need a baseline first. For this reason we evaluate the performance of the pretrained models first (before doing any finetuning).\n",
    "We chose the following models for our experiments:\n",
    "\n",
    "- Alibaba-NLP/gte-reranker-modernbert-base (referred to as alibaba): This model is based on ModernBERT, a variant of BERT that improves performance through architectural tweaks and training optimizations. It combines a text embedding component with a reranking head, offering state-of-the-art results for its parameter size and has been shown to perform well on retrieval benchmarks.\n",
    "- Alibaba-NLP/gte-multilingual-reranker-base, (alibaba multilingual): This model is trained on multilingual data and designed to handle queries and documents in multiple languages. We included it mainly to compare its performance against the English-only alibaba model and to check whether our dataset might contain any non-English content, as the dataset documentation does not specify the language.\n",
    "- cross-encoder/ms-marco-TinyBERT-L2-v2 (tinyBERT): A compact reranking model based on TinyBERT, which is a distilled version of BERT designed to keep most of BERTâ€™s accuracy while significantly reducing model size and inference time. It was trained on the MS MARCO Passage dataset. We mainly used this model during development and coding because itâ€™s efficient and fast to train, yet still delivers decent resultsâ€”making it ideal for quick experiments and debugging.\n",
    "- cross-encoder/ms-marco-MiniLM-L6-v2 and cross-encoder/ms-marco-MiniLM-L12-v2 (miniLMx): These models use the MiniLM architecture, which employs deep self- attention distillation to deliver a lightweight transformer model. With 6 and 12 layers respectively, they offer a good trade-off between speed and accuracy. Both are pretrained and fine-tuned on MS MARCO.\n",
    "- cross-encoder/ms-marco-electra-base (electra): This model uses ELECTRA as its backbone, which replaces traditional masked language modeling with a more sample-efficient pretraining method based on a discriminator network. ELECTRA models often outperform BERT in downstream tasks while being faster to train.\n",
    "- mixedbread-ai/mxbai-rerank-base-v2 (mxbai): This was the best-performing model we could run on our hardware, but unfortunately, it doesnâ€™t support fine-tuning through its API. It uses a sophisticated three-stage reinforcement learning approach inspired by DeepSeek: first, it learns binary relevance classification; next, it learns to capture semantic relationships via contrastive learning; and finally, it learns to optimize the ranking order.This multi-step training makes it especially effective for retrieval tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ee16e593",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reranking: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1400/1400 [06:42<00:00,  3.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 1\n",
      "Number of queries in top 1: 945\n",
      "Number of queries not in top 1: 455\n",
      "k = 5\n",
      "Number of queries in top 5: 1092\n",
      "Number of queries not in top 5: 308\n",
      "k = 10\n",
      "Number of queries in top 10: 1120\n",
      "Number of queries not in top 10: 280\n",
      "Evaluation results: {1: 0.675, 5: 0.7175714285714285, 10: 0.7203741496598639}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df_query_single = experiment_single_bm25(df_collection, df_query_dev, stemmer=stemmer, k=30)\n",
    "model_name = \"Alibaba-NLP/gte-reranker-modernbert-base\"\n",
    "tokenizer, model = initialize_reranker(model_name)\n",
    "df_query = rerank_with_alibaba(df_query_single, df_collection, tokenizer, model, k=10, batch_size=100)\n",
    "df_query.to_parquet('data/reranked_results_alibaba.parquet')\n",
    "results = evaluate_reranked_results(df_query)\n",
    "print(f\"Evaluation results: {results}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e3ed1b59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reranking: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1400/1400 [06:05<00:00,  3.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 1\n",
      "Number of queries in top 1: 898\n",
      "Number of queries not in top 1: 502\n",
      "k = 5\n",
      "Number of queries in top 5: 1068\n",
      "Number of queries not in top 5: 332\n",
      "k = 10\n",
      "Number of queries in top 10: 1100\n",
      "Number of queries not in top 10: 300\n",
      "Evaluation results: {1: 0.6414285714285715, 5: 0.6917500000000001, 10: 0.6949143990929705}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df_query_dev_single = experiment_single_bm25(df_collection, df_query_dev, stemmer=stemmer, k=30)\n",
    "model_name = \"Alibaba-NLP/gte-multilingual-reranker-base\"\n",
    "tokenizer, model = initialize_reranker(model_name)\n",
    "df_query = rerank_with_alibaba(df_query_dev_single, df_collection, tokenizer, model, k=10, batch_size=100)\n",
    "df_query.to_parquet('data/reranked_results_alibaba_multilingual.parquet')\n",
    "results = evaluate_reranked_results(df_query)\n",
    "print(f\"Evaluation results: {results}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e7c75753",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>cord_uid</th>\n",
       "      <th>bm25_topk</th>\n",
       "      <th>in_topx</th>\n",
       "      <th>reranked_topk</th>\n",
       "      <th>reranked_docs</th>\n",
       "      <th>reranked_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16</td>\n",
       "      <td>covid recovery: this study from the usa reveal...</td>\n",
       "      <td>3qvh482o</td>\n",
       "      <td>[atji1xge, mb18fj8a, 66g5lpm6, 59up4v56, gatxu...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[59up4v56, 82y56t7d, 8t2tic9n, n2kn7o67, 6mfd3...</td>\n",
       "      <td>[59up4v56, 82y56t7d, 8t2tic9n, n2kn7o67, 6mfd3...</td>\n",
       "      <td>[0.71435546875, 0.4404296875, 0.345458984375, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>69</td>\n",
       "      <td>\"Among 139 clients exposed to two symptomatic ...</td>\n",
       "      <td>r58aohnu</td>\n",
       "      <td>[r58aohnu, p0kg6dyz, yrowv62k, s2vckt2w, j1ucr...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[r58aohnu, kiq6xb6k, s2vckt2w, eay6qfhz, 70ine...</td>\n",
       "      <td>[r58aohnu, kiq6xb6k, s2vckt2w, eay6qfhz, 70ine...</td>\n",
       "      <td>[3.333984375, 0.349853515625, 0.17138671875, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>73</td>\n",
       "      <td>I recall early on reading that researchers who...</td>\n",
       "      <td>sts48u9i</td>\n",
       "      <td>[sgo76prc, sts48u9i, tz2shoso, gruir7aw, 3xw4q...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[sts48u9i, o47v5vgw, o877uul1, tz2shoso, gruir...</td>\n",
       "      <td>[sts48u9i, o47v5vgw, o877uul1, tz2shoso, gruir...</td>\n",
       "      <td>[0.309814453125, -0.06854248046875, -0.1237792...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>93</td>\n",
       "      <td>You know you're credible when NIH website has ...</td>\n",
       "      <td>3sr2exq9</td>\n",
       "      <td>[3sr2exq9, hgpiig0g, sv48gjkk, 1cpjqav4, k0f4c...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[3sr2exq9, k0f4cwig, sv48gjkk, 8j3bb6zx, tx8yp...</td>\n",
       "      <td>[3sr2exq9, k0f4cwig, sv48gjkk, 8j3bb6zx, tx8yp...</td>\n",
       "      <td>[0.83642578125, 0.22509765625, 0.1030883789062...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>96</td>\n",
       "      <td>Resistance to antifungal medications is a grow...</td>\n",
       "      <td>ybwwmyqy</td>\n",
       "      <td>[3l6ipiwk, vabb2f26, ouvq2wpq, lzddnb8j, ybwwm...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[ybwwmyqy, rs3umc1x, ouvq2wpq, 3l6ipiwk, ierqf...</td>\n",
       "      <td>[ybwwmyqy, rs3umc1x, ouvq2wpq, 3l6ipiwk, ierqf...</td>\n",
       "      <td>[0.22314453125, 0.08758544921875, -0.127197265...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   post_id                                         tweet_text  cord_uid  \\\n",
       "0       16  covid recovery: this study from the usa reveal...  3qvh482o   \n",
       "1       69  \"Among 139 clients exposed to two symptomatic ...  r58aohnu   \n",
       "2       73  I recall early on reading that researchers who...  sts48u9i   \n",
       "3       93  You know you're credible when NIH website has ...  3sr2exq9   \n",
       "4       96  Resistance to antifungal medications is a grow...  ybwwmyqy   \n",
       "\n",
       "                                           bm25_topk  in_topx  \\\n",
       "0  [atji1xge, mb18fj8a, 66g5lpm6, 59up4v56, gatxu...      0.0   \n",
       "1  [r58aohnu, p0kg6dyz, yrowv62k, s2vckt2w, j1ucr...      1.0   \n",
       "2  [sgo76prc, sts48u9i, tz2shoso, gruir7aw, 3xw4q...      1.0   \n",
       "3  [3sr2exq9, hgpiig0g, sv48gjkk, 1cpjqav4, k0f4c...      1.0   \n",
       "4  [3l6ipiwk, vabb2f26, ouvq2wpq, lzddnb8j, ybwwm...      1.0   \n",
       "\n",
       "                                       reranked_topk  \\\n",
       "0  [59up4v56, 82y56t7d, 8t2tic9n, n2kn7o67, 6mfd3...   \n",
       "1  [r58aohnu, kiq6xb6k, s2vckt2w, eay6qfhz, 70ine...   \n",
       "2  [sts48u9i, o47v5vgw, o877uul1, tz2shoso, gruir...   \n",
       "3  [3sr2exq9, k0f4cwig, sv48gjkk, 8j3bb6zx, tx8yp...   \n",
       "4  [ybwwmyqy, rs3umc1x, ouvq2wpq, 3l6ipiwk, ierqf...   \n",
       "\n",
       "                                       reranked_docs  \\\n",
       "0  [59up4v56, 82y56t7d, 8t2tic9n, n2kn7o67, 6mfd3...   \n",
       "1  [r58aohnu, kiq6xb6k, s2vckt2w, eay6qfhz, 70ine...   \n",
       "2  [sts48u9i, o47v5vgw, o877uul1, tz2shoso, gruir...   \n",
       "3  [3sr2exq9, k0f4cwig, sv48gjkk, 8j3bb6zx, tx8yp...   \n",
       "4  [ybwwmyqy, rs3umc1x, ouvq2wpq, 3l6ipiwk, ierqf...   \n",
       "\n",
       "                                     reranked_scores  \n",
       "0  [0.71435546875, 0.4404296875, 0.345458984375, ...  \n",
       "1  [3.333984375, 0.349853515625, 0.17138671875, 0...  \n",
       "2  [0.309814453125, -0.06854248046875, -0.1237792...  \n",
       "3  [0.83642578125, 0.22509765625, 0.1030883789062...  \n",
       "4  [0.22314453125, 0.08758544921875, -0.127197265...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reranking: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1400/1400 [01:10<00:00, 19.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 1\n",
      "Number of queries in top 1: 784\n",
      "Number of queries not in top 1: 616\n",
      "k = 5\n",
      "Number of queries in top 5: 993\n",
      "Number of queries not in top 5: 407\n",
      "k = 10\n",
      "Number of queries in top 10: 1057\n",
      "Number of queries not in top 10: 343\n",
      "Evaluation results: {1: 0.56, 5: 0.6177857142857143, 10: 0.6241026077097507}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df_query_dev_single = experiment_single_bm25(df_collection, df_query_dev, stemmer=stemmer, k=30)\n",
    "display(df_query_dev_single.head(5))\n",
    "model_name = \"cross-encoder/ms-marco-TinyBERT-L2-v2\"\n",
    "tokenizer, model = initialize_reranker(model_name)\n",
    "df_query = rerank_with_alibaba(df_query_dev_single, df_collection, tokenizer, model, k=10, batch_size=100)\n",
    "df_query.to_parquet(\"data/reranked_results_tinyBERT.parquet\")\n",
    "results = evaluate_reranked_results(df_query)\n",
    "print(f\"Evaluation results: {results}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a99af320",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>cord_uid</th>\n",
       "      <th>bm25_topk</th>\n",
       "      <th>in_topx</th>\n",
       "      <th>reranked_topk</th>\n",
       "      <th>reranked_docs</th>\n",
       "      <th>reranked_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16</td>\n",
       "      <td>covid recovery: this study from the usa reveal...</td>\n",
       "      <td>3qvh482o</td>\n",
       "      <td>[atji1xge, mb18fj8a, 66g5lpm6, 59up4v56, gatxu...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[atji1xge, 82y56t7d, trrg1mnw, o4vvlmr4, 8t2ti...</td>\n",
       "      <td>[atji1xge, 82y56t7d, trrg1mnw, o4vvlmr4, 8t2ti...</td>\n",
       "      <td>[5.74609375, 5.4140625, 5.33203125, 5.13671875...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>69</td>\n",
       "      <td>\"Among 139 clients exposed to two symptomatic ...</td>\n",
       "      <td>r58aohnu</td>\n",
       "      <td>[r58aohnu, p0kg6dyz, yrowv62k, s2vckt2w, j1ucr...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[r58aohnu, 6zfpcm4j, tu1vevx9, yrowv62k, kiq6x...</td>\n",
       "      <td>[r58aohnu, 6zfpcm4j, tu1vevx9, yrowv62k, kiq6x...</td>\n",
       "      <td>[6.75390625, 1.7626953125, 1.083984375, 0.7802...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>73</td>\n",
       "      <td>I recall early on reading that researchers who...</td>\n",
       "      <td>sts48u9i</td>\n",
       "      <td>[sgo76prc, sts48u9i, tz2shoso, gruir7aw, 3xw4q...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[sts48u9i, o47v5vgw, gruir7aw, 3xw4qjoy, o877u...</td>\n",
       "      <td>[sts48u9i, o47v5vgw, gruir7aw, 3xw4qjoy, o877u...</td>\n",
       "      <td>[-0.48095703125, -1.2470703125, -1.6162109375,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>93</td>\n",
       "      <td>You know you're credible when NIH website has ...</td>\n",
       "      <td>3sr2exq9</td>\n",
       "      <td>[3sr2exq9, hgpiig0g, sv48gjkk, 1cpjqav4, k0f4c...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>[kdegnr6i, bn22k0p3, 3sr2exq9, k0f4cwig, sv48g...</td>\n",
       "      <td>[kdegnr6i, bn22k0p3, 3sr2exq9, k0f4cwig, sv48g...</td>\n",
       "      <td>[-0.0164794921875, -1.2412109375, -1.251953125...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>96</td>\n",
       "      <td>Resistance to antifungal medications is a grow...</td>\n",
       "      <td>ybwwmyqy</td>\n",
       "      <td>[3l6ipiwk, vabb2f26, ouvq2wpq, lzddnb8j, ybwwm...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>[vabb2f26, ybwwmyqy, 3l6ipiwk, ouvq2wpq, buswb...</td>\n",
       "      <td>[vabb2f26, ybwwmyqy, 3l6ipiwk, ouvq2wpq, buswb...</td>\n",
       "      <td>[4.51171875, 4.36328125, 4.16015625, 2.578125,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   post_id                                         tweet_text  cord_uid  \\\n",
       "0       16  covid recovery: this study from the usa reveal...  3qvh482o   \n",
       "1       69  \"Among 139 clients exposed to two symptomatic ...  r58aohnu   \n",
       "2       73  I recall early on reading that researchers who...  sts48u9i   \n",
       "3       93  You know you're credible when NIH website has ...  3sr2exq9   \n",
       "4       96  Resistance to antifungal medications is a grow...  ybwwmyqy   \n",
       "\n",
       "                                           bm25_topk   in_topx  \\\n",
       "0  [atji1xge, mb18fj8a, 66g5lpm6, 59up4v56, gatxu...  0.000000   \n",
       "1  [r58aohnu, p0kg6dyz, yrowv62k, s2vckt2w, j1ucr...  1.000000   \n",
       "2  [sgo76prc, sts48u9i, tz2shoso, gruir7aw, 3xw4q...  1.000000   \n",
       "3  [3sr2exq9, hgpiig0g, sv48gjkk, 1cpjqav4, k0f4c...  0.333333   \n",
       "4  [3l6ipiwk, vabb2f26, ouvq2wpq, lzddnb8j, ybwwm...  0.500000   \n",
       "\n",
       "                                       reranked_topk  \\\n",
       "0  [atji1xge, 82y56t7d, trrg1mnw, o4vvlmr4, 8t2ti...   \n",
       "1  [r58aohnu, 6zfpcm4j, tu1vevx9, yrowv62k, kiq6x...   \n",
       "2  [sts48u9i, o47v5vgw, gruir7aw, 3xw4qjoy, o877u...   \n",
       "3  [kdegnr6i, bn22k0p3, 3sr2exq9, k0f4cwig, sv48g...   \n",
       "4  [vabb2f26, ybwwmyqy, 3l6ipiwk, ouvq2wpq, buswb...   \n",
       "\n",
       "                                       reranked_docs  \\\n",
       "0  [atji1xge, 82y56t7d, trrg1mnw, o4vvlmr4, 8t2ti...   \n",
       "1  [r58aohnu, 6zfpcm4j, tu1vevx9, yrowv62k, kiq6x...   \n",
       "2  [sts48u9i, o47v5vgw, gruir7aw, 3xw4qjoy, o877u...   \n",
       "3  [kdegnr6i, bn22k0p3, 3sr2exq9, k0f4cwig, sv48g...   \n",
       "4  [vabb2f26, ybwwmyqy, 3l6ipiwk, ouvq2wpq, buswb...   \n",
       "\n",
       "                                     reranked_scores  \n",
       "0  [5.74609375, 5.4140625, 5.33203125, 5.13671875...  \n",
       "1  [6.75390625, 1.7626953125, 1.083984375, 0.7802...  \n",
       "2  [-0.48095703125, -1.2470703125, -1.6162109375,...  \n",
       "3  [-0.0164794921875, -1.2412109375, -1.251953125...  \n",
       "4  [4.51171875, 4.36328125, 4.16015625, 2.578125,...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reranking: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1400/1400 [01:44<00:00, 13.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 1\n",
      "Number of queries in top 1: 807\n",
      "Number of queries not in top 1: 593\n",
      "k = 5\n",
      "Number of queries in top 5: 1008\n",
      "Number of queries not in top 5: 392\n",
      "k = 10\n",
      "Number of queries in top 10: 1068\n",
      "Number of queries not in top 10: 332\n",
      "Evaluation results: {1: 0.5764285714285714, 5: 0.630452380952381, 10: 0.6363630952380952}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df_query_dev_single = experiment_single_bm25(df_collection, df_query_dev, stemmer=stemmer, k=30)\n",
    "display(df_query_dev_single.head(5))\n",
    "model_name = \"cross-encoder/ms-marco-MiniLM-L6-v2\"\n",
    "tokenizer, model = initialize_reranker(model_name)\n",
    "df_query = rerank_with_alibaba(df_query_dev_single, df_collection, tokenizer, model, k=10, batch_size=100)\n",
    "df_query.to_parquet(\"data/reranked_results_miniLM6.parquet\")\n",
    "results = evaluate_reranked_results(df_query)\n",
    "print(f\"Evaluation results: {results}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f6a83dfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>cord_uid</th>\n",
       "      <th>bm25_topk</th>\n",
       "      <th>in_topx</th>\n",
       "      <th>reranked_topk</th>\n",
       "      <th>reranked_docs</th>\n",
       "      <th>reranked_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16</td>\n",
       "      <td>covid recovery: this study from the usa reveal...</td>\n",
       "      <td>3qvh482o</td>\n",
       "      <td>[atji1xge, mb18fj8a, 66g5lpm6, 59up4v56, gatxu...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[8t2tic9n, 6mfd3n4s, o4vvlmr4, 5hxsagx6, styav...</td>\n",
       "      <td>[8t2tic9n, 6mfd3n4s, o4vvlmr4, 5hxsagx6, styav...</td>\n",
       "      <td>[7.15625, 7.0546875, 7.0234375, 6.7734375, 6.5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>69</td>\n",
       "      <td>\"Among 139 clients exposed to two symptomatic ...</td>\n",
       "      <td>r58aohnu</td>\n",
       "      <td>[r58aohnu, p0kg6dyz, yrowv62k, s2vckt2w, j1ucr...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[r58aohnu, yrowv62k, tgd6gy3z, tu1vevx9, pdiyq...</td>\n",
       "      <td>[r58aohnu, yrowv62k, tgd6gy3z, tu1vevx9, pdiyq...</td>\n",
       "      <td>[9.3984375, 3.0859375, 2.765625, 2.6796875, 2....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>73</td>\n",
       "      <td>I recall early on reading that researchers who...</td>\n",
       "      <td>sts48u9i</td>\n",
       "      <td>[sgo76prc, sts48u9i, tz2shoso, gruir7aw, 3xw4q...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[sts48u9i, gruir7aw, o47v5vgw, o877uul1, mbam5...</td>\n",
       "      <td>[sts48u9i, gruir7aw, o47v5vgw, o877uul1, mbam5...</td>\n",
       "      <td>[6.203125, 6.0390625, 5.0625, 4.8046875, 3.953...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>93</td>\n",
       "      <td>You know you're credible when NIH website has ...</td>\n",
       "      <td>3sr2exq9</td>\n",
       "      <td>[3sr2exq9, hgpiig0g, sv48gjkk, 1cpjqav4, k0f4c...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[3sr2exq9, k0f4cwig, sv48gjkk, 8j3bb6zx, kdegn...</td>\n",
       "      <td>[3sr2exq9, k0f4cwig, sv48gjkk, 8j3bb6zx, kdegn...</td>\n",
       "      <td>[9.6796875, 5.7578125, 5.171875, 4.1875, 2.546...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>96</td>\n",
       "      <td>Resistance to antifungal medications is a grow...</td>\n",
       "      <td>ybwwmyqy</td>\n",
       "      <td>[3l6ipiwk, vabb2f26, ouvq2wpq, lzddnb8j, ybwwm...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[ybwwmyqy, ierqfgo5, ouvq2wpq, 3l6ipiwk, vabb2...</td>\n",
       "      <td>[ybwwmyqy, ierqfgo5, ouvq2wpq, 3l6ipiwk, vabb2...</td>\n",
       "      <td>[7.421875, 6.25, 5.9765625, 5.46875, 5.109375,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   post_id                                         tweet_text  cord_uid  \\\n",
       "0       16  covid recovery: this study from the usa reveal...  3qvh482o   \n",
       "1       69  \"Among 139 clients exposed to two symptomatic ...  r58aohnu   \n",
       "2       73  I recall early on reading that researchers who...  sts48u9i   \n",
       "3       93  You know you're credible when NIH website has ...  3sr2exq9   \n",
       "4       96  Resistance to antifungal medications is a grow...  ybwwmyqy   \n",
       "\n",
       "                                           bm25_topk  in_topx  \\\n",
       "0  [atji1xge, mb18fj8a, 66g5lpm6, 59up4v56, gatxu...      0.0   \n",
       "1  [r58aohnu, p0kg6dyz, yrowv62k, s2vckt2w, j1ucr...      1.0   \n",
       "2  [sgo76prc, sts48u9i, tz2shoso, gruir7aw, 3xw4q...      1.0   \n",
       "3  [3sr2exq9, hgpiig0g, sv48gjkk, 1cpjqav4, k0f4c...      1.0   \n",
       "4  [3l6ipiwk, vabb2f26, ouvq2wpq, lzddnb8j, ybwwm...      1.0   \n",
       "\n",
       "                                       reranked_topk  \\\n",
       "0  [8t2tic9n, 6mfd3n4s, o4vvlmr4, 5hxsagx6, styav...   \n",
       "1  [r58aohnu, yrowv62k, tgd6gy3z, tu1vevx9, pdiyq...   \n",
       "2  [sts48u9i, gruir7aw, o47v5vgw, o877uul1, mbam5...   \n",
       "3  [3sr2exq9, k0f4cwig, sv48gjkk, 8j3bb6zx, kdegn...   \n",
       "4  [ybwwmyqy, ierqfgo5, ouvq2wpq, 3l6ipiwk, vabb2...   \n",
       "\n",
       "                                       reranked_docs  \\\n",
       "0  [8t2tic9n, 6mfd3n4s, o4vvlmr4, 5hxsagx6, styav...   \n",
       "1  [r58aohnu, yrowv62k, tgd6gy3z, tu1vevx9, pdiyq...   \n",
       "2  [sts48u9i, gruir7aw, o47v5vgw, o877uul1, mbam5...   \n",
       "3  [3sr2exq9, k0f4cwig, sv48gjkk, 8j3bb6zx, kdegn...   \n",
       "4  [ybwwmyqy, ierqfgo5, ouvq2wpq, 3l6ipiwk, vabb2...   \n",
       "\n",
       "                                     reranked_scores  \n",
       "0  [7.15625, 7.0546875, 7.0234375, 6.7734375, 6.5...  \n",
       "1  [9.3984375, 3.0859375, 2.765625, 2.6796875, 2....  \n",
       "2  [6.203125, 6.0390625, 5.0625, 4.8046875, 3.953...  \n",
       "3  [9.6796875, 5.7578125, 5.171875, 4.1875, 2.546...  \n",
       "4  [7.421875, 6.25, 5.9765625, 5.46875, 5.109375,...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reranking: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1400/1400 [02:27<00:00,  9.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 1\n",
      "Number of queries in top 1: 778\n",
      "Number of queries not in top 1: 622\n",
      "k = 5\n",
      "Number of queries in top 5: 978\n",
      "Number of queries not in top 5: 422\n",
      "k = 10\n",
      "Number of queries in top 10: 1047\n",
      "Number of queries not in top 10: 353\n",
      "Evaluation results: {1: 0.5557142857142857, 5: 0.61075, 10: 0.6173647959183672}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df_query_dev_single = experiment_single_bm25(df_collection, df_query_dev, stemmer=stemmer, k=30)\n",
    "display(df_query_dev_single.head(5))\n",
    "model_name = \"cross-encoder/ms-marco-MiniLM-L12-v2\"\n",
    "tokenizer, model = initialize_reranker(model_name)\n",
    "df_query = rerank_with_alibaba(df_query_dev_single, df_collection, tokenizer, model, k=10, batch_size=100)\n",
    "df_query.to_parquet(\"data/reranked_results_miniLM12.parquet\")\n",
    "results = evaluate_reranked_results(df_query)\n",
    "print(f\"Evaluation results: {results}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "069665d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reranking: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1400/1400 [05:27<00:00,  4.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 1\n",
      "Number of queries in top 1: 717\n",
      "Number of queries not in top 1: 683\n",
      "k = 5\n",
      "Number of queries in top 5: 932\n",
      "Number of queries not in top 5: 468\n",
      "k = 10\n",
      "Number of queries in top 10: 1031\n",
      "Number of queries not in top 10: 369\n",
      "Evaluation results: {1: 0.5121428571428571, 5: 0.5711309523809525, 10: 0.58031179138322}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df_query_dev_single = experiment_single_bm25(df_collection, df_query_dev, stemmer=stemmer, k=30)\n",
    "model_name = \"cross-encoder/ms-marco-electra-base\"\n",
    "tokenizer, model = initialize_reranker(model_name)\n",
    "df_query = rerank_with_alibaba(df_query_dev_single, df_collection, tokenizer, model, k=10, batch_size=50, max_length=None )\n",
    "df_query.to_parquet(\"data/reranked_results_electra.parquet\")\n",
    "results = evaluate_reranked_results(df_query)\n",
    "print(f\"Evaluation results: {results}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cd25c9d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n",
      "Reranking:   0%|          | 0/1400 [00:00<?, ?it/s]You're using a Qwen2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "Reranking: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1400/1400 [27:41<00:00,  1.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 1\n",
      "Number of queries in top 1: 963\n",
      "Number of queries not in top 1: 437\n",
      "k = 5\n",
      "Number of queries in top 5: 1100\n",
      "Number of queries not in top 5: 300\n",
      "k = 10\n",
      "Number of queries in top 10: 1123\n",
      "Number of queries not in top 10: 277\n",
      "Evaluation results: {1: 0.6878571428571428, 5: 0.7266190476190477, 10: 0.7287573696145124}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df_query_dev_single = experiment_single_bm25(df_collection, df_query_dev, stemmer=stemmer, k=30)\n",
    "df_query = rerank_mxbai(df_query_dev_single, df_collection, \"mixedbread-ai/mxbai-rerank-base-v2\", batch_size=1)\n",
    "df_query.to_parquet(\"data/reranked_results_mxbai.parquet\")\n",
    "results = evaluate_reranked_results(df_query)\n",
    "print(f\"Evaluation results: {results}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcbff983",
   "metadata": {},
   "source": [
    "## Finetuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93606b0",
   "metadata": {},
   "source": [
    "This section shows the code and our experiments for the reranker finetuning. We used the sentence_transformers library to write the finetuning code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0b1d662d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "from sentence_transformers import CrossEncoder\n",
    "from sentence_transformers.cross_encoder.losses import CachedMultipleNegativesRankingLoss, MultipleNegativesRankingLoss, LambdaLoss\n",
    "from sentence_transformers.cross_encoder import CrossEncoderTrainingArguments\n",
    "from sentence_transformers.training_args import BatchSamplers\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sentence_transformers.util import mine_hard_negatives\n",
    "from sentence_transformers.cross_encoder.evaluation import CrossEncoderRerankingEvaluator\n",
    "from sentence_transformers.cross_encoder.losses.BinaryCrossEntropyLoss import BinaryCrossEntropyLoss\n",
    "from sentence_transformers.cross_encoder import CrossEncoderTrainer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e63c5e2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cord_uid</th>\n",
       "      <th>source_x</th>\n",
       "      <th>title</th>\n",
       "      <th>doi</th>\n",
       "      <th>pmcid</th>\n",
       "      <th>pubmed_id</th>\n",
       "      <th>license</th>\n",
       "      <th>abstract</th>\n",
       "      <th>publish_time</th>\n",
       "      <th>authors</th>\n",
       "      <th>journal</th>\n",
       "      <th>mag_id</th>\n",
       "      <th>who_covidence_id</th>\n",
       "      <th>arxiv_id</th>\n",
       "      <th>label</th>\n",
       "      <th>time</th>\n",
       "      <th>timet</th>\n",
       "      <th>last_names</th>\n",
       "      <th>publish_year</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>umvrwgaw</td>\n",
       "      <td>PMC</td>\n",
       "      <td>Professional and Home-Made Face Masks Reduce E...</td>\n",
       "      <td>10.1371/journal.pone.0002618</td>\n",
       "      <td>PMC2440799</td>\n",
       "      <td>18612429</td>\n",
       "      <td>cc-by</td>\n",
       "      <td>BACKGROUND: Governments are preparing for a po...</td>\n",
       "      <td>2008-07-09</td>\n",
       "      <td>van der Sande, Marianne; Teunis, Peter; Sabel,...</td>\n",
       "      <td>PLoS One</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>umvrwgaw</td>\n",
       "      <td>2008-07-09</td>\n",
       "      <td>1215561600</td>\n",
       "      <td>van der Sande; Teunis; Sabel</td>\n",
       "      <td>2008</td>\n",
       "      <td>Professional and Home-Made Face Masks Reduce E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611</th>\n",
       "      <td>spiud6ok</td>\n",
       "      <td>PMC</td>\n",
       "      <td>The Failure of R (0)</td>\n",
       "      <td>10.1155/2011/527610</td>\n",
       "      <td>PMC3157160</td>\n",
       "      <td>21860658</td>\n",
       "      <td>cc-by</td>\n",
       "      <td>The basic reproductive ratio, R (0), is one of...</td>\n",
       "      <td>2011-08-16</td>\n",
       "      <td>Li, Jing; Blakeley, Daniel; Smith?, Robert J.</td>\n",
       "      <td>Comput Math Methods Med</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>spiud6ok</td>\n",
       "      <td>2011-08-16</td>\n",
       "      <td>1313452800</td>\n",
       "      <td>Li; Blakeley; Smith?</td>\n",
       "      <td>2011</td>\n",
       "      <td>The Failure of R (0) The basic reproductive ra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>918</th>\n",
       "      <td>aclzp3iy</td>\n",
       "      <td>PMC</td>\n",
       "      <td>Pulmonary sequelae in a patient recovered from...</td>\n",
       "      <td>10.4103/0970-2113.99118</td>\n",
       "      <td>PMC3424870</td>\n",
       "      <td>22919170</td>\n",
       "      <td>cc-by-nc-sa</td>\n",
       "      <td>The pandemic of swine flu (H1N1) influenza spr...</td>\n",
       "      <td>2012</td>\n",
       "      <td>Singh, Virendra; Sharma, Bharat Bhushan; Patel...</td>\n",
       "      <td>Lung India</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>aclzp3iy</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>1325376000</td>\n",
       "      <td>Singh; Sharma; Patel</td>\n",
       "      <td>2012</td>\n",
       "      <td>Pulmonary sequelae in a patient recovered from...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     cord_uid source_x                                              title  \\\n",
       "162  umvrwgaw      PMC  Professional and Home-Made Face Masks Reduce E...   \n",
       "611  spiud6ok      PMC                               The Failure of R (0)   \n",
       "918  aclzp3iy      PMC  Pulmonary sequelae in a patient recovered from...   \n",
       "\n",
       "                              doi       pmcid pubmed_id      license  \\\n",
       "162  10.1371/journal.pone.0002618  PMC2440799  18612429        cc-by   \n",
       "611           10.1155/2011/527610  PMC3157160  21860658        cc-by   \n",
       "918       10.4103/0970-2113.99118  PMC3424870  22919170  cc-by-nc-sa   \n",
       "\n",
       "                                              abstract publish_time  \\\n",
       "162  BACKGROUND: Governments are preparing for a po...   2008-07-09   \n",
       "611  The basic reproductive ratio, R (0), is one of...   2011-08-16   \n",
       "918  The pandemic of swine flu (H1N1) influenza spr...         2012   \n",
       "\n",
       "                                               authors  \\\n",
       "162  van der Sande, Marianne; Teunis, Peter; Sabel,...   \n",
       "611      Li, Jing; Blakeley, Daniel; Smith?, Robert J.   \n",
       "918  Singh, Virendra; Sharma, Bharat Bhushan; Patel...   \n",
       "\n",
       "                     journal  mag_id who_covidence_id arxiv_id     label  \\\n",
       "162                 PLoS One     NaN              NaN      NaN  umvrwgaw   \n",
       "611  Comput Math Methods Med     NaN              NaN      NaN  spiud6ok   \n",
       "918               Lung India     NaN              NaN      NaN  aclzp3iy   \n",
       "\n",
       "          time       timet                    last_names publish_year  \\\n",
       "162 2008-07-09  1215561600  van der Sande; Teunis; Sabel         2008   \n",
       "611 2011-08-16  1313452800          Li; Blakeley; Smith?         2011   \n",
       "918 2012-01-01  1325376000          Singh; Sharma; Patel         2012   \n",
       "\n",
       "                                                answer  \n",
       "162  Professional and Home-Made Face Masks Reduce E...  \n",
       "611  The Failure of R (0) The basic reproductive ra...  \n",
       "918  Pulmonary sequelae in a patient recovered from...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_collection['answer'] = df_collection.apply(\n",
    "    lambda row: f\"{row['title']} {row['abstract']} {row['last_names']} {row['journal']}\", axis=1\n",
    ")\n",
    "df_collection.head(3)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b460ba5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>cord_uid</th>\n",
       "      <th>bm25_topk</th>\n",
       "      <th>in_topx</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Oral care in rehabilitation medicine: oral vul...</td>\n",
       "      <td>htlvpvz5</td>\n",
       "      <td>[htlvpvz5, h7hj64q5, 4aps0kvp, 5tkyir3r, 32z7b...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Oral Management in Rehabilitation Medicine: Or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>this study isn't receiving sufficient attentio...</td>\n",
       "      <td>4kfl29ul</td>\n",
       "      <td>[maj8r6ti, bjvg2ivr, 7tto4hr7, 2cwvga0k, 46je8...</td>\n",
       "      <td>0.003145</td>\n",
       "      <td>Variation in racial/ethnic disparities in COVI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>thanks, xi jinping. a reminder that this study...</td>\n",
       "      <td>jtwb17u8</td>\n",
       "      <td>[jtwb17u8, veeavho5, jbpmbm9m, 8hkxbxz9, 32v44...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Effect of non-pharmaceutical interventions for...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   post_id                                         tweet_text  cord_uid  \\\n",
       "0        0  Oral care in rehabilitation medicine: oral vul...  htlvpvz5   \n",
       "1        1  this study isn't receiving sufficient attentio...  4kfl29ul   \n",
       "2        2  thanks, xi jinping. a reminder that this study...  jtwb17u8   \n",
       "\n",
       "                                           bm25_topk   in_topx  \\\n",
       "0  [htlvpvz5, h7hj64q5, 4aps0kvp, 5tkyir3r, 32z7b...  1.000000   \n",
       "1  [maj8r6ti, bjvg2ivr, 7tto4hr7, 2cwvga0k, 46je8...  0.003145   \n",
       "2  [jtwb17u8, veeavho5, jbpmbm9m, 8hkxbxz9, 32v44...  1.000000   \n",
       "\n",
       "                                              answer  \n",
       "0  Oral Management in Rehabilitation Medicine: Or...  \n",
       "1  Variation in racial/ethnic disparities in COVI...  \n",
       "2  Effect of non-pharmaceutical interventions for...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = df_query_train.merge(df_collection[['cord_uid', 'answer']], on='cord_uid', how='left')\n",
    "df_dev = df_query_dev.merge(df_collection[['cord_uid', 'answer']], on='cord_uid', how='left')\n",
    "df_full = pd.concat([df_train, df_dev], ignore_index=True)\n",
    "df_full.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "56627c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset.from_dict({\n",
    "    \"query\": df_train['tweet_text'].tolist(),\n",
    "    \"document\": df_train['answer'].tolist(),\n",
    "})\n",
    "\n",
    "dev_dataset = Dataset.from_dict({\n",
    "    \"query\": df_dev['tweet_text'].tolist(),\n",
    "    \"document\": df_dev['answer'].tolist(),\n",
    "})\n",
    "full_dataset = Dataset.from_dict({\n",
    "    \"query\": df_full['tweet_text'].tolist(),\n",
    "    \"document\": df_full['answer'].tolist(),\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6194801f",
   "metadata": {},
   "source": [
    "We use hard negative mining during training to give the model highly related but irrelevant documents such that the model is able to learn the differences between them.\n",
    "Depending on our loss function we either feed pairs of (query, document, relevancy-label) or (query, [doc1, ...], [relevancy-label1, ...]) triplets.\n",
    "\n",
    "The code for the training is relatively straightforward - its mostly just setting parameters. We save the best model according to the validation dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3388f98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hard_negatives(embedding_model_hard_negatives, num_hard_negatives, num_hard_negatives_eval, train_dataset, dev_dataset, df_full, batch_size=4096, loss='crossentropy', stricter_hard_negatives=False):\n",
    "\n",
    "    embedding_model = SentenceTransformer(embedding_model_hard_negatives, device=torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "\n",
    "    if loss == 'crossentropy':\n",
    "        output_format = \"labeled-pair\"\n",
    "    elif loss == 'lambda':\n",
    "        output_format = \"labeled-list\"\n",
    "    else:\n",
    "        raise ValueError(\"Invalid loss type. Use 'crossentropy' or 'lambda'.\")\n",
    "    \n",
    "    if stricter_hard_negatives:\n",
    "        hard_train_dataset = mine_hard_negatives(\n",
    "            train_dataset,\n",
    "            embedding_model,\n",
    "            num_negatives=num_hard_negatives,  # How many negatives per question-answer pair\n",
    "            range_min=3,  # Skip the x most similar samples\n",
    "            range_max=100,  # Consider only the x most similar samples\n",
    "            max_score=0.95,  # Only consider samples with a similarity score of at most x\n",
    "            margin=0.0,  # Similarity between query and negative samples should be x lower than query-positive similarity\n",
    "            sampling_strategy=\"top\",  # Randomly sample negatives from the range\n",
    "            batch_size=batch_size,\n",
    "            output_format=output_format, \n",
    "        )\n",
    "    else:\n",
    "        hard_train_dataset = mine_hard_negatives(\n",
    "            train_dataset,\n",
    "            embedding_model,\n",
    "            num_negatives=num_hard_negatives,  # How many negatives per question-answer pair\n",
    "            range_min=5,  # Skip the x most similar samples\n",
    "            range_max=100,  # Consider only the x most similar samples\n",
    "            max_score=0.8,  # Only consider samples with a similarity score of at most x\n",
    "            margin=0.05,  # Similarity between query and negative samples should be x lower than query-positive similarity\n",
    "            sampling_strategy=\"top\",  # Randomly sample negatives from the range\n",
    "            batch_size=batch_size,  \n",
    "            output_format=output_format,\n",
    "        )\n",
    "\n",
    "\n",
    "    print(\"======================\")\n",
    "    hard_eval_dataset = mine_hard_negatives(\n",
    "        dev_dataset,\n",
    "        embedding_model,\n",
    "        corpus=df_full[\"answer\"],  # Use the full dataset as the corpus\n",
    "        num_negatives=num_hard_negatives_eval,  # How many negatives per question-answer pair\n",
    "        batch_size=batch_size,  \n",
    "        output_format=output_format,\n",
    "    )\n",
    "\n",
    "    print(\"======================\")\n",
    "    hard_eval_dataset_evaluator = mine_hard_negatives(\n",
    "        dev_dataset,\n",
    "        embedding_model,\n",
    "        corpus=df_full[\"answer\"],  # Use the full dataset as the corpus\n",
    "        num_negatives=num_hard_negatives_eval,  # How many negatives per question-answer pair\n",
    "        batch_size=batch_size,\n",
    "        include_positives=True,  # Key: Include the positive answer in the list of negatives, needed for the evaluater to work correctly\n",
    "    )\n",
    "\n",
    "    return hard_train_dataset, hard_eval_dataset, hard_eval_dataset_evaluator\n",
    "\n",
    "\n",
    "class ExperimentRunner:\n",
    "    def __init__(self, model_to_finetune, train_batch_size, num_epochs, max_length, experiment_name):\n",
    "        self.experiment_name = experiment_name\n",
    "        self.model_to_finetune = model_to_finetune\n",
    "        self.train_batch_size = train_batch_size\n",
    "        self.num_epochs = num_epochs\n",
    "        self.max_length = max_length\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    def run_experiment(\n",
    "            self, \n",
    "            hard_train_dataset, \n",
    "            hard_eval_dataset, \n",
    "            hard_eval_dataset_evaluator, \n",
    "            num_hard_negatives, \n",
    "            trust_remote_code=False, \n",
    "            eval_steps=None, \n",
    "            loss='crossentropy',\n",
    "            adaptive_learning_rate=False,\n",
    "        ):\n",
    "\n",
    "        if eval_steps is None:\n",
    "            eval_steps = int(3000/self.train_batch_size)\n",
    "        \n",
    "        print(f\"Eval steps: {eval_steps}\")\n",
    "        model = CrossEncoder(self.model_to_finetune, max_length=self.max_length, device=self.device, trust_remote_code=trust_remote_code)\n",
    "\n",
    "        if adaptive_learning_rate:\n",
    "            learning_rate = 2e-6\n",
    "            weight_decay = 1e-7\n",
    "            adam_epsilon = 1e-7\n",
    "            warmup_ratio = 0.05\n",
    "        else:\n",
    "            learning_rate = 2e-5\n",
    "            weight_decay = 0.0\n",
    "            adam_epsilon = 1e-8\n",
    "            warmup_ratio = 0.1\n",
    "\n",
    "        args = CrossEncoderTrainingArguments(\n",
    "            output_dir=f\"model/{self.model_to_finetune.split(\"/\")[-1]}{self.experiment_name}\",\n",
    "            num_train_epochs=self.num_epochs,\n",
    "            per_device_train_batch_size=self.train_batch_size,\n",
    "            per_device_eval_batch_size=self.train_batch_size,\n",
    "            learning_rate=learning_rate,\n",
    "            weight_decay=weight_decay,\n",
    "            adam_epsilon=adam_epsilon,\n",
    "            warmup_ratio=warmup_ratio,\n",
    "            fp16=True,  \n",
    "            bf16=False, \n",
    "            batch_sampler=BatchSamplers.NO_DUPLICATES, \n",
    "            eval_strategy=\"steps\",\n",
    "            eval_steps=eval_steps,\n",
    "            save_strategy=\"steps\",\n",
    "            save_steps=eval_steps,\n",
    "            save_total_limit=10,\n",
    "            logging_steps=eval_steps,\n",
    "            run_name=self.model_to_finetune.split(\"/\")[-1],\n",
    "            load_best_model_at_end=True,\n",
    "            metric_for_best_model=\"eval_dev_set_mrr@10\",\n",
    "            greater_is_better=False,\n",
    "            eval_on_start=True,\n",
    "        )\n",
    "        \n",
    "        reranking_evaluator = CrossEncoderRerankingEvaluator(\n",
    "            samples=[\n",
    "                {\n",
    "                    \"query\": sample[\"query\"],\n",
    "                    \"positive\": [sample[\"document\"]],\n",
    "                    \"documents\": [sample[column_name] for column_name in hard_eval_dataset_evaluator.column_names if 'negative' in column_name],\n",
    "                }\n",
    "                for sample in hard_eval_dataset_evaluator\n",
    "            ],\n",
    "            batch_size=self.train_batch_size,\n",
    "            name=\"dev_set\",\n",
    "            show_progress_bar=True,\n",
    "        )\n",
    "\n",
    "        if loss == 'crossentropy':\n",
    "            loss = BinaryCrossEntropyLoss(model=model, pos_weight=torch.tensor(num_hard_negatives))\n",
    "        elif loss == 'lambda':\n",
    "            loss = LambdaLoss(model=model, k=5)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid loss type. Use 'crossentropy' or 'lambda'.\")\n",
    "        \n",
    "        trainer = CrossEncoderTrainer(\n",
    "            model=model,\n",
    "            args=args,\n",
    "            train_dataset=hard_train_dataset,\n",
    "            eval_dataset=hard_eval_dataset,\n",
    "            loss=loss,\n",
    "            evaluator=reranking_evaluator,\n",
    "    \n",
    "        )\n",
    "\n",
    "        trainer.train()\n",
    "\n",
    "        model.save(f\"models/{self.model_to_finetune.split('/')[-1]}-finetuned{self.experiment_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afccf474",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 2\n",
    "# embedding_model_hard_negatives = \"sentence-transformers/static-retrieval-mrl-en-v1\"\n",
    "embedding_model_hard_negatives = \"BAAI/bge-small-en-v1.5\"\n",
    "loss = 'lambda'\n",
    "stricter_hard_negatives = True\n",
    "adaptive_learning_rate = True\n",
    "experiment_name = f\"_{embedding_model_hard_negatives.split('/')[-1]}_epochs{num_epochs}_{loss}loss_learningrate\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bdb639f",
   "metadata": {},
   "source": [
    "This code actually mines the hard negatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23062379",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `margin` parameter is deprecated. Use the `absolute_margin` and/or `relative_margin` parameter instead. Setting `absolute_margin` to `0.0`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12842 unique queries out of 12853 total queries.\n",
      "Found an average of 1.001 positives per query.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 109/109 [00:41<00:00,  2.60it/s]\n",
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 201/201 [00:09<00:00, 20.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric       Positive       Negative     Difference\n",
      "Count          12,853         56,528               \n",
      "Mean           0.8195         0.7853         0.0519\n",
      "Median         0.8329         0.7960         0.0405\n",
      "Std            0.0826         0.0539         0.0473\n",
      "Min            0.3809         0.5096        -0.0630\n",
      "25%            0.7696         0.7537         0.0122\n",
      "50%            0.8329         0.7960         0.0405\n",
      "75%            0.8834         0.8233         0.0781\n",
      "Max            0.9881         0.9207         0.2992\n",
      "Skipped 237,587 potential negatives (17.96%) due to the absolute_margin of 0.0.\n",
      "Skipped 4 potential negatives (0.00%) due to the max_score of 0.95.\n",
      "Could not find enough negatives for 7737 samples (12.04%). Consider adjusting the range_max, range_min, absolute_margin and max_score parameters if you'd like to find more valid negatives.\n",
      "======================\n",
      "Setting range_max to 7 based on the provided parameters.\n",
      "Found 1399 unique queries out of 1400 total queries.\n",
      "Found an average of 1.001 positives per query.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 121/121 [00:46<00:00,  2.60it/s]\n",
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:01<00:00, 21.45it/s]\n",
      "When using `include_positives=True`, `output_format` will be set to `\"n-tuple\"` to ensure that the ranking order is preserved.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric       Positive       Negative     Difference\n",
      "Count           1,400          7,000               \n",
      "Mean           0.8219         0.8033         0.0186\n",
      "Median         0.8323         0.8101         0.0168\n",
      "Std            0.0783         0.0505         0.0640\n",
      "Min            0.4977         0.5529        -0.1856\n",
      "25%            0.7717         0.7739        -0.0220\n",
      "50%            0.8323         0.8101         0.0168\n",
      "75%            0.8846         0.8388         0.0593\n",
      "Max            0.9681         0.9451         0.2385\n",
      "======================\n",
      "Setting range_max to 7 based on the provided parameters.\n",
      "Found 1399 unique queries out of 1400 total queries.\n",
      "Found an average of 1.001 positives per query.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 121/121 [00:47<00:00,  2.56it/s]\n",
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:01<00:00, 21.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric       Positive       Negative     Difference\n",
      "Count           1,400          7,000               \n",
      "Mean           0.8219         0.8117         0.0102\n",
      "Median         0.8323         0.8156         0.0000\n",
      "Std            0.0783         0.0543         0.0593\n",
      "Min            0.4977         0.5593        -0.1856\n",
      "25%            0.7717         0.7790        -0.0220\n",
      "50%            0.8323         0.8156         0.0000\n",
      "75%            0.8846         0.8466         0.0443\n",
      "Max            0.9681         0.9681         0.2377\n"
     ]
    }
   ],
   "source": [
    "num_hard_negatives = 5\n",
    "hard_train_dataset, hard_eval_dataset, hard_eval_dataset_evaluator = get_hard_negatives(\n",
    "    embedding_model_hard_negatives, \n",
    "    num_hard_negatives=num_hard_negatives, \n",
    "    num_hard_negatives_eval=5, \n",
    "    train_dataset=train_dataset, \n",
    "    dev_dataset=dev_dataset, \n",
    "    df_full=df_full, \n",
    "    batch_size=64, \n",
    "    loss=loss,\n",
    "    stricter_hard_negatives=stricter_hard_negatives\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "45f89b42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['query', 'document', 'labels'],\n",
       "    num_rows: 11322\n",
       "})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hard_train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d68af576",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['query', 'document', 'labels'],\n",
       "    num_rows: 1400\n",
       "})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hard_eval_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "02be7808",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['query', 'document', 'negative_1', 'negative_2', 'negative_3', 'negative_4', 'negative_5'],\n",
       "    num_rows: 1400\n",
       "})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hard_eval_dataset_evaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72765dfa",
   "metadata": {},
   "source": [
    "### Experiments\n",
    "In the following cells we finetune each of the models based on the parameters defined above. We set the batch size as high as possible such that we (just barely) dont run into OOM errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b31039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval steps: 22\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='120' max='120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [120/120 01:33, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Dev Set Map</th>\n",
       "      <th>Dev Set Mrr@10</th>\n",
       "      <th>Dev Set Ndcg@10</th>\n",
       "      <th>Dev Set Base Map</th>\n",
       "      <th>Dev Set Base Mrr@10</th>\n",
       "      <th>Dev Set Base Ndcg@10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.365992</td>\n",
       "      <td>0.756345</td>\n",
       "      <td>0.756345</td>\n",
       "      <td>0.815318</td>\n",
       "      <td>0.568988</td>\n",
       "      <td>0.568988</td>\n",
       "      <td>0.595057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.688500</td>\n",
       "      <td>1.361590</td>\n",
       "      <td>0.754798</td>\n",
       "      <td>0.754798</td>\n",
       "      <td>0.814166</td>\n",
       "      <td>0.568988</td>\n",
       "      <td>0.568988</td>\n",
       "      <td>0.595057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.677600</td>\n",
       "      <td>1.346526</td>\n",
       "      <td>0.753988</td>\n",
       "      <td>0.753988</td>\n",
       "      <td>0.813541</td>\n",
       "      <td>0.568988</td>\n",
       "      <td>0.568988</td>\n",
       "      <td>0.595057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>0.616600</td>\n",
       "      <td>1.342660</td>\n",
       "      <td>0.754012</td>\n",
       "      <td>0.754012</td>\n",
       "      <td>0.813548</td>\n",
       "      <td>0.568988</td>\n",
       "      <td>0.568988</td>\n",
       "      <td>0.595057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88</td>\n",
       "      <td>0.584200</td>\n",
       "      <td>1.340421</td>\n",
       "      <td>0.754702</td>\n",
       "      <td>0.754702</td>\n",
       "      <td>0.814057</td>\n",
       "      <td>0.568988</td>\n",
       "      <td>0.568988</td>\n",
       "      <td>0.595057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.602200</td>\n",
       "      <td>1.327426</td>\n",
       "      <td>0.753988</td>\n",
       "      <td>0.753988</td>\n",
       "      <td>0.813503</td>\n",
       "      <td>0.568988</td>\n",
       "      <td>0.568988</td>\n",
       "      <td>0.595057</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    }
   ],
   "source": [
    "train_batch_size = 128\n",
    "max_length = 512\n",
    "model_to_finetune = \"cross-encoder/ms-marco-TinyBERT-L2-v2\"\n",
    "\n",
    "exp_runner = ExperimentRunner(\n",
    "    model_to_finetune,\n",
    "    train_batch_size,\n",
    "    num_epochs,\n",
    "    max_length,\n",
    "    experiment_name=experiment_name\n",
    ")\n",
    "exp_runner.run_experiment(hard_train_dataset, hard_eval_dataset, hard_eval_dataset_evaluator, num_hard_negatives, loss=loss, adaptive_learning_rate=adaptive_learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d051f523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval steps: 750\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3942' max='3942' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3942/3942 21:56, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Dev Set Map</th>\n",
       "      <th>Dev Set Mrr@10</th>\n",
       "      <th>Dev Set Ndcg@10</th>\n",
       "      <th>Dev Set Base Map</th>\n",
       "      <th>Dev Set Base Mrr@10</th>\n",
       "      <th>Dev Set Base Ndcg@10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.317779</td>\n",
       "      <td>0.740036</td>\n",
       "      <td>0.740036</td>\n",
       "      <td>0.802646</td>\n",
       "      <td>0.568988</td>\n",
       "      <td>0.568988</td>\n",
       "      <td>0.595057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.237300</td>\n",
       "      <td>1.212988</td>\n",
       "      <td>0.783750</td>\n",
       "      <td>0.783750</td>\n",
       "      <td>0.835814</td>\n",
       "      <td>0.568988</td>\n",
       "      <td>0.568988</td>\n",
       "      <td>0.595057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.088200</td>\n",
       "      <td>1.292978</td>\n",
       "      <td>0.788357</td>\n",
       "      <td>0.788357</td>\n",
       "      <td>0.839327</td>\n",
       "      <td>0.568988</td>\n",
       "      <td>0.568988</td>\n",
       "      <td>0.595057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2250</td>\n",
       "      <td>0.082200</td>\n",
       "      <td>1.354321</td>\n",
       "      <td>0.788595</td>\n",
       "      <td>0.788595</td>\n",
       "      <td>0.839466</td>\n",
       "      <td>0.568988</td>\n",
       "      <td>0.568988</td>\n",
       "      <td>0.595057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.071900</td>\n",
       "      <td>1.403692</td>\n",
       "      <td>0.788440</td>\n",
       "      <td>0.788440</td>\n",
       "      <td>0.839341</td>\n",
       "      <td>0.568988</td>\n",
       "      <td>0.568988</td>\n",
       "      <td>0.595057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3750</td>\n",
       "      <td>0.078000</td>\n",
       "      <td>1.422006</td>\n",
       "      <td>0.790524</td>\n",
       "      <td>0.790524</td>\n",
       "      <td>0.840919</td>\n",
       "      <td>0.568988</td>\n",
       "      <td>0.568988</td>\n",
       "      <td>0.595057</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    }
   ],
   "source": [
    "train_batch_size = 4\n",
    "max_length = 512\n",
    "model_to_finetune = \"cross-encoder/ms-marco-MiniLM-L12-v2\"\n",
    "\n",
    "exp_runner = ExperimentRunner(\n",
    "    model_to_finetune,\n",
    "    train_batch_size,\n",
    "    num_epochs,\n",
    "    max_length,\n",
    "    experiment_name=experiment_name\n",
    ")\n",
    "\n",
    "exp_runner.run_experiment(hard_train_dataset, hard_eval_dataset, hard_eval_dataset_evaluator, num_hard_negatives, loss=loss, adaptive_learning_rate=adaptive_learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64dcc1a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval steps: 375\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1972' max='1972' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1972/1972 11:26, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Dev Set Map</th>\n",
       "      <th>Dev Set Mrr@10</th>\n",
       "      <th>Dev Set Ndcg@10</th>\n",
       "      <th>Dev Set Base Map</th>\n",
       "      <th>Dev Set Base Mrr@10</th>\n",
       "      <th>Dev Set Base Ndcg@10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.235787</td>\n",
       "      <td>0.759298</td>\n",
       "      <td>0.759298</td>\n",
       "      <td>0.817261</td>\n",
       "      <td>0.568988</td>\n",
       "      <td>0.568988</td>\n",
       "      <td>0.595057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.250400</td>\n",
       "      <td>1.146599</td>\n",
       "      <td>0.777667</td>\n",
       "      <td>0.777667</td>\n",
       "      <td>0.831213</td>\n",
       "      <td>0.568988</td>\n",
       "      <td>0.568988</td>\n",
       "      <td>0.595057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.143700</td>\n",
       "      <td>1.216257</td>\n",
       "      <td>0.782012</td>\n",
       "      <td>0.782012</td>\n",
       "      <td>0.834577</td>\n",
       "      <td>0.568988</td>\n",
       "      <td>0.568988</td>\n",
       "      <td>0.595057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1125</td>\n",
       "      <td>0.120500</td>\n",
       "      <td>1.275048</td>\n",
       "      <td>0.784190</td>\n",
       "      <td>0.784190</td>\n",
       "      <td>0.836246</td>\n",
       "      <td>0.568988</td>\n",
       "      <td>0.568988</td>\n",
       "      <td>0.595057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.097000</td>\n",
       "      <td>1.318414</td>\n",
       "      <td>0.785560</td>\n",
       "      <td>0.785560</td>\n",
       "      <td>0.837306</td>\n",
       "      <td>0.568988</td>\n",
       "      <td>0.568988</td>\n",
       "      <td>0.595057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1875</td>\n",
       "      <td>0.108400</td>\n",
       "      <td>1.317869</td>\n",
       "      <td>0.785512</td>\n",
       "      <td>0.785512</td>\n",
       "      <td>0.837261</td>\n",
       "      <td>0.568988</td>\n",
       "      <td>0.568988</td>\n",
       "      <td>0.595057</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    }
   ],
   "source": [
    "train_batch_size = 8\n",
    "max_length = 512\n",
    "model_to_finetune = \"cross-encoder/ms-marco-MiniLM-L6-v2\"\n",
    "\n",
    "exp_runner = ExperimentRunner(\n",
    "    model_to_finetune,\n",
    "    train_batch_size,\n",
    "    num_epochs,\n",
    "    max_length,\n",
    "    experiment_name=experiment_name\n",
    ")\n",
    "\n",
    "exp_runner.run_experiment(hard_train_dataset, hard_eval_dataset, hard_eval_dataset_evaluator, num_hard_negatives, loss=loss, adaptive_learning_rate=adaptive_learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8f9fef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval steps: 3000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='15770' max='15770' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15770/15770 1:24:09, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Dev Set Map</th>\n",
       "      <th>Dev Set Mrr@10</th>\n",
       "      <th>Dev Set Ndcg@10</th>\n",
       "      <th>Dev Set Base Map</th>\n",
       "      <th>Dev Set Base Mrr@10</th>\n",
       "      <th>Dev Set Base Ndcg@10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>No log</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.716131</td>\n",
       "      <td>0.716131</td>\n",
       "      <td>0.784809</td>\n",
       "      <td>0.568988</td>\n",
       "      <td>0.568988</td>\n",
       "      <td>0.595057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.275200</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.774929</td>\n",
       "      <td>0.774929</td>\n",
       "      <td>0.829386</td>\n",
       "      <td>0.568988</td>\n",
       "      <td>0.568988</td>\n",
       "      <td>0.595057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.087500</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.775321</td>\n",
       "      <td>0.775321</td>\n",
       "      <td>0.829746</td>\n",
       "      <td>0.568988</td>\n",
       "      <td>0.568988</td>\n",
       "      <td>0.595057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.075400</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.775964</td>\n",
       "      <td>0.775964</td>\n",
       "      <td>0.830208</td>\n",
       "      <td>0.568988</td>\n",
       "      <td>0.568988</td>\n",
       "      <td>0.595057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.042900</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.783214</td>\n",
       "      <td>0.783214</td>\n",
       "      <td>0.835638</td>\n",
       "      <td>0.568988</td>\n",
       "      <td>0.568988</td>\n",
       "      <td>0.595057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.040800</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.775857</td>\n",
       "      <td>0.776214</td>\n",
       "      <td>0.830430</td>\n",
       "      <td>0.568988</td>\n",
       "      <td>0.568988</td>\n",
       "      <td>0.595057</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    }
   ],
   "source": [
    "\n",
    "train_batch_size = 1\n",
    "max_length = 512\n",
    "model_to_finetune = \"cross-encoder/ms-marco-electra-base\"\n",
    "\n",
    "exp_runner = ExperimentRunner(\n",
    "    model_to_finetune,\n",
    "    train_batch_size,\n",
    "    num_epochs,\n",
    "    max_length,\n",
    "    experiment_name=experiment_name\n",
    ")\n",
    "\n",
    "exp_runner.run_experiment(hard_train_dataset, hard_eval_dataset, hard_eval_dataset_evaluator, num_hard_negatives, loss=loss, adaptive_learning_rate=adaptive_learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5120df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval steps: 3000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='22644' max='22644' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22644/22644 2:28:58, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Dev Set Map</th>\n",
       "      <th>Dev Set Mrr@10</th>\n",
       "      <th>Dev Set Ndcg@10</th>\n",
       "      <th>Dev Set Base Map</th>\n",
       "      <th>Dev Set Base Mrr@10</th>\n",
       "      <th>Dev Set Base Ndcg@10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>No log</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.838726</td>\n",
       "      <td>0.838726</td>\n",
       "      <td>0.878283</td>\n",
       "      <td>0.568988</td>\n",
       "      <td>0.568988</td>\n",
       "      <td>0.595057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.397400</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.806345</td>\n",
       "      <td>0.832417</td>\n",
       "      <td>0.875308</td>\n",
       "      <td>0.568988</td>\n",
       "      <td>0.568988</td>\n",
       "      <td>0.595057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.338600</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.839536</td>\n",
       "      <td>0.859417</td>\n",
       "      <td>0.891746</td>\n",
       "      <td>0.568988</td>\n",
       "      <td>0.568988</td>\n",
       "      <td>0.595057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.343900</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.837167</td>\n",
       "      <td>0.858000</td>\n",
       "      <td>0.889666</td>\n",
       "      <td>0.568988</td>\n",
       "      <td>0.568988</td>\n",
       "      <td>0.595057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.246700</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.799464</td>\n",
       "      <td>0.830179</td>\n",
       "      <td>0.875662</td>\n",
       "      <td>0.568988</td>\n",
       "      <td>0.568988</td>\n",
       "      <td>0.595057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.154600</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.809155</td>\n",
       "      <td>0.837190</td>\n",
       "      <td>0.880746</td>\n",
       "      <td>0.568988</td>\n",
       "      <td>0.568988</td>\n",
       "      <td>0.595057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.156500</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.817738</td>\n",
       "      <td>0.841905</td>\n",
       "      <td>0.881764</td>\n",
       "      <td>0.568988</td>\n",
       "      <td>0.568988</td>\n",
       "      <td>0.595057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21000</td>\n",
       "      <td>0.143800</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.804155</td>\n",
       "      <td>0.834095</td>\n",
       "      <td>0.877099</td>\n",
       "      <td>0.568988</td>\n",
       "      <td>0.568988</td>\n",
       "      <td>0.595057</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    }
   ],
   "source": [
    "train_batch_size = 1\n",
    "max_length = 512\n",
    "model_to_finetune = \"Alibaba-NLP/gte-reranker-modernbert-base\"\n",
    "\n",
    "exp_runner = ExperimentRunner(\n",
    "    model_to_finetune,\n",
    "    train_batch_size,\n",
    "    num_epochs,\n",
    "    max_length,\n",
    "    experiment_name=experiment_name\n",
    ")\n",
    "\n",
    "exp_runner.run_experiment(hard_train_dataset, hard_eval_dataset, hard_eval_dataset_evaluator, num_hard_negatives, loss=loss, adaptive_learning_rate=adaptive_learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15f90a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `margin` parameter is deprecated. Use the `absolute_margin` and/or `relative_margin` parameter instead. Setting `absolute_margin` to `0.05`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12842 unique queries out of 12853 total queries.\n",
      "Found an average of 1.001 positives per query.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 109/109 [00:41<00:00,  2.65it/s]\n",
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 201/201 [00:09<00:00, 21.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric       Positive       Negative     Difference\n",
      "Count          12,853         15,746               \n",
      "Mean           0.8195         0.7637         0.0914\n",
      "Median         0.8329         0.7830         0.0814\n",
      "Std            0.0826         0.0427         0.0388\n",
      "Min            0.3809         0.5047        -0.0924\n",
      "25%            0.7696         0.7428         0.0570\n",
      "50%            0.8329         0.7830         0.0814\n",
      "75%            0.8834         0.7956         0.1156\n",
      "Max            0.9881         0.7998         0.2959\n",
      "Skipped 561,379 potential negatives (42.44%) due to the absolute_margin of 0.05.\n",
      "Skipped 146,681 potential negatives (19.27%) due to the max_score of 0.8.\n",
      "Could not find enough negatives for 9960 samples (38.75%). Consider adjusting the range_max, range_min, absolute_margin and max_score parameters if you'd like to find more valid negatives.\n",
      "======================\n",
      "Setting range_max to 4 based on the provided parameters.\n",
      "Found 1399 unique queries out of 1400 total queries.\n",
      "Found an average of 1.001 positives per query.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 121/121 [00:45<00:00,  2.64it/s]\n",
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:00<00:00, 22.23it/s]\n",
      "When using `include_positives=True`, `output_format` will be set to `\"n-tuple\"` to ensure that the ranking order is preserved.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric       Positive       Negative     Difference\n",
      "Count           1,400          2,800               \n",
      "Mean           0.8219         0.8132         0.0087\n",
      "Median         0.8323         0.8191         0.0069\n",
      "Std            0.0783         0.0501         0.0625\n",
      "Min            0.4977         0.5707        -0.1856\n",
      "25%            0.7717         0.7844        -0.0299\n",
      "50%            0.8323         0.8192         0.0069\n",
      "75%            0.8846         0.8478         0.0478\n",
      "Max            0.9681         0.9451         0.2158\n",
      "======================\n",
      "Setting range_max to 4 based on the provided parameters.\n",
      "Found 1399 unique queries out of 1400 total queries.\n",
      "Found an average of 1.001 positives per query.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 121/121 [00:45<00:00,  2.64it/s]\n",
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:00<00:00, 22.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric       Positive       Negative     Difference\n",
      "Count           1,400          2,800               \n",
      "Mean           0.8219         0.8294        -0.0075\n",
      "Median         0.8323         0.8332        -0.0000\n",
      "Std            0.0783         0.0559         0.0501\n",
      "Min            0.4977         0.5787        -0.1856\n",
      "25%            0.7717         0.7953        -0.0299\n",
      "50%            0.8323         0.8332        -0.0000\n",
      "75%            0.8846         0.8678         0.0004\n",
      "Max            0.9681         0.9681         0.1977\n",
      "Eval steps: 3000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='15768' max='15768' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15768/15768 1:05:54, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Dev Set Map</th>\n",
       "      <th>Dev Set Mrr@10</th>\n",
       "      <th>Dev Set Ndcg@10</th>\n",
       "      <th>Dev Set Base Map</th>\n",
       "      <th>Dev Set Base Mrr@10</th>\n",
       "      <th>Dev Set Base Ndcg@10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.872254</td>\n",
       "      <td>0.874524</td>\n",
       "      <td>0.874524</td>\n",
       "      <td>0.906698</td>\n",
       "      <td>0.543929</td>\n",
       "      <td>0.543929</td>\n",
       "      <td>0.554684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.226200</td>\n",
       "      <td>2.880633</td>\n",
       "      <td>0.858929</td>\n",
       "      <td>0.858929</td>\n",
       "      <td>0.895107</td>\n",
       "      <td>0.543929</td>\n",
       "      <td>0.543929</td>\n",
       "      <td>0.554684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.095300</td>\n",
       "      <td>3.151024</td>\n",
       "      <td>0.857024</td>\n",
       "      <td>0.857024</td>\n",
       "      <td>0.893594</td>\n",
       "      <td>0.543929</td>\n",
       "      <td>0.543929</td>\n",
       "      <td>0.554684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.051500</td>\n",
       "      <td>3.207670</td>\n",
       "      <td>0.863929</td>\n",
       "      <td>0.863929</td>\n",
       "      <td>0.898713</td>\n",
       "      <td>0.543929</td>\n",
       "      <td>0.543929</td>\n",
       "      <td>0.554684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.037800</td>\n",
       "      <td>3.293346</td>\n",
       "      <td>0.866310</td>\n",
       "      <td>0.866310</td>\n",
       "      <td>0.900465</td>\n",
       "      <td>0.543929</td>\n",
       "      <td>0.543929</td>\n",
       "      <td>0.554684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.018200</td>\n",
       "      <td>3.282988</td>\n",
       "      <td>0.867024</td>\n",
       "      <td>0.867024</td>\n",
       "      <td>0.901009</td>\n",
       "      <td>0.543929</td>\n",
       "      <td>0.543929</td>\n",
       "      <td>0.554684</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    }
   ],
   "source": [
    "num_hard_negatives = 2\n",
    "num_hard_negatives_eval = 2\n",
    "\n",
    "hard_train_dataset, hard_eval_dataset, hard_eval_dataset_evaluator = get_hard_negatives(\n",
    "    embedding_model_hard_negatives, \n",
    "    num_hard_negatives=num_hard_negatives, \n",
    "    num_hard_negatives_eval=num_hard_negatives_eval, \n",
    "    train_dataset=train_dataset, \n",
    "    dev_dataset=dev_dataset, \n",
    "    df_full=df_full, \n",
    "    loss=loss, \n",
    "    batch_size=64,\n",
    "    stricter_hard_negatives=stricter_hard_negatives\n",
    "    )\n",
    "\n",
    "train_batch_size = 1\n",
    "max_length = 512\n",
    "model_to_finetune = \"Alibaba-NLP/gte-multilingual-reranker-base\"\n",
    "\n",
    "exp_runner = ExperimentRunner(\n",
    "    model_to_finetune,\n",
    "    train_batch_size,\n",
    "    num_epochs,\n",
    "    max_length,\n",
    "    experiment_name=experiment_name\n",
    ")\n",
    "exp_runner.run_experiment(hard_train_dataset, hard_eval_dataset, hard_eval_dataset_evaluator, num_hard_negatives, trust_remote_code=True, loss=loss, adaptive_learning_rate=adaptive_learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da6057e",
   "metadata": {},
   "source": [
    "### Reranking with finetuned models\n",
    "\n",
    "Now, after finetuning the models, we are able to run the inference with the newly trained models. Since we are making use of computationally intensive rerankers, we first need to rank the results with an efficient first-stage ranker. We use our best performing BM25 for this purpose. We feed the top 30 documents according to BM25 into the reranking model, save the predictions and print the evaluation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2afedbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reranking: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1400/1400 [06:42<00:00,  3.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 1\n",
      "Number of queries in top 1: 980\n",
      "Number of queries not in top 1: 420\n",
      "k = 5\n",
      "Number of queries in top 5: 1113\n",
      "Number of queries not in top 5: 287\n",
      "k = 10\n",
      "Number of queries in top 10: 1123\n",
      "Number of queries not in top 10: 277\n",
      "Evaluation results: {1: 0.7, 5: 0.7398095238095238, 10: 0.7407922335600907}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df_query_single = experiment_single_bm25(df_collection, df_query_dev, stemmer=stemmer, k=30)\n",
    "model_name = f\"models/gte-reranker-modernbert-base-finetuned{experiment_name}\"\n",
    "tokenizer, model = initialize_reranker(model_name)\n",
    "df_query = rerank_with_alibaba(df_query_single, df_collection, tokenizer, model, k=10, batch_size=100)\n",
    "df_query.to_parquet(f'data/reranked_results_alibaba_finetuned{experiment_name}.parquet')\n",
    "results = evaluate_reranked_results(df_query)\n",
    "print(f\"Evaluation results: {results}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d1871660",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reranking: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1400/1400 [06:03<00:00,  3.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 1\n",
      "Number of queries in top 1: 890\n",
      "Number of queries not in top 1: 510\n",
      "k = 5\n",
      "Number of queries in top 5: 1088\n",
      "Number of queries not in top 5: 312\n",
      "k = 10\n",
      "Number of queries in top 10: 1118\n",
      "Number of queries not in top 10: 282\n",
      "Evaluation results: {1: 0.6357142857142857, 5: 0.693952380952381, 10: 0.6968236961451246}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df_query_dev_single = experiment_single_bm25(df_collection, df_query_dev, stemmer=stemmer, k=30)\n",
    "model_name = f\"models/gte-multilingual-reranker-base-finetuned{experiment_name}\"\n",
    "tokenizer, model = initialize_reranker(model_name)\n",
    "df_query = rerank_with_alibaba(df_query_dev_single, df_collection, tokenizer, model, k=10, batch_size=100)\n",
    "df_query.to_parquet(f'data/reranked_results_alibaba_multilingual_finetuned{experiment_name}.parquet')\n",
    "results = evaluate_reranked_results(df_query)\n",
    "print(f\"Evaluation results: {results}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9f615c0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reranking: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1400/1400 [02:27<00:00,  9.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 1\n",
      "Number of queries in top 1: 874\n",
      "Number of queries not in top 1: 526\n",
      "k = 5\n",
      "Number of queries in top 5: 1036\n",
      "Number of queries not in top 5: 364\n",
      "k = 10\n",
      "Number of queries in top 10: 1088\n",
      "Number of queries not in top 10: 312\n",
      "Evaluation results: {1: 0.6242857142857143, 5: 0.6715, 10: 0.6765413832199546}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df_query_dev_single = experiment_single_bm25(df_collection, df_query_dev, stemmer=stemmer, k=30)\n",
    "model_name = f\"models/ms-marco-MiniLM-L12-v2-finetuned{experiment_name}\"\n",
    "tokenizer, model = initialize_reranker(model_name)\n",
    "df_query = rerank_with_alibaba(df_query_dev_single, df_collection, tokenizer, model, k=10, batch_size=100)\n",
    "df_query.to_parquet(f\"data/reranked_results_miniLM12_finetuned{experiment_name}.parquet\")\n",
    "results = evaluate_reranked_results(df_query)\n",
    "print(f\"Evaluation results: {results}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1726416c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reranking: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1400/1400 [01:45<00:00, 13.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 1\n",
      "Number of queries in top 1: 861\n",
      "Number of queries not in top 1: 539\n",
      "k = 5\n",
      "Number of queries in top 5: 1037\n",
      "Number of queries not in top 5: 363\n",
      "k = 10\n",
      "Number of queries in top 10: 1090\n",
      "Number of queries not in top 10: 310\n",
      "Evaluation results: {1: 0.615, 5: 0.6652380952380952, 10: 0.6704767573696144}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df_query_dev_single = experiment_single_bm25(df_collection, df_query_dev, stemmer=stemmer, k=30)\n",
    "model_name = f\"models/ms-marco-MiniLM-L6-v2-finetuned{experiment_name}\"\n",
    "tokenizer, model = initialize_reranker(model_name)\n",
    "df_query = rerank_with_alibaba(df_query_dev_single, df_collection, tokenizer, model, k=10, batch_size=100)\n",
    "df_query.to_parquet(f\"data/reranked_results_miniLM6_finetuned.parquet{experiment_name}\")\n",
    "results = evaluate_reranked_results(df_query)\n",
    "print(f\"Evaluation results: {results}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e1bc22bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reranking: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1400/1400 [01:09<00:00, 20.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 1\n",
      "Number of queries in top 1: 794\n",
      "Number of queries not in top 1: 606\n",
      "k = 5\n",
      "Number of queries in top 5: 995\n",
      "Number of queries not in top 5: 405\n",
      "k = 10\n",
      "Number of queries in top 10: 1059\n",
      "Number of queries not in top 10: 341\n",
      "Evaluation results: {1: 0.5671428571428572, 5: 0.6222619047619047, 10: 0.6285807823129252}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df_query_dev_single = experiment_single_bm25(df_collection, df_query_dev, stemmer=stemmer, k=30)\n",
    "model_name = f\"models/ms-marco-TinyBERT-L2-v2-finetuned{experiment_name}\"\n",
    "tokenizer, model = initialize_reranker(model_name)\n",
    "df_query = rerank_with_alibaba(df_query_dev_single, df_collection, tokenizer, model, k=10, batch_size=100)\n",
    "df_query.to_parquet(f\"data/reranked_results_tinyBERT_finetuned{experiment_name}.parquet\")\n",
    "results = evaluate_reranked_results(df_query)\n",
    "print(f\"Evaluation results: {results}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2b096aa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reranking: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1400/1400 [05:38<00:00,  4.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 1\n",
      "Number of queries in top 1: 872\n",
      "Number of queries not in top 1: 528\n",
      "k = 5\n",
      "Number of queries in top 5: 1055\n",
      "Number of queries not in top 5: 345\n",
      "k = 10\n",
      "Number of queries in top 10: 1106\n",
      "Number of queries not in top 10: 294\n",
      "Evaluation results: {1: 0.6228571428571429, 5: 0.6750357142857143, 10: 0.6799353741496599}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df_query_dev_single = experiment_single_bm25(df_collection, df_query_dev, stemmer=stemmer, k=30)\n",
    "model_name = f\"models/ms-marco-electra-base-finetuned{experiment_name}\"\n",
    "tokenizer, model = initialize_reranker(model_name)\n",
    "df_query = rerank_with_alibaba(df_query_dev_single, df_collection, tokenizer, model, k=10, batch_size=50, max_length=None )\n",
    "df_query.to_parquet(f\"data/reranked_results_electra_finetuned.parquet{experiment_name}\")\n",
    "results = evaluate_reranked_results(df_query)\n",
    "print(f\"Evaluation results: {results}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a82aa3",
   "metadata": {},
   "source": [
    "## Predictions on the testset\n",
    "We use our best performing finetuned model and let it rerank the top 1k BM25 documents. Since the finetuned model is significantly better than BM25, feeding more documents into the reranker should lead to a better performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b80580",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reranking: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1446/1446 [3:59:53<00:00,  9.95s/it]  \n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'cord_uid'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/core/indexes/base.py:3805\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3804\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3805\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3806\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'cord_uid'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m df_query = rerank_with_alibaba(df_query_single, df_collection, tokenizer, model, k=\u001b[32m10\u001b[39m, batch_size=\u001b[32m256\u001b[39m)\n\u001b[32m      5\u001b[39m df_query.to_parquet(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mdata/reranked_results_alibaba_finetuned\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexperiment_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_testset.parquet\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m results = \u001b[43mevaluate_reranked_results\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_query\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEvaluation results: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresults\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 2\u001b[39m, in \u001b[36mevaluate_reranked_results\u001b[39m\u001b[34m(df_query, col_gold, col_pred, list_k)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mevaluate_reranked_results\u001b[39m(df_query, col_gold=\u001b[33m'\u001b[39m\u001b[33mcord_uid\u001b[39m\u001b[33m'\u001b[39m, col_pred=\u001b[33m'\u001b[39m\u001b[33mreranked_topk\u001b[39m\u001b[33m'\u001b[39m, list_k=[\u001b[32m1\u001b[39m, \u001b[32m5\u001b[39m, \u001b[32m10\u001b[39m]):\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_performance_mrr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcol_gold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcol_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlist_k\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 4\u001b[39m, in \u001b[36mget_performance_mrr\u001b[39m\u001b[34m(data, col_gold, col_pred, list_k)\u001b[39m\n\u001b[32m      2\u001b[39m d_performance = {}\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m list_k:\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     data[\u001b[33m\"\u001b[39m\u001b[33min_topx\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m/\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol_pred\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol_gold\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol_gold\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol_pred\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m     d_performance[k] = data[\u001b[33m\"\u001b[39m\u001b[33min_topx\u001b[39m\u001b[33m\"\u001b[39m].mean()\n\u001b[32m      6\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;250m \u001b[39m\u001b[38;5;132;01m= }\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/core/frame.py:10374\u001b[39m, in \u001b[36mDataFrame.apply\u001b[39m\u001b[34m(self, func, axis, raw, result_type, args, by_row, engine, engine_kwargs, **kwargs)\u001b[39m\n\u001b[32m  10360\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapply\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[32m  10362\u001b[39m op = frame_apply(\n\u001b[32m  10363\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m  10364\u001b[39m     func=func,\n\u001b[32m   (...)\u001b[39m\u001b[32m  10372\u001b[39m     kwargs=kwargs,\n\u001b[32m  10373\u001b[39m )\n\u001b[32m> \u001b[39m\u001b[32m10374\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m.__finalize__(\u001b[38;5;28mself\u001b[39m, method=\u001b[33m\"\u001b[39m\u001b[33mapply\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/core/apply.py:916\u001b[39m, in \u001b[36mFrameApply.apply\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    913\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.raw:\n\u001b[32m    914\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.apply_raw(engine=\u001b[38;5;28mself\u001b[39m.engine, engine_kwargs=\u001b[38;5;28mself\u001b[39m.engine_kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m916\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/core/apply.py:1063\u001b[39m, in \u001b[36mFrameApply.apply_standard\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1061\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m   1062\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.engine == \u001b[33m\"\u001b[39m\u001b[33mpython\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m1063\u001b[39m         results, res_index = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapply_series_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1064\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1065\u001b[39m         results, res_index = \u001b[38;5;28mself\u001b[39m.apply_series_numba()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/core/apply.py:1081\u001b[39m, in \u001b[36mFrameApply.apply_series_generator\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1078\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[33m\"\u001b[39m\u001b[33mmode.chained_assignment\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m   1079\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[32m   1080\u001b[39m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1081\u001b[39m         results[i] = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1082\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[32m   1083\u001b[39m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[32m   1084\u001b[39m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[32m   1085\u001b[39m             results[i] = results[i].copy(deep=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 4\u001b[39m, in \u001b[36mget_performance_mrr.<locals>.<lambda>\u001b[39m\u001b[34m(x)\u001b[39m\n\u001b[32m      2\u001b[39m d_performance = {}\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m list_k:\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     data[\u001b[33m\"\u001b[39m\u001b[33min_topx\u001b[39m\u001b[33m\"\u001b[39m] = data.apply(\u001b[38;5;28;01mlambda\u001b[39;00m x: (\u001b[32m1\u001b[39m/([i \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m x[col_pred][:k]].index(x[col_gold]) + \u001b[32m1\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol_gold\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;129;01min\u001b[39;00m [i \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m x[col_pred][:k]] \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m0\u001b[39m), axis=\u001b[32m1\u001b[39m)\n\u001b[32m      5\u001b[39m     d_performance[k] = data[\u001b[33m\"\u001b[39m\u001b[33min_topx\u001b[39m\u001b[33m\"\u001b[39m].mean()\n\u001b[32m      6\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;250m \u001b[39m\u001b[38;5;132;01m= }\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/core/series.py:1121\u001b[39m, in \u001b[36mSeries.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   1118\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._values[key]\n\u001b[32m   1120\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[32m-> \u001b[39m\u001b[32m1121\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1123\u001b[39m \u001b[38;5;66;03m# Convert generator to list before going through hashable part\u001b[39;00m\n\u001b[32m   1124\u001b[39m \u001b[38;5;66;03m# (We will iterate through the generator there to check for slices)\u001b[39;00m\n\u001b[32m   1125\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/core/series.py:1237\u001b[39m, in \u001b[36mSeries._get_value\u001b[39m\u001b[34m(self, label, takeable)\u001b[39m\n\u001b[32m   1234\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._values[label]\n\u001b[32m   1236\u001b[39m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1237\u001b[39m loc = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1239\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[32m   1240\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._values[loc]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/core/indexes/base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3807\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3808\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3809\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3810\u001b[39m     ):\n\u001b[32m   3811\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3814\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3815\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3816\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3817\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'cord_uid'"
     ]
    }
   ],
   "source": [
    "df_query_single = experiment_single_bm25(df_collection, df_query_test, stemmer=stemmer, k=1000)\n",
    "model_name = f\"models/gte-reranker-modernbert-base-finetuned{experiment_name}\"\n",
    "tokenizer, model = initialize_reranker(model_name)\n",
    "df_query = rerank_with_alibaba(df_query_single, df_collection, tokenizer, model, k=10, batch_size=256)\n",
    "df_query.to_parquet(f'data/reranked_results_alibaba_finetuned{experiment_name}_testset.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5deb60a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_query['preds'] = df_query['reranked_topk'].apply(lambda x: x[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "22979c02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>bm25_topk</th>\n",
       "      <th>reranked_topk</th>\n",
       "      <th>reranked_docs</th>\n",
       "      <th>reranked_scores</th>\n",
       "      <th>preds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>A recent research study published yesterday cl...</td>\n",
       "      <td>[bttme4wn, 8fkzc445, nswj8x43, uifnjio5, j0bu0...</td>\n",
       "      <td>[x4zuv4jo, j0bu0upi, tpic8ddl, qgwu9fsk, 1qvkl...</td>\n",
       "      <td>[x4zuv4jo, j0bu0upi, tpic8ddl, qgwu9fsk, 1qvkl...</td>\n",
       "      <td>[6.66796875, 5.98046875, 5.875, 4.734375, 3.42...</td>\n",
       "      <td>[x4zuv4jo, j0bu0upi, tpic8ddl, qgwu9fsk, 1qvkl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>\"We should track the long-term effects of thes...</td>\n",
       "      <td>[evf9nz05, 65n6p550, f6vau5s6, mnsm39a8, 5vp2r...</td>\n",
       "      <td>[evf9nz05, 7keaoi4d, vtagfrds, ot1uz6vc, mnsm3...</td>\n",
       "      <td>[evf9nz05, 7keaoi4d, vtagfrds, ot1uz6vc, mnsm3...</td>\n",
       "      <td>[25.59375, -6.83984375, -8.2265625, -9.546875,...</td>\n",
       "      <td>[evf9nz05, 7keaoi4d, vtagfrds, ot1uz6vc, mnsm3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>the agony of \"long haul\" covid-19 symptoms.</td>\n",
       "      <td>[376x58k1, 00ugdhvf, e6m1tkrs, ofavwj52, t2gxk...</td>\n",
       "      <td>[2kd89h12, m3m2n3fw, 00ugdhvf, ky5env7t, 82y56...</td>\n",
       "      <td>[2kd89h12, m3m2n3fw, 00ugdhvf, ky5env7t, 82y56...</td>\n",
       "      <td>[24.421875, 23.828125, 20.203125, 14.3828125, ...</td>\n",
       "      <td>[2kd89h12, m3m2n3fw, 00ugdhvf, ky5env7t, 82y56...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Home and online monitoring and assessment of b...</td>\n",
       "      <td>[ru2ty1y9, wabd3b9z, enlj85zc, bnkggl84, 609b8...</td>\n",
       "      <td>[ru2ty1y9, wabd3b9z, ir874dkj, mim419b8, oqd5o...</td>\n",
       "      <td>[ru2ty1y9, wabd3b9z, ir874dkj, mim419b8, oqd5o...</td>\n",
       "      <td>[36.71875, -6.00390625, -10.2578125, -14.85156...</td>\n",
       "      <td>[ru2ty1y9, wabd3b9z, ir874dkj, mim419b8, oqd5o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>it may be a long one, folks! to avoid exceedin...</td>\n",
       "      <td>[f5p37j7g, nzat41wu, jnz5by5w, n0uy6hd2, g283l...</td>\n",
       "      <td>[f5p37j7g, nzat41wu, 9mact9br, l70ghm8g, zsra2...</td>\n",
       "      <td>[f5p37j7g, nzat41wu, 9mact9br, l70ghm8g, zsra2...</td>\n",
       "      <td>[22.875, 16.796875, -2.7890625, -5.921875, -10...</td>\n",
       "      <td>[f5p37j7g, nzat41wu, 9mact9br, l70ghm8g, zsra2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1441</th>\n",
       "      <td>1442</td>\n",
       "      <td>Clinical presentations, predisposing factors, ...</td>\n",
       "      <td>[ohyvuybc, 06fwhyac, x64zft78, 18b6ikq3, 5rpd8...</td>\n",
       "      <td>[ohyvuybc, 06fwhyac, x64zft78, vq9m9m94, 18b6i...</td>\n",
       "      <td>[ohyvuybc, 06fwhyac, x64zft78, vq9m9m94, 18b6i...</td>\n",
       "      <td>[33.53125, 20.203125, 14.453125, 12.9296875, 4...</td>\n",
       "      <td>[ohyvuybc, 06fwhyac, x64zft78, vq9m9m94, 18b6i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1442</th>\n",
       "      <td>1443</td>\n",
       "      <td>risk factors for post-covid-19 condition in ho...</td>\n",
       "      <td>[pwb7rw89, 32ut5vr7, ce1a9k8b, 5dk3pslc, 8ymu4...</td>\n",
       "      <td>[32ut5vr7, pwb7rw89, hqjphv5g, dh3zqjbz, dmqk2...</td>\n",
       "      <td>[32ut5vr7, pwb7rw89, hqjphv5g, dh3zqjbz, dmqk2...</td>\n",
       "      <td>[30.890625, 7.5, 2.689453125, -1.810546875, -7...</td>\n",
       "      <td>[32ut5vr7, pwb7rw89, hqjphv5g, dh3zqjbz, dmqk2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1443</th>\n",
       "      <td>1444</td>\n",
       "      <td>do not assume children are less susceptible.</td>\n",
       "      <td>[st67fvgk, 9rczqcaz, wtxhbzr9, 7ru6tapp, du8wm...</td>\n",
       "      <td>[9rczqcaz, 35xqlryc, uo3ww8j4, t3b2adct, st67f...</td>\n",
       "      <td>[9rczqcaz, 35xqlryc, uo3ww8j4, t3b2adct, st67f...</td>\n",
       "      <td>[19.140625, 14.7578125, 11.8046875, 10.65625, ...</td>\n",
       "      <td>[9rczqcaz, 35xqlryc, uo3ww8j4, t3b2adct, st67f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1444</th>\n",
       "      <td>1445</td>\n",
       "      <td>eurosurveillance | estimated number of fatalit...</td>\n",
       "      <td>[leg5ntvu, bnhwbaqj, qlejjw9s, 6l3coibe, 2cwvg...</td>\n",
       "      <td>[leg5ntvu, o1xsjx2p, 79xnx9gr, bnhwbaqj, l6lhm...</td>\n",
       "      <td>[leg5ntvu, o1xsjx2p, 79xnx9gr, bnhwbaqj, l6lhm...</td>\n",
       "      <td>[36.78125, -12.453125, -14.1796875, -15.617187...</td>\n",
       "      <td>[leg5ntvu, o1xsjx2p, 79xnx9gr, bnhwbaqj, l6lhm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1445</th>\n",
       "      <td>1446</td>\n",
       "      <td>breaking update: hydroxychloroquine still does...</td>\n",
       "      <td>[gk3wr6s1, y33jkc01, fcdwitxy, no45mgyd, cq5z8...</td>\n",
       "      <td>[gk3wr6s1, p699a0g2, otp1atui, wk61uyrt, dt7hi...</td>\n",
       "      <td>[gk3wr6s1, p699a0g2, otp1atui, wk61uyrt, dt7hi...</td>\n",
       "      <td>[6.58203125, 3.212890625, 0.52880859375, -1.02...</td>\n",
       "      <td>[gk3wr6s1, p699a0g2, otp1atui, wk61uyrt, dt7hi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1446 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      post_id                                         tweet_text  \\\n",
       "0           1  A recent research study published yesterday cl...   \n",
       "1           2  \"We should track the long-term effects of thes...   \n",
       "2           3        the agony of \"long haul\" covid-19 symptoms.   \n",
       "3           4  Home and online monitoring and assessment of b...   \n",
       "4           5  it may be a long one, folks! to avoid exceedin...   \n",
       "...       ...                                                ...   \n",
       "1441     1442  Clinical presentations, predisposing factors, ...   \n",
       "1442     1443  risk factors for post-covid-19 condition in ho...   \n",
       "1443     1444       do not assume children are less susceptible.   \n",
       "1444     1445  eurosurveillance | estimated number of fatalit...   \n",
       "1445     1446  breaking update: hydroxychloroquine still does...   \n",
       "\n",
       "                                              bm25_topk  \\\n",
       "0     [bttme4wn, 8fkzc445, nswj8x43, uifnjio5, j0bu0...   \n",
       "1     [evf9nz05, 65n6p550, f6vau5s6, mnsm39a8, 5vp2r...   \n",
       "2     [376x58k1, 00ugdhvf, e6m1tkrs, ofavwj52, t2gxk...   \n",
       "3     [ru2ty1y9, wabd3b9z, enlj85zc, bnkggl84, 609b8...   \n",
       "4     [f5p37j7g, nzat41wu, jnz5by5w, n0uy6hd2, g283l...   \n",
       "...                                                 ...   \n",
       "1441  [ohyvuybc, 06fwhyac, x64zft78, 18b6ikq3, 5rpd8...   \n",
       "1442  [pwb7rw89, 32ut5vr7, ce1a9k8b, 5dk3pslc, 8ymu4...   \n",
       "1443  [st67fvgk, 9rczqcaz, wtxhbzr9, 7ru6tapp, du8wm...   \n",
       "1444  [leg5ntvu, bnhwbaqj, qlejjw9s, 6l3coibe, 2cwvg...   \n",
       "1445  [gk3wr6s1, y33jkc01, fcdwitxy, no45mgyd, cq5z8...   \n",
       "\n",
       "                                          reranked_topk  \\\n",
       "0     [x4zuv4jo, j0bu0upi, tpic8ddl, qgwu9fsk, 1qvkl...   \n",
       "1     [evf9nz05, 7keaoi4d, vtagfrds, ot1uz6vc, mnsm3...   \n",
       "2     [2kd89h12, m3m2n3fw, 00ugdhvf, ky5env7t, 82y56...   \n",
       "3     [ru2ty1y9, wabd3b9z, ir874dkj, mim419b8, oqd5o...   \n",
       "4     [f5p37j7g, nzat41wu, 9mact9br, l70ghm8g, zsra2...   \n",
       "...                                                 ...   \n",
       "1441  [ohyvuybc, 06fwhyac, x64zft78, vq9m9m94, 18b6i...   \n",
       "1442  [32ut5vr7, pwb7rw89, hqjphv5g, dh3zqjbz, dmqk2...   \n",
       "1443  [9rczqcaz, 35xqlryc, uo3ww8j4, t3b2adct, st67f...   \n",
       "1444  [leg5ntvu, o1xsjx2p, 79xnx9gr, bnhwbaqj, l6lhm...   \n",
       "1445  [gk3wr6s1, p699a0g2, otp1atui, wk61uyrt, dt7hi...   \n",
       "\n",
       "                                          reranked_docs  \\\n",
       "0     [x4zuv4jo, j0bu0upi, tpic8ddl, qgwu9fsk, 1qvkl...   \n",
       "1     [evf9nz05, 7keaoi4d, vtagfrds, ot1uz6vc, mnsm3...   \n",
       "2     [2kd89h12, m3m2n3fw, 00ugdhvf, ky5env7t, 82y56...   \n",
       "3     [ru2ty1y9, wabd3b9z, ir874dkj, mim419b8, oqd5o...   \n",
       "4     [f5p37j7g, nzat41wu, 9mact9br, l70ghm8g, zsra2...   \n",
       "...                                                 ...   \n",
       "1441  [ohyvuybc, 06fwhyac, x64zft78, vq9m9m94, 18b6i...   \n",
       "1442  [32ut5vr7, pwb7rw89, hqjphv5g, dh3zqjbz, dmqk2...   \n",
       "1443  [9rczqcaz, 35xqlryc, uo3ww8j4, t3b2adct, st67f...   \n",
       "1444  [leg5ntvu, o1xsjx2p, 79xnx9gr, bnhwbaqj, l6lhm...   \n",
       "1445  [gk3wr6s1, p699a0g2, otp1atui, wk61uyrt, dt7hi...   \n",
       "\n",
       "                                        reranked_scores  \\\n",
       "0     [6.66796875, 5.98046875, 5.875, 4.734375, 3.42...   \n",
       "1     [25.59375, -6.83984375, -8.2265625, -9.546875,...   \n",
       "2     [24.421875, 23.828125, 20.203125, 14.3828125, ...   \n",
       "3     [36.71875, -6.00390625, -10.2578125, -14.85156...   \n",
       "4     [22.875, 16.796875, -2.7890625, -5.921875, -10...   \n",
       "...                                                 ...   \n",
       "1441  [33.53125, 20.203125, 14.453125, 12.9296875, 4...   \n",
       "1442  [30.890625, 7.5, 2.689453125, -1.810546875, -7...   \n",
       "1443  [19.140625, 14.7578125, 11.8046875, 10.65625, ...   \n",
       "1444  [36.78125, -12.453125, -14.1796875, -15.617187...   \n",
       "1445  [6.58203125, 3.212890625, 0.52880859375, -1.02...   \n",
       "\n",
       "                                                  preds  \n",
       "0     [x4zuv4jo, j0bu0upi, tpic8ddl, qgwu9fsk, 1qvkl...  \n",
       "1     [evf9nz05, 7keaoi4d, vtagfrds, ot1uz6vc, mnsm3...  \n",
       "2     [2kd89h12, m3m2n3fw, 00ugdhvf, ky5env7t, 82y56...  \n",
       "3     [ru2ty1y9, wabd3b9z, ir874dkj, mim419b8, oqd5o...  \n",
       "4     [f5p37j7g, nzat41wu, 9mact9br, l70ghm8g, zsra2...  \n",
       "...                                                 ...  \n",
       "1441  [ohyvuybc, 06fwhyac, x64zft78, vq9m9m94, 18b6i...  \n",
       "1442  [32ut5vr7, pwb7rw89, hqjphv5g, dh3zqjbz, dmqk2...  \n",
       "1443  [9rczqcaz, 35xqlryc, uo3ww8j4, t3b2adct, st67f...  \n",
       "1444  [leg5ntvu, o1xsjx2p, 79xnx9gr, bnhwbaqj, l6lhm...  \n",
       "1445  [gk3wr6s1, p699a0g2, otp1atui, wk61uyrt, dt7hi...  \n",
       "\n",
       "[1446 rows x 7 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48eb15a5",
   "metadata": {},
   "source": [
    "Ultimately we save the predictions into the format required by the competition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f8229323",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_query[['post_id', 'preds']].to_csv('predictions.tsv', index=None, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d1d6a4f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'_bge-small-en-v1.5_epochs2_lambdaloss_learningrate'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_name"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
