{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "58e2003b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import bm25s\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from tqdm import tqdm\n",
    "from mxbai_rerank import MxbaiRerankV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d91b9f90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce RTX 3070'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "28ddfe89",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path('data/')\n",
    "\n",
    "collection_data_path = data_path / 'subtask4b_collection_data.pkl' \n",
    "query_dev_data_path = data_path / 'subtask4b_query_tweets_dev.tsv'\n",
    "query_train_data_path = data_path / 'subtask4b_query_tweets_train.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6cfb2779",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cord_uid</th>\n",
       "      <th>source_x</th>\n",
       "      <th>title</th>\n",
       "      <th>doi</th>\n",
       "      <th>pmcid</th>\n",
       "      <th>pubmed_id</th>\n",
       "      <th>license</th>\n",
       "      <th>abstract</th>\n",
       "      <th>publish_time</th>\n",
       "      <th>authors</th>\n",
       "      <th>journal</th>\n",
       "      <th>mag_id</th>\n",
       "      <th>who_covidence_id</th>\n",
       "      <th>arxiv_id</th>\n",
       "      <th>label</th>\n",
       "      <th>time</th>\n",
       "      <th>timet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>umvrwgaw</td>\n",
       "      <td>PMC</td>\n",
       "      <td>Professional and Home-Made Face Masks Reduce E...</td>\n",
       "      <td>10.1371/journal.pone.0002618</td>\n",
       "      <td>PMC2440799</td>\n",
       "      <td>18612429</td>\n",
       "      <td>cc-by</td>\n",
       "      <td>BACKGROUND: Governments are preparing for a po...</td>\n",
       "      <td>2008-07-09</td>\n",
       "      <td>van der Sande, Marianne; Teunis, Peter; Sabel,...</td>\n",
       "      <td>PLoS One</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>umvrwgaw</td>\n",
       "      <td>2008-07-09</td>\n",
       "      <td>1215561600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611</th>\n",
       "      <td>spiud6ok</td>\n",
       "      <td>PMC</td>\n",
       "      <td>The Failure of R (0)</td>\n",
       "      <td>10.1155/2011/527610</td>\n",
       "      <td>PMC3157160</td>\n",
       "      <td>21860658</td>\n",
       "      <td>cc-by</td>\n",
       "      <td>The basic reproductive ratio, R (0), is one of...</td>\n",
       "      <td>2011-08-16</td>\n",
       "      <td>Li, Jing; Blakeley, Daniel; Smith?, Robert J.</td>\n",
       "      <td>Comput Math Methods Med</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>spiud6ok</td>\n",
       "      <td>2011-08-16</td>\n",
       "      <td>1313452800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>918</th>\n",
       "      <td>aclzp3iy</td>\n",
       "      <td>PMC</td>\n",
       "      <td>Pulmonary sequelae in a patient recovered from...</td>\n",
       "      <td>10.4103/0970-2113.99118</td>\n",
       "      <td>PMC3424870</td>\n",
       "      <td>22919170</td>\n",
       "      <td>cc-by-nc-sa</td>\n",
       "      <td>The pandemic of swine flu (H1N1) influenza spr...</td>\n",
       "      <td>2012</td>\n",
       "      <td>Singh, Virendra; Sharma, Bharat Bhushan; Patel...</td>\n",
       "      <td>Lung India</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>aclzp3iy</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>1325376000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>ycxyn2a2</td>\n",
       "      <td>PMC</td>\n",
       "      <td>What was the primary mode of smallpox transmis...</td>\n",
       "      <td>10.3389/fcimb.2012.00150</td>\n",
       "      <td>PMC3509329</td>\n",
       "      <td>23226686</td>\n",
       "      <td>cc-by</td>\n",
       "      <td>The mode of infection transmission has profoun...</td>\n",
       "      <td>2012-11-29</td>\n",
       "      <td>Milton, Donald K.</td>\n",
       "      <td>Front Cell Infect Microbiol</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ycxyn2a2</td>\n",
       "      <td>2012-11-29</td>\n",
       "      <td>1354147200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1053</th>\n",
       "      <td>zxe95qy9</td>\n",
       "      <td>PMC</td>\n",
       "      <td>Lessons from the History of Quarantine, from P...</td>\n",
       "      <td>10.3201/eid1902.120312</td>\n",
       "      <td>PMC3559034</td>\n",
       "      <td>23343512</td>\n",
       "      <td>no-cc</td>\n",
       "      <td>In the new millennium, the centuries-old strat...</td>\n",
       "      <td>2013-02-03</td>\n",
       "      <td>Tognotti, Eugenia</td>\n",
       "      <td>Emerg Infect Dis</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>zxe95qy9</td>\n",
       "      <td>2013-02-03</td>\n",
       "      <td>1359849600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      cord_uid source_x                                              title  \\\n",
       "162   umvrwgaw      PMC  Professional and Home-Made Face Masks Reduce E...   \n",
       "611   spiud6ok      PMC                               The Failure of R (0)   \n",
       "918   aclzp3iy      PMC  Pulmonary sequelae in a patient recovered from...   \n",
       "993   ycxyn2a2      PMC  What was the primary mode of smallpox transmis...   \n",
       "1053  zxe95qy9      PMC  Lessons from the History of Quarantine, from P...   \n",
       "\n",
       "                               doi       pmcid pubmed_id      license  \\\n",
       "162   10.1371/journal.pone.0002618  PMC2440799  18612429        cc-by   \n",
       "611            10.1155/2011/527610  PMC3157160  21860658        cc-by   \n",
       "918        10.4103/0970-2113.99118  PMC3424870  22919170  cc-by-nc-sa   \n",
       "993       10.3389/fcimb.2012.00150  PMC3509329  23226686        cc-by   \n",
       "1053        10.3201/eid1902.120312  PMC3559034  23343512        no-cc   \n",
       "\n",
       "                                               abstract publish_time  \\\n",
       "162   BACKGROUND: Governments are preparing for a po...   2008-07-09   \n",
       "611   The basic reproductive ratio, R (0), is one of...   2011-08-16   \n",
       "918   The pandemic of swine flu (H1N1) influenza spr...         2012   \n",
       "993   The mode of infection transmission has profoun...   2012-11-29   \n",
       "1053  In the new millennium, the centuries-old strat...   2013-02-03   \n",
       "\n",
       "                                                authors  \\\n",
       "162   van der Sande, Marianne; Teunis, Peter; Sabel,...   \n",
       "611       Li, Jing; Blakeley, Daniel; Smith?, Robert J.   \n",
       "918   Singh, Virendra; Sharma, Bharat Bhushan; Patel...   \n",
       "993                                   Milton, Donald K.   \n",
       "1053                                  Tognotti, Eugenia   \n",
       "\n",
       "                          journal  mag_id who_covidence_id arxiv_id     label  \\\n",
       "162                      PLoS One     NaN              NaN      NaN  umvrwgaw   \n",
       "611       Comput Math Methods Med     NaN              NaN      NaN  spiud6ok   \n",
       "918                    Lung India     NaN              NaN      NaN  aclzp3iy   \n",
       "993   Front Cell Infect Microbiol     NaN              NaN      NaN  ycxyn2a2   \n",
       "1053             Emerg Infect Dis     NaN              NaN      NaN  zxe95qy9   \n",
       "\n",
       "           time       timet  \n",
       "162  2008-07-09  1215561600  \n",
       "611  2011-08-16  1313452800  \n",
       "918  2012-01-01  1325376000  \n",
       "993  2012-11-29  1354147200  \n",
       "1053 2013-02-03  1359849600  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_collection = pd.read_pickle(collection_data_path)\n",
    "df_collection.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "02fe1d0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>cord_uid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16</td>\n",
       "      <td>covid recovery: this study from the usa reveal...</td>\n",
       "      <td>3qvh482o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>69</td>\n",
       "      <td>\"Among 139 clients exposed to two symptomatic ...</td>\n",
       "      <td>r58aohnu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>73</td>\n",
       "      <td>I recall early on reading that researchers who...</td>\n",
       "      <td>sts48u9i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>93</td>\n",
       "      <td>You know you're credible when NIH website has ...</td>\n",
       "      <td>3sr2exq9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>96</td>\n",
       "      <td>Resistance to antifungal medications is a grow...</td>\n",
       "      <td>ybwwmyqy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1395</th>\n",
       "      <td>14193</td>\n",
       "      <td>Residents at high risk of covid-19: effectiven...</td>\n",
       "      <td>0gn3b98n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1396</th>\n",
       "      <td>14196</td>\n",
       "      <td>61% of teenagers hospitalized for covid were \"...</td>\n",
       "      <td>25bdifv6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1397</th>\n",
       "      <td>14203</td>\n",
       "      <td>\"fresh evidence backing melatonin against covi...</td>\n",
       "      <td>qn6wawxk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1398</th>\n",
       "      <td>14233</td>\n",
       "      <td>the vaccine doesn't halt the spread, it is pro...</td>\n",
       "      <td>3u3i5myh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1399</th>\n",
       "      <td>14236</td>\n",
       "      <td>\"Great commentary from K. Carvalho,  black pre...</td>\n",
       "      <td>nih4l4ok</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1400 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      post_id                                         tweet_text  cord_uid\n",
       "0          16  covid recovery: this study from the usa reveal...  3qvh482o\n",
       "1          69  \"Among 139 clients exposed to two symptomatic ...  r58aohnu\n",
       "2          73  I recall early on reading that researchers who...  sts48u9i\n",
       "3          93  You know you're credible when NIH website has ...  3sr2exq9\n",
       "4          96  Resistance to antifungal medications is a grow...  ybwwmyqy\n",
       "...       ...                                                ...       ...\n",
       "1395    14193  Residents at high risk of covid-19: effectiven...  0gn3b98n\n",
       "1396    14196  61% of teenagers hospitalized for covid were \"...  25bdifv6\n",
       "1397    14203  \"fresh evidence backing melatonin against covi...  qn6wawxk\n",
       "1398    14233  the vaccine doesn't halt the spread, it is pro...  3u3i5myh\n",
       "1399    14236  \"Great commentary from K. Carvalho,  black pre...  nih4l4ok\n",
       "\n",
       "[1400 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>cord_uid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Oral care in rehabilitation medicine: oral vul...</td>\n",
       "      <td>htlvpvz5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>this study isn't receiving sufficient attentio...</td>\n",
       "      <td>4kfl29ul</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>thanks, xi jinping. a reminder that this study...</td>\n",
       "      <td>jtwb17u8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Taiwan - a population of 23 million has had ju...</td>\n",
       "      <td>0w9k8iy1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Obtaining a diagnosis of autism in lower incom...</td>\n",
       "      <td>tiqksd69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12848</th>\n",
       "      <td>14248</td>\n",
       "      <td>\"evidence on covid-19 reveals a growing body o...</td>\n",
       "      <td>9169o29b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12849</th>\n",
       "      <td>14249</td>\n",
       "      <td>Outdoor lighting has detrimental impacts on lo...</td>\n",
       "      <td>s2bpha8l</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12850</th>\n",
       "      <td>14250</td>\n",
       "      <td>26/ and influenza virus (and other pathogens, ...</td>\n",
       "      <td>atloc9th</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12851</th>\n",
       "      <td>14251</td>\n",
       "      <td>does it?'sars-cov-2-naïve vaccinees had a 13.0...</td>\n",
       "      <td>t4y1ylb3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12852</th>\n",
       "      <td>14252</td>\n",
       "      <td>when \"the airway immune cells of children are ...</td>\n",
       "      <td>nlsv8bin</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12853 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       post_id                                         tweet_text  cord_uid\n",
       "0            0  Oral care in rehabilitation medicine: oral vul...  htlvpvz5\n",
       "1            1  this study isn't receiving sufficient attentio...  4kfl29ul\n",
       "2            2  thanks, xi jinping. a reminder that this study...  jtwb17u8\n",
       "3            3  Taiwan - a population of 23 million has had ju...  0w9k8iy1\n",
       "4            4  Obtaining a diagnosis of autism in lower incom...  tiqksd69\n",
       "...        ...                                                ...       ...\n",
       "12848    14248  \"evidence on covid-19 reveals a growing body o...  9169o29b\n",
       "12849    14249  Outdoor lighting has detrimental impacts on lo...  s2bpha8l\n",
       "12850    14250  26/ and influenza virus (and other pathogens, ...  atloc9th\n",
       "12851    14251  does it?'sars-cov-2-naïve vaccinees had a 13.0...  t4y1ylb3\n",
       "12852    14252  when \"the airway immune cells of children are ...  nlsv8bin\n",
       "\n",
       "[12853 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_query_dev = pd.read_csv(query_dev_data_path, sep='\\t')\n",
    "df_query_train = pd.read_csv(query_train_data_path, sep='\\t')\n",
    "display(df_query_dev)\n",
    "display(df_query_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a720417a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>cord_uid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16</td>\n",
       "      <td>covid recovery: this study from the usa reveal...</td>\n",
       "      <td>3qvh482o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>69</td>\n",
       "      <td>\"Among 139 clients exposed to two symptomatic ...</td>\n",
       "      <td>r58aohnu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>73</td>\n",
       "      <td>I recall early on reading that researchers who...</td>\n",
       "      <td>sts48u9i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>93</td>\n",
       "      <td>You know you're credible when NIH website has ...</td>\n",
       "      <td>3sr2exq9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>96</td>\n",
       "      <td>Resistance to antifungal medications is a grow...</td>\n",
       "      <td>ybwwmyqy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14248</th>\n",
       "      <td>14248</td>\n",
       "      <td>\"evidence on covid-19 reveals a growing body o...</td>\n",
       "      <td>9169o29b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14249</th>\n",
       "      <td>14249</td>\n",
       "      <td>Outdoor lighting has detrimental impacts on lo...</td>\n",
       "      <td>s2bpha8l</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14250</th>\n",
       "      <td>14250</td>\n",
       "      <td>26/ and influenza virus (and other pathogens, ...</td>\n",
       "      <td>atloc9th</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14251</th>\n",
       "      <td>14251</td>\n",
       "      <td>does it?'sars-cov-2-naïve vaccinees had a 13.0...</td>\n",
       "      <td>t4y1ylb3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14252</th>\n",
       "      <td>14252</td>\n",
       "      <td>when \"the airway immune cells of children are ...</td>\n",
       "      <td>nlsv8bin</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14253 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       post_id                                         tweet_text  cord_uid\n",
       "0           16  covid recovery: this study from the usa reveal...  3qvh482o\n",
       "1           69  \"Among 139 clients exposed to two symptomatic ...  r58aohnu\n",
       "2           73  I recall early on reading that researchers who...  sts48u9i\n",
       "3           93  You know you're credible when NIH website has ...  3sr2exq9\n",
       "4           96  Resistance to antifungal medications is a grow...  ybwwmyqy\n",
       "...        ...                                                ...       ...\n",
       "14248    14248  \"evidence on covid-19 reveals a growing body o...  9169o29b\n",
       "14249    14249  Outdoor lighting has detrimental impacts on lo...  s2bpha8l\n",
       "14250    14250  26/ and influenza virus (and other pathogens, ...  atloc9th\n",
       "14251    14251  does it?'sars-cov-2-naïve vaccinees had a 13.0...  t4y1ylb3\n",
       "14252    14252  when \"the airway immune cells of children are ...  nlsv8bin\n",
       "\n",
       "[14253 rows x 3 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_query_combined = pd.concat([df_query_dev, df_query_train], ignore_index=True)\n",
    "df_query_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a66f44e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_collection['last_names'] = df_collection['authors'].str.split(';').apply(\n",
    "    lambda authors: [author.split(',')[0].strip() for author in authors] if isinstance(authors, list) else authors\n",
    ")\n",
    "df_collection['last_names'] = df_collection['last_names'].apply(\n",
    "    lambda x: '; '.join(x) if isinstance(x, list) else x\n",
    ")\n",
    "df_collection['publish_year'] = df_collection['publish_time'].str.split('-').str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "10c6aa4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_bm25(corpus: list[str], cord_uids:list[str], k1=1.5, b=0.75, method='lucene', stemmer=None):\n",
    "    tokenized_corpus = bm25s.tokenize(corpus, stemmer=stemmer)\n",
    "    bm25 = bm25s.BM25(corpus=cord_uids, k1=k1, b=b, method=method)\n",
    "    bm25.index(tokenized_corpus)\n",
    "    return bm25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "33950172",
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment_single_bm25(df_collection, df_query, k1=1.5, b=0.75, stemmer=None, k=10):\n",
    "    corpus = df_collection.apply(\n",
    "        lambda x: f\"{x['title']} {x['abstract']} {x['last_names']} {x['journal']} {x['publish_year']}\", axis=1\n",
    "    ).tolist()\n",
    "    bm25 = initialize_bm25(corpus, df_collection['cord_uid'].tolist(), k1, b, stemmer=stemmer)\n",
    "    tokenized_queries = bm25s.tokenize(df_query['tweet_text'], stemmer=stemmer)\n",
    "    doc_scores = bm25.retrieve(tokenized_queries, n_threads=-1, k=k)\n",
    "    df_query['bm25_topk'] = doc_scores.documents.tolist()\n",
    "    \n",
    "    return df_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e1d4677d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_performance_mrr(data, col_gold, col_pred, list_k = [1, 5, 10]):\n",
    "    d_performance = {}\n",
    "    for k in list_k:\n",
    "        data[\"in_topx\"] = data.apply(lambda x: (1/([i for i in x[col_pred][:k]].index(x[col_gold]) + 1) if x[col_gold] in [i for i in x[col_pred][:k]] else 0), axis=1)\n",
    "        d_performance[k] = data[\"in_topx\"].mean()\n",
    "        print(f\"{k = }\")\n",
    "        in_topx = data[\"in_topx\"] > 0\n",
    "        print(f\"Number of queries in top {k}: {in_topx.sum()}\")\n",
    "        print(f\"Number of queries not in top {k}: {len(data) - in_topx.sum()}\")\n",
    "    return d_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3a580058",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_experiment(df_query_train, df_query_dev, experiment_name, list_k=[1, 5, 10]):\n",
    "    results = get_performance_mrr(df_query_train, 'cord_uid', 'bm25_topk', list_k)\n",
    "    print(f\"Results for {experiment_name}, train: {results}\")\n",
    "    results = get_performance_mrr(df_query_dev, 'cord_uid', 'bm25_topk', list_k)\n",
    "    print(f\"Results for {experiment_name}, dev: {results}\")\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0dfb72d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 1\n",
      "Number of queries in top 1: 7540\n",
      "Number of queries not in top 1: 5313\n",
      "k = 5\n",
      "Number of queries in top 5: 9096\n",
      "Number of queries not in top 5: 3757\n",
      "k = 10\n",
      "Number of queries in top 10: 9630\n",
      "Number of queries not in top 10: 3223\n",
      "k = 100\n",
      "Number of queries in top 100: 11157\n",
      "Number of queries not in top 100: 1696\n",
      "k = 200\n",
      "Number of queries in top 200: 11513\n",
      "Number of queries not in top 200: 1340\n",
      "k = 500\n",
      "Number of queries in top 500: 11957\n",
      "Number of queries not in top 500: 896\n",
      "k = 700\n",
      "Number of queries in top 700: 12090\n",
      "Number of queries not in top 700: 763\n",
      "k = 1000\n",
      "Number of queries in top 1000: 12211\n",
      "Number of queries not in top 1000: 642\n",
      "k = 2000\n",
      "Number of queries in top 2000: 12211\n",
      "Number of queries not in top 2000: 642\n",
      "k = 5000\n",
      "Number of queries in top 5000: 12211\n",
      "Number of queries not in top 5000: 642\n",
      "Results for Single BM25 with all features, train: {1: np.float64(0.5866334707850307), 5: np.float64(0.634745455016987), 10: np.float64(0.6402931685394925), 100: np.float64(0.6449074311828275), 200: np.float64(0.6451042573971111), 500: np.float64(0.6452173205148215), 700: np.float64(0.6452349451615127), 1000: np.float64(0.6452462313827287), 2000: np.float64(0.6452462313827287), 5000: np.float64(0.6452462313827287)}\n",
      "k = 1\n",
      "Number of queries in top 1: 829\n",
      "Number of queries not in top 1: 571\n",
      "k = 5\n",
      "Number of queries in top 5: 1004\n",
      "Number of queries not in top 5: 396\n",
      "k = 10\n",
      "Number of queries in top 10: 1060\n",
      "Number of queries not in top 10: 340\n",
      "k = 100\n",
      "Number of queries in top 100: 1222\n",
      "Number of queries not in top 100: 178\n",
      "k = 200\n",
      "Number of queries in top 200: 1266\n",
      "Number of queries not in top 200: 134\n",
      "k = 500\n",
      "Number of queries in top 500: 1300\n",
      "Number of queries not in top 500: 100\n",
      "k = 700\n",
      "Number of queries in top 700: 1323\n",
      "Number of queries not in top 700: 77\n",
      "k = 1000\n",
      "Number of queries in top 1000: 1336\n",
      "Number of queries not in top 1000: 64\n",
      "k = 2000\n",
      "Number of queries in top 2000: 1336\n",
      "Number of queries not in top 2000: 64\n",
      "k = 5000\n",
      "Number of queries in top 5000: 1336\n",
      "Number of queries not in top 5000: 64\n",
      "Results for Single BM25 with all features, dev: {1: np.float64(0.5921428571428572), 5: np.float64(0.6397619047619048), 10: np.float64(0.6450986394557824), 100: np.float64(0.6495240324689373), 200: np.float64(0.6497567832248164), 500: np.float64(0.6498352020281756), 700: np.float64(0.6498638803520272), 1000: np.float64(0.6498750349577517), 2000: np.float64(0.6498750349577517), 5000: np.float64(0.6498750349577517)}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{1: np.float64(0.5921428571428572),\n",
       " 5: np.float64(0.6397619047619048),\n",
       " 10: np.float64(0.6450986394557824),\n",
       " 100: np.float64(0.6495240324689373),\n",
       " 200: np.float64(0.6497567832248164),\n",
       " 500: np.float64(0.6498352020281756),\n",
       " 700: np.float64(0.6498638803520272),\n",
       " 1000: np.float64(0.6498750349577517),\n",
       " 2000: np.float64(0.6498750349577517),\n",
       " 5000: np.float64(0.6498750349577517)}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "stemmer = None\n",
    "df_query_train_single = experiment_single_bm25(df_collection, df_query_train, stemmer=stemmer, k=1000)\n",
    "df_query_dev_single = experiment_single_bm25(df_collection, df_query_dev, stemmer=stemmer, k=1000)\n",
    "evaluate_experiment(df_query_train_single, df_query_dev_single, \"Single BM25 with all features\", list_k=[1, 5, 10, 100, 200, 500, 700, 1000, 2000, 5000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975a0b66",
   "metadata": {},
   "source": [
    "We will use BM25 as a baseline ranking model. The experiment above shouws us that there is no improvement after the first 1k (doesnt matter whether we take top 1k or top 2k etc.) -> so for each query we will prefilter the documents with BM25 to the top 1k and then the reranker will take over."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eefbf4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_reranker(model_name, torch_dtype=torch.float16):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        model_name, trust_remote_code=True, torch_dtype=torch.float16\n",
    "    )\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"Using GPU\")\n",
    "        model = model.to('cuda')\n",
    "    model.eval()\n",
    "    return tokenizer, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "25058bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rerank_with_alibaba(df_query, df_collection, tokenizer, model, k=10, max_length=512, batch_size=32):\n",
    "    reranked_results = []\n",
    "    reranked_scores = []\n",
    "    reranked_docs = []\n",
    "\n",
    "    for _, row in tqdm(df_query.iterrows(), total=len(df_query), desc=\"Reranking\"):\n",
    "        query_text = row['tweet_text']\n",
    "        topk_docs = row['bm25_topk'] \n",
    "\n",
    "        pairs = [\n",
    "            [\n",
    "                query_text, \n",
    "                df_collection.loc[df_collection['cord_uid'] == doc_id, 'title'].values[0] + \" \" + \n",
    "                df_collection.loc[df_collection['cord_uid'] == doc_id, 'abstract'].values[0] + \" \" +\n",
    "                str(df_collection.loc[df_collection['cord_uid'] == doc_id, 'journal'].values[0]) + \" \" +\n",
    "                str(df_collection.loc[df_collection['cord_uid'] == doc_id, 'last_names'].values[0]) \n",
    "            ]\n",
    "            for doc_id in topk_docs\n",
    "        ]\n",
    "        \n",
    "        batch_scores = []\n",
    "        batch_docs = []\n",
    "\n",
    "        for i in range(0, len(pairs), batch_size):\n",
    "            batch_pairs = pairs[i:i + batch_size]\n",
    "            with torch.no_grad():\n",
    "                inputs = tokenizer(batch_pairs, padding=True, truncation=True, return_tensors='pt', max_length=max_length)\n",
    "                if torch.cuda.is_available():\n",
    "                    inputs = {key: value.to('cuda') for key, value in inputs.items()}\n",
    "                scores = model(**inputs, return_dict=True).logits.view(-1).float()\n",
    "\n",
    "            batch_scores.extend(scores.tolist())\n",
    "            batch_docs.extend(topk_docs[i:i+batch_size])\n",
    "\n",
    "\n",
    "        reranked = sorted(zip(batch_docs, batch_scores), key=lambda x: x[1], reverse=True)\n",
    "        reranked_results.append([doc_id for doc_id, _ in reranked[:k]])\n",
    "        reranked_scores.append([score for _, score in reranked])\n",
    "        reranked_docs.append([doc_id for doc_id, _ in reranked])\n",
    "\n",
    "    df_query['reranked_topk'] = reranked_results\n",
    "    df_query['reranked_docs'] = reranked_docs\n",
    "    df_query['reranked_scores'] = reranked_scores\n",
    "    return df_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e360937c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rerank_mxbai(df_query, df_collection, model_name, k=10, batch_size=1):\n",
    "    reranked_results = []    \n",
    "    reranked_scores = []\n",
    "\n",
    "    model = MxbaiRerankV2(model_name, torch_dtype=torch.float16)\n",
    "\n",
    "    for _, row in tqdm(df_query.iterrows(), total=len(df_query), desc=\"Reranking\"):\n",
    "        query_text = row['tweet_text']\n",
    "        topk_docs = row['bm25_topk']  # Get top-k BM25 results for the query\n",
    "\n",
    "        documents = [\n",
    "            [\n",
    "                df_collection.loc[df_collection['cord_uid'] == doc_id, 'title'].values[0] + \" \" + \n",
    "                df_collection.loc[df_collection['cord_uid'] == doc_id, 'abstract'].values[0] + \" \" +\n",
    "                str(df_collection.loc[df_collection['cord_uid'] == doc_id, 'journal'].values[0]) + \" \" +\n",
    "                str(df_collection.loc[df_collection['cord_uid'] == doc_id, 'last_names'].values[0]) \n",
    "            ]\n",
    "            for doc_id in topk_docs\n",
    "        ]\n",
    "\n",
    "        results = model.rank(query_text, documents, return_documents=True, top_k=k, batch_size=batch_size)\n",
    "        reranked = [topk_docs[result.index] for result in results]\n",
    "        reranked_score = [result.score for result in results]\n",
    "\n",
    "        reranked_results.append(reranked)\n",
    "        reranked_scores.append(reranked_score)\n",
    "\n",
    "    df_query['reranked_topk'] = reranked_results\n",
    "    df_query['reranked_docs'] = reranked_results\n",
    "    df_query['reranked_scores'] = reranked_scores\n",
    "    \n",
    "    return df_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4f96d6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_reranked_results(df_query, col_gold='cord_uid', col_pred='reranked_topk', list_k=[1, 5, 10]):\n",
    "    return get_performance_mrr(df_query, col_gold, col_pred, list_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0ec103",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee16e593",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in:                                                       <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x7fd9e42dfa10>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/vscode/.local/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 775, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "\n",
      "KeyboardInterrupt: \n",
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reranking:   0%|          | 12/14253 [00:06<2:06:33,  1.88it/s]"
     ]
    }
   ],
   "source": [
    "df_query_single = experiment_single_bm25(df_collection, df_query_combined, stemmer=stemmer, k=50)\n",
    "model_name = \"Alibaba-NLP/gte-reranker-modernbert-base\"\n",
    "tokenizer, model = initialize_reranker(model_name)\n",
    "df_query = rerank_with_alibaba(df_query_single, df_collection, tokenizer, model, k=10, batch_size=100)\n",
    "df_query.to_parquet('data/reranked_results_alibaba.parquet')\n",
    "results = evaluate_reranked_results(df_query)\n",
    "print(f\"Evaluation results: {results}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ed1b59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reranking: 100%|██████████| 14253/14253 [1:49:21<00:00,  2.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 1\n",
      "Number of queries in top 1: 9026\n",
      "Number of queries not in top 1: 5227\n",
      "k = 5\n",
      "Number of queries in top 5: 10949\n",
      "Number of queries not in top 5: 3304\n",
      "k = 10\n",
      "Number of queries in top 10: 11361\n",
      "Number of queries not in top 10: 2892\n",
      "Evaluation results: {1: np.float64(0.6332701887321968), 5: np.float64(0.6880668397296476), 10: np.float64(0.6920471490825101)}\n"
     ]
    }
   ],
   "source": [
    "df_query_dev_single = experiment_single_bm25(df_collection, df_query_combined, stemmer=stemmer, k=50)\n",
    "model_name = \"Alibaba-NLP/gte-multilingual-reranker-base\"\n",
    "tokenizer, model = initialize_reranker(model_name)\n",
    "df_query = rerank_with_alibaba(df_query_dev_single, df_collection, tokenizer, model, k=10, batch_size=100)\n",
    "df_query.to_parquet('data/reranked_results_alibaba_multilingual.parquet')\n",
    "results = evaluate_reranked_results(df_query)\n",
    "print(f\"Evaluation results: {results}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c75753",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>cord_uid</th>\n",
       "      <th>bm25_topk</th>\n",
       "      <th>reranked_topk</th>\n",
       "      <th>reranked_docs</th>\n",
       "      <th>reranked_scores</th>\n",
       "      <th>in_topx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16</td>\n",
       "      <td>covid recovery: this study from the usa reveal...</td>\n",
       "      <td>3qvh482o</td>\n",
       "      <td>[atji1xge, mb18fj8a, 66g5lpm6, 59up4v56, gatxu...</td>\n",
       "      <td>[hg3xpej0, 59up4v56, 82y56t7d, 86xwnpde, 8t2ti...</td>\n",
       "      <td>[hg3xpej0, 59up4v56, 82y56t7d, 86xwnpde, 8t2ti...</td>\n",
       "      <td>[1.2587890625, 0.71435546875, 0.4404296875, 0....</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>69</td>\n",
       "      <td>\"Among 139 clients exposed to two symptomatic ...</td>\n",
       "      <td>r58aohnu</td>\n",
       "      <td>[r58aohnu, p0kg6dyz, yrowv62k, s2vckt2w, j1ucr...</td>\n",
       "      <td>[r58aohnu, kiq6xb6k, s2vckt2w, icgsbelo, eay6q...</td>\n",
       "      <td>[r58aohnu, kiq6xb6k, s2vckt2w, icgsbelo, eay6q...</td>\n",
       "      <td>[3.333984375, 0.349853515625, 0.17138671875, 0...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>73</td>\n",
       "      <td>I recall early on reading that researchers who...</td>\n",
       "      <td>sts48u9i</td>\n",
       "      <td>[sgo76prc, sts48u9i, tz2shoso, gruir7aw, 3xw4q...</td>\n",
       "      <td>[sts48u9i, o47v5vgw, a7frertc, o877uul1, u5nxm...</td>\n",
       "      <td>[sts48u9i, o47v5vgw, a7frertc, o877uul1, u5nxm...</td>\n",
       "      <td>[0.309814453125, -0.06854248046875, -0.1201171...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>93</td>\n",
       "      <td>You know you're credible when NIH website has ...</td>\n",
       "      <td>3sr2exq9</td>\n",
       "      <td>[3sr2exq9, hgpiig0g, sv48gjkk, 1cpjqav4, k0f4c...</td>\n",
       "      <td>[3sr2exq9, k0f4cwig, sv48gjkk, 8j3bb6zx, pq3n1...</td>\n",
       "      <td>[3sr2exq9, k0f4cwig, sv48gjkk, 8j3bb6zx, pq3n1...</td>\n",
       "      <td>[0.83642578125, 0.22509765625, 0.1030883789062...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>96</td>\n",
       "      <td>Resistance to antifungal medications is a grow...</td>\n",
       "      <td>ybwwmyqy</td>\n",
       "      <td>[3l6ipiwk, vabb2f26, ouvq2wpq, lzddnb8j, ybwwm...</td>\n",
       "      <td>[ybwwmyqy, rs3umc1x, ouvq2wpq, 3l6ipiwk, ierqf...</td>\n",
       "      <td>[ybwwmyqy, rs3umc1x, ouvq2wpq, 3l6ipiwk, ierqf...</td>\n",
       "      <td>[0.22314453125, 0.08758544921875, -0.127197265...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   post_id                                         tweet_text  cord_uid  \\\n",
       "0       16  covid recovery: this study from the usa reveal...  3qvh482o   \n",
       "1       69  \"Among 139 clients exposed to two symptomatic ...  r58aohnu   \n",
       "2       73  I recall early on reading that researchers who...  sts48u9i   \n",
       "3       93  You know you're credible when NIH website has ...  3sr2exq9   \n",
       "4       96  Resistance to antifungal medications is a grow...  ybwwmyqy   \n",
       "\n",
       "                                           bm25_topk  \\\n",
       "0  [atji1xge, mb18fj8a, 66g5lpm6, 59up4v56, gatxu...   \n",
       "1  [r58aohnu, p0kg6dyz, yrowv62k, s2vckt2w, j1ucr...   \n",
       "2  [sgo76prc, sts48u9i, tz2shoso, gruir7aw, 3xw4q...   \n",
       "3  [3sr2exq9, hgpiig0g, sv48gjkk, 1cpjqav4, k0f4c...   \n",
       "4  [3l6ipiwk, vabb2f26, ouvq2wpq, lzddnb8j, ybwwm...   \n",
       "\n",
       "                                       reranked_topk  \\\n",
       "0  [hg3xpej0, 59up4v56, 82y56t7d, 86xwnpde, 8t2ti...   \n",
       "1  [r58aohnu, kiq6xb6k, s2vckt2w, icgsbelo, eay6q...   \n",
       "2  [sts48u9i, o47v5vgw, a7frertc, o877uul1, u5nxm...   \n",
       "3  [3sr2exq9, k0f4cwig, sv48gjkk, 8j3bb6zx, pq3n1...   \n",
       "4  [ybwwmyqy, rs3umc1x, ouvq2wpq, 3l6ipiwk, ierqf...   \n",
       "\n",
       "                                       reranked_docs  \\\n",
       "0  [hg3xpej0, 59up4v56, 82y56t7d, 86xwnpde, 8t2ti...   \n",
       "1  [r58aohnu, kiq6xb6k, s2vckt2w, icgsbelo, eay6q...   \n",
       "2  [sts48u9i, o47v5vgw, a7frertc, o877uul1, u5nxm...   \n",
       "3  [3sr2exq9, k0f4cwig, sv48gjkk, 8j3bb6zx, pq3n1...   \n",
       "4  [ybwwmyqy, rs3umc1x, ouvq2wpq, 3l6ipiwk, ierqf...   \n",
       "\n",
       "                                     reranked_scores  in_topx  \n",
       "0  [1.2587890625, 0.71435546875, 0.4404296875, 0....      0.0  \n",
       "1  [3.333984375, 0.349853515625, 0.17138671875, 0...      1.0  \n",
       "2  [0.309814453125, -0.06854248046875, -0.1201171...      1.0  \n",
       "3  [0.83642578125, 0.22509765625, 0.1030883789062...      1.0  \n",
       "4  [0.22314453125, 0.08758544921875, -0.127197265...      1.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reranking: 100%|██████████| 14253/14253 [1:30:21<00:00,  2.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 1\n",
      "Number of queries in top 1: 7438\n",
      "Number of queries not in top 1: 6815\n",
      "k = 5\n",
      "Number of queries in top 5: 9521\n",
      "Number of queries not in top 5: 4732\n",
      "k = 10\n",
      "Number of queries in top 10: 10215\n",
      "Number of queries not in top 10: 4038\n",
      "Evaluation results: {1: np.float64(0.5218550480600576), 5: np.float64(0.5785320049580205), 10: np.float64(0.5850188876972712)}\n"
     ]
    }
   ],
   "source": [
    "df_query_dev_single = experiment_single_bm25(df_collection, df_query_combined, stemmer=stemmer, k=200)\n",
    "display(df_query_dev_single.head(5))\n",
    "model_name = \"cross-encoder/ms-marco-TinyBERT-L2-v2\"\n",
    "tokenizer, model = initialize_reranker(model_name)\n",
    "df_query = rerank_with_alibaba(df_query_dev_single, df_collection, tokenizer, model, k=10, batch_size=100)\n",
    "df_query.to_parquet(\"data/reranked_results_tinyBERT.parquet\")\n",
    "results = evaluate_reranked_results(df_query)\n",
    "print(f\"Evaluation results: {results}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99af320",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>cord_uid</th>\n",
       "      <th>bm25_topk</th>\n",
       "      <th>reranked_topk</th>\n",
       "      <th>reranked_docs</th>\n",
       "      <th>reranked_scores</th>\n",
       "      <th>in_topx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16</td>\n",
       "      <td>covid recovery: this study from the usa reveal...</td>\n",
       "      <td>3qvh482o</td>\n",
       "      <td>[atji1xge, mb18fj8a, 66g5lpm6, 59up4v56, gatxu...</td>\n",
       "      <td>[nksd3wuw, es8l29ub, atji1xge, 82y56t7d, sqxdw...</td>\n",
       "      <td>[nksd3wuw, es8l29ub, atji1xge, 82y56t7d, sqxdw...</td>\n",
       "      <td>[7.078125, 6.046875, 5.74609375, 5.4140625, 5....</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>69</td>\n",
       "      <td>\"Among 139 clients exposed to two symptomatic ...</td>\n",
       "      <td>r58aohnu</td>\n",
       "      <td>[r58aohnu, p0kg6dyz, yrowv62k, s2vckt2w, j1ucr...</td>\n",
       "      <td>[r58aohnu, 6zfpcm4j, wk61uyrt, xsqgrd5l, icgsb...</td>\n",
       "      <td>[r58aohnu, 6zfpcm4j, wk61uyrt, xsqgrd5l, icgsb...</td>\n",
       "      <td>[6.75390625, 1.7626953125, 1.494140625, 1.3847...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>73</td>\n",
       "      <td>I recall early on reading that researchers who...</td>\n",
       "      <td>sts48u9i</td>\n",
       "      <td>[sgo76prc, sts48u9i, tz2shoso, gruir7aw, 3xw4q...</td>\n",
       "      <td>[u5nxm9tu, qkg8fwbp, sts48u9i, 4aps0kvp, ujq9m...</td>\n",
       "      <td>[u5nxm9tu, qkg8fwbp, sts48u9i, 4aps0kvp, ujq9m...</td>\n",
       "      <td>[0.5537109375, -0.328857421875, -0.48095703125...</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>93</td>\n",
       "      <td>You know you're credible when NIH website has ...</td>\n",
       "      <td>3sr2exq9</td>\n",
       "      <td>[3sr2exq9, hgpiig0g, sv48gjkk, 1cpjqav4, k0f4c...</td>\n",
       "      <td>[kdegnr6i, bn22k0p3, 3sr2exq9, k0f4cwig, wbw7g...</td>\n",
       "      <td>[kdegnr6i, bn22k0p3, 3sr2exq9, k0f4cwig, wbw7g...</td>\n",
       "      <td>[-0.0164794921875, -1.2412109375, -1.251953125...</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>96</td>\n",
       "      <td>Resistance to antifungal medications is a grow...</td>\n",
       "      <td>ybwwmyqy</td>\n",
       "      <td>[3l6ipiwk, vabb2f26, ouvq2wpq, lzddnb8j, ybwwm...</td>\n",
       "      <td>[vabb2f26, ybwwmyqy, 3l6ipiwk, ouvq2wpq, buswb...</td>\n",
       "      <td>[vabb2f26, ybwwmyqy, 3l6ipiwk, ouvq2wpq, buswb...</td>\n",
       "      <td>[4.51171875, 4.36328125, 4.16015625, 2.578125,...</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   post_id                                         tweet_text  cord_uid  \\\n",
       "0       16  covid recovery: this study from the usa reveal...  3qvh482o   \n",
       "1       69  \"Among 139 clients exposed to two symptomatic ...  r58aohnu   \n",
       "2       73  I recall early on reading that researchers who...  sts48u9i   \n",
       "3       93  You know you're credible when NIH website has ...  3sr2exq9   \n",
       "4       96  Resistance to antifungal medications is a grow...  ybwwmyqy   \n",
       "\n",
       "                                           bm25_topk  \\\n",
       "0  [atji1xge, mb18fj8a, 66g5lpm6, 59up4v56, gatxu...   \n",
       "1  [r58aohnu, p0kg6dyz, yrowv62k, s2vckt2w, j1ucr...   \n",
       "2  [sgo76prc, sts48u9i, tz2shoso, gruir7aw, 3xw4q...   \n",
       "3  [3sr2exq9, hgpiig0g, sv48gjkk, 1cpjqav4, k0f4c...   \n",
       "4  [3l6ipiwk, vabb2f26, ouvq2wpq, lzddnb8j, ybwwm...   \n",
       "\n",
       "                                       reranked_topk  \\\n",
       "0  [nksd3wuw, es8l29ub, atji1xge, 82y56t7d, sqxdw...   \n",
       "1  [r58aohnu, 6zfpcm4j, wk61uyrt, xsqgrd5l, icgsb...   \n",
       "2  [u5nxm9tu, qkg8fwbp, sts48u9i, 4aps0kvp, ujq9m...   \n",
       "3  [kdegnr6i, bn22k0p3, 3sr2exq9, k0f4cwig, wbw7g...   \n",
       "4  [vabb2f26, ybwwmyqy, 3l6ipiwk, ouvq2wpq, buswb...   \n",
       "\n",
       "                                       reranked_docs  \\\n",
       "0  [nksd3wuw, es8l29ub, atji1xge, 82y56t7d, sqxdw...   \n",
       "1  [r58aohnu, 6zfpcm4j, wk61uyrt, xsqgrd5l, icgsb...   \n",
       "2  [u5nxm9tu, qkg8fwbp, sts48u9i, 4aps0kvp, ujq9m...   \n",
       "3  [kdegnr6i, bn22k0p3, 3sr2exq9, k0f4cwig, wbw7g...   \n",
       "4  [vabb2f26, ybwwmyqy, 3l6ipiwk, ouvq2wpq, buswb...   \n",
       "\n",
       "                                     reranked_scores   in_topx  \n",
       "0  [7.078125, 6.046875, 5.74609375, 5.4140625, 5....  0.000000  \n",
       "1  [6.75390625, 1.7626953125, 1.494140625, 1.3847...  1.000000  \n",
       "2  [0.5537109375, -0.328857421875, -0.48095703125...  0.333333  \n",
       "3  [-0.0164794921875, -1.2412109375, -1.251953125...  0.333333  \n",
       "4  [4.51171875, 4.36328125, 4.16015625, 2.578125,...  0.500000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reranking: 100%|██████████| 14253/14253 [1:30:00<00:00,  2.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 1\n",
      "Number of queries in top 1: 7613\n",
      "Number of queries not in top 1: 6640\n",
      "k = 5\n",
      "Number of queries in top 5: 9648\n",
      "Number of queries not in top 5: 4605\n",
      "k = 10\n",
      "Number of queries in top 10: 10355\n",
      "Number of queries not in top 10: 3898\n",
      "Evaluation results: {1: np.float64(0.5341331649477303), 5: np.float64(0.5887462288640988), 10: np.float64(0.5954533659858855)}\n"
     ]
    }
   ],
   "source": [
    "df_query_dev_single = experiment_single_bm25(df_collection, df_query_combined, stemmer=stemmer, k=100)\n",
    "display(df_query_dev_single.head(5))\n",
    "model_name = \"cross-encoder/ms-marco-MiniLM-L12-v2\"\n",
    "tokenizer, model = initialize_reranker(model_name)\n",
    "df_query = rerank_with_alibaba(df_query_dev_single, df_collection, tokenizer, model, k=10, batch_size=100)\n",
    "df_query.to_parquet(\"data/reranked_results_miniLM.parquet\")\n",
    "results = evaluate_reranked_results(df_query)\n",
    "print(f\"Evaluation results: {results}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069665d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reranking: 100%|██████████| 14253/14253 [1:20:58<00:00,  2.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 1\n",
      "Number of queries in top 1: 7032\n",
      "Number of queries not in top 1: 7221\n",
      "k = 5\n",
      "Number of queries in top 5: 9334\n",
      "Number of queries not in top 5: 4919\n",
      "k = 10\n",
      "Number of queries in top 10: 10228\n",
      "Number of queries not in top 10: 4025\n",
      "Evaluation results: {1: np.float64(0.49336981688065673), 5: np.float64(0.5558163193713604), 10: np.float64(0.5641402422659)}\n"
     ]
    }
   ],
   "source": [
    "df_query_dev_single = experiment_single_bm25(df_collection, df_query_combined, stemmer=stemmer, k=40)\n",
    "model_name = \"cross-encoder/ms-marco-electra-base\"\n",
    "tokenizer, model = initialize_reranker(model_name)\n",
    "df_query = rerank_with_alibaba(df_query_dev_single, df_collection, tokenizer, model, k=10, batch_size=50, max_length=None )\n",
    "df_query.to_parquet(\"data/reranked_results_electra.parquet\")\n",
    "results = evaluate_reranked_results(df_query)\n",
    "print(f\"Evaluation results: {results}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd25c9d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reranking:   0%|          | 0/14253 [00:00<?, ?it/s]                        You're using a Qwen2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "Reranking: 100%|██████████| 14253/14253 [4:14:34<00:00,  1.07s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 1\n",
      "Number of queries in top 1: 9784\n",
      "Number of queries not in top 1: 4469\n",
      "k = 5\n",
      "Number of queries in top 5: 11050\n",
      "Number of queries not in top 5: 3203\n",
      "k = 10\n",
      "Number of queries in top 10: 11274\n",
      "Number of queries not in top 10: 2979\n",
      "Evaluation results: {1: np.float64(0.6864519750228022), 5: np.float64(0.7231974555064431), 10: np.float64(0.7253506362904384)}\n"
     ]
    }
   ],
   "source": [
    "df_query_dev_single = experiment_single_bm25(df_collection, df_query_combined, stemmer=stemmer, k=25)\n",
    "df_query = rerank_mxbai(df_query_dev_single, df_collection, \"mixedbread-ai/mxbai-rerank-base-v2\", batch_size=1)\n",
    "df_query.to_parquet(\"data/reranked_results_mxbai.parquet\")\n",
    "results = evaluate_reranked_results(df_query)\n",
    "print(f\"Evaluation results: {results}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcbff983",
   "metadata": {},
   "source": [
    "## Finetune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0b1d662d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "from sentence_transformers import CrossEncoder\n",
    "from sentence_transformers.cross_encoder.losses import CachedMultipleNegativesRankingLoss, MultipleNegativesRankingLoss, LambdaLoss\n",
    "from sentence_transformers.cross_encoder import CrossEncoderTrainingArguments\n",
    "from sentence_transformers.training_args import BatchSamplers\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sentence_transformers.util import mine_hard_negatives\n",
    "from sentence_transformers.cross_encoder.evaluation import CrossEncoderRerankingEvaluator\n",
    "from sentence_transformers.cross_encoder.losses.BinaryCrossEntropyLoss import BinaryCrossEntropyLoss\n",
    "from sentence_transformers.cross_encoder import CrossEncoderTrainer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e63c5e2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cord_uid</th>\n",
       "      <th>source_x</th>\n",
       "      <th>title</th>\n",
       "      <th>doi</th>\n",
       "      <th>pmcid</th>\n",
       "      <th>pubmed_id</th>\n",
       "      <th>license</th>\n",
       "      <th>abstract</th>\n",
       "      <th>publish_time</th>\n",
       "      <th>authors</th>\n",
       "      <th>journal</th>\n",
       "      <th>mag_id</th>\n",
       "      <th>who_covidence_id</th>\n",
       "      <th>arxiv_id</th>\n",
       "      <th>label</th>\n",
       "      <th>time</th>\n",
       "      <th>timet</th>\n",
       "      <th>last_names</th>\n",
       "      <th>publish_year</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>umvrwgaw</td>\n",
       "      <td>PMC</td>\n",
       "      <td>Professional and Home-Made Face Masks Reduce E...</td>\n",
       "      <td>10.1371/journal.pone.0002618</td>\n",
       "      <td>PMC2440799</td>\n",
       "      <td>18612429</td>\n",
       "      <td>cc-by</td>\n",
       "      <td>BACKGROUND: Governments are preparing for a po...</td>\n",
       "      <td>2008-07-09</td>\n",
       "      <td>van der Sande, Marianne; Teunis, Peter; Sabel,...</td>\n",
       "      <td>PLoS One</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>umvrwgaw</td>\n",
       "      <td>2008-07-09</td>\n",
       "      <td>1215561600</td>\n",
       "      <td>van der Sande; Teunis; Sabel</td>\n",
       "      <td>2008</td>\n",
       "      <td>Professional and Home-Made Face Masks Reduce E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611</th>\n",
       "      <td>spiud6ok</td>\n",
       "      <td>PMC</td>\n",
       "      <td>The Failure of R (0)</td>\n",
       "      <td>10.1155/2011/527610</td>\n",
       "      <td>PMC3157160</td>\n",
       "      <td>21860658</td>\n",
       "      <td>cc-by</td>\n",
       "      <td>The basic reproductive ratio, R (0), is one of...</td>\n",
       "      <td>2011-08-16</td>\n",
       "      <td>Li, Jing; Blakeley, Daniel; Smith?, Robert J.</td>\n",
       "      <td>Comput Math Methods Med</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>spiud6ok</td>\n",
       "      <td>2011-08-16</td>\n",
       "      <td>1313452800</td>\n",
       "      <td>Li; Blakeley; Smith?</td>\n",
       "      <td>2011</td>\n",
       "      <td>The Failure of R (0) The basic reproductive ra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>918</th>\n",
       "      <td>aclzp3iy</td>\n",
       "      <td>PMC</td>\n",
       "      <td>Pulmonary sequelae in a patient recovered from...</td>\n",
       "      <td>10.4103/0970-2113.99118</td>\n",
       "      <td>PMC3424870</td>\n",
       "      <td>22919170</td>\n",
       "      <td>cc-by-nc-sa</td>\n",
       "      <td>The pandemic of swine flu (H1N1) influenza spr...</td>\n",
       "      <td>2012</td>\n",
       "      <td>Singh, Virendra; Sharma, Bharat Bhushan; Patel...</td>\n",
       "      <td>Lung India</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>aclzp3iy</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>1325376000</td>\n",
       "      <td>Singh; Sharma; Patel</td>\n",
       "      <td>2012</td>\n",
       "      <td>Pulmonary sequelae in a patient recovered from...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     cord_uid source_x                                              title  \\\n",
       "162  umvrwgaw      PMC  Professional and Home-Made Face Masks Reduce E...   \n",
       "611  spiud6ok      PMC                               The Failure of R (0)   \n",
       "918  aclzp3iy      PMC  Pulmonary sequelae in a patient recovered from...   \n",
       "\n",
       "                              doi       pmcid pubmed_id      license  \\\n",
       "162  10.1371/journal.pone.0002618  PMC2440799  18612429        cc-by   \n",
       "611           10.1155/2011/527610  PMC3157160  21860658        cc-by   \n",
       "918       10.4103/0970-2113.99118  PMC3424870  22919170  cc-by-nc-sa   \n",
       "\n",
       "                                              abstract publish_time  \\\n",
       "162  BACKGROUND: Governments are preparing for a po...   2008-07-09   \n",
       "611  The basic reproductive ratio, R (0), is one of...   2011-08-16   \n",
       "918  The pandemic of swine flu (H1N1) influenza spr...         2012   \n",
       "\n",
       "                                               authors  \\\n",
       "162  van der Sande, Marianne; Teunis, Peter; Sabel,...   \n",
       "611      Li, Jing; Blakeley, Daniel; Smith?, Robert J.   \n",
       "918  Singh, Virendra; Sharma, Bharat Bhushan; Patel...   \n",
       "\n",
       "                     journal  mag_id who_covidence_id arxiv_id     label  \\\n",
       "162                 PLoS One     NaN              NaN      NaN  umvrwgaw   \n",
       "611  Comput Math Methods Med     NaN              NaN      NaN  spiud6ok   \n",
       "918               Lung India     NaN              NaN      NaN  aclzp3iy   \n",
       "\n",
       "          time       timet                    last_names publish_year  \\\n",
       "162 2008-07-09  1215561600  van der Sande; Teunis; Sabel         2008   \n",
       "611 2011-08-16  1313452800          Li; Blakeley; Smith?         2011   \n",
       "918 2012-01-01  1325376000          Singh; Sharma; Patel         2012   \n",
       "\n",
       "                                                answer  \n",
       "162  Professional and Home-Made Face Masks Reduce E...  \n",
       "611  The Failure of R (0) The basic reproductive ra...  \n",
       "918  Pulmonary sequelae in a patient recovered from...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_collection['answer'] = df_collection.apply(\n",
    "    lambda row: f\"{row['title']} {row['abstract']} {row['last_names']} {row['journal']}\", axis=1\n",
    ")\n",
    "df_collection.head(3)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b460ba5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>cord_uid</th>\n",
       "      <th>bm25_topk</th>\n",
       "      <th>in_topx</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Oral care in rehabilitation medicine: oral vul...</td>\n",
       "      <td>htlvpvz5</td>\n",
       "      <td>[htlvpvz5, h7hj64q5, 4aps0kvp, 5tkyir3r, 32z7b...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Oral Management in Rehabilitation Medicine: Or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>this study isn't receiving sufficient attentio...</td>\n",
       "      <td>4kfl29ul</td>\n",
       "      <td>[maj8r6ti, bjvg2ivr, 7tto4hr7, 2cwvga0k, 46je8...</td>\n",
       "      <td>0.003145</td>\n",
       "      <td>Variation in racial/ethnic disparities in COVI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>thanks, xi jinping. a reminder that this study...</td>\n",
       "      <td>jtwb17u8</td>\n",
       "      <td>[jtwb17u8, veeavho5, jbpmbm9m, 8hkxbxz9, 32v44...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Effect of non-pharmaceutical interventions for...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   post_id                                         tweet_text  cord_uid  \\\n",
       "0        0  Oral care in rehabilitation medicine: oral vul...  htlvpvz5   \n",
       "1        1  this study isn't receiving sufficient attentio...  4kfl29ul   \n",
       "2        2  thanks, xi jinping. a reminder that this study...  jtwb17u8   \n",
       "\n",
       "                                           bm25_topk   in_topx  \\\n",
       "0  [htlvpvz5, h7hj64q5, 4aps0kvp, 5tkyir3r, 32z7b...  1.000000   \n",
       "1  [maj8r6ti, bjvg2ivr, 7tto4hr7, 2cwvga0k, 46je8...  0.003145   \n",
       "2  [jtwb17u8, veeavho5, jbpmbm9m, 8hkxbxz9, 32v44...  1.000000   \n",
       "\n",
       "                                              answer  \n",
       "0  Oral Management in Rehabilitation Medicine: Or...  \n",
       "1  Variation in racial/ethnic disparities in COVI...  \n",
       "2  Effect of non-pharmaceutical interventions for...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = df_query_train.merge(df_collection[['cord_uid', 'answer']], on='cord_uid', how='left')\n",
    "df_dev = df_query_dev.merge(df_collection[['cord_uid', 'answer']], on='cord_uid', how='left')\n",
    "df_full = pd.concat([df_train, df_dev], ignore_index=True)\n",
    "df_full.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56627c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset.from_dict({\n",
    "    \"query\": df_train['tweet_text'].tolist(),\n",
    "    \"document\": df_train['answer'].tolist(),\n",
    "})\n",
    "\n",
    "dev_dataset = Dataset.from_dict({\n",
    "    \"query\": df_dev['tweet_text'].tolist(),\n",
    "    \"document\": df_dev['answer'].tolist(),\n",
    "})\n",
    "full_dataset = Dataset.from_dict({\n",
    "    \"query\": df_full['tweet_text'].tolist(),\n",
    "    \"document\": df_full['answer'].tolist(),\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3388f98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hard_negatives(embedding_model_hard_negatives, num_hard_negatives, num_hard_negatives_eval, train_dataset, dev_dataset, df_full, batch_size=4096):\n",
    "\n",
    "    embedding_model = SentenceTransformer(embedding_model_hard_negatives, device=torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "\n",
    "    # hard_train_dataset = mine_hard_negatives(\n",
    "    #     train_dataset,\n",
    "    #     embedding_model,\n",
    "    #     num_negatives=num_hard_negatives,  # How many negatives per question-answer pair\n",
    "    #     range_min=3,  # Skip the x most similar samples\n",
    "    #     range_max=100,  # Consider only the x most similar samples\n",
    "    #     max_score=0.95,  # Only consider samples with a similarity score of at most x\n",
    "    #     margin=0.05,  # Similarity between query and negative samples should be x lower than query-positive similarity\n",
    "    #     sampling_strategy=\"top\",  # Randomly sample negatives from the range\n",
    "    #     batch_size=batch_size,  # Use a batch size of 4096 for the embedding model\n",
    "    #     output_format=\"labeled-pair\",  # The output format is (query, passage, label), as required by BinaryCrossEntropyLoss\n",
    "    # )\n",
    "\n",
    "    # hard_eval_dataset = mine_hard_negatives(\n",
    "    #     dev_dataset,\n",
    "    #     embedding_model,\n",
    "    #     corpus=df_full[\"answer\"],  # Use the full dataset as the corpus\n",
    "    #     num_negatives=num_hard_negatives_eval,  # How many negatives per question-answer pair\n",
    "    #     batch_size=batch_size,  # Use a batch size of 4096 for the embedding model\n",
    "    #     output_format=\"n-tuple\",  # The output format is (query, positive, negative1, negative2, ...) for the evaluator\n",
    "    #     include_positives=True,  # Key: Include the positive answer in the list of negatives\n",
    "    #     range_min=3,  # Skip the x most similar samples\n",
    "    #     range_max=100,  # Consider only the x most similar samples\n",
    "    #     max_score=0.95,  # Only consider samples with a similarity score of at most x\n",
    "    #     margin=0.05,  # Similarity between query and negative samples should be x lower than query-positive similarity\n",
    "    #     sampling_strategy=\"top\",  # Randomly sample negatives from the range\n",
    "    # )\n",
    "\n",
    "    hard_train_dataset = mine_hard_negatives(\n",
    "        train_dataset,\n",
    "        embedding_model,\n",
    "        num_negatives=num_hard_negatives,  # How many negatives per question-answer pair\n",
    "        range_min=3,  # Skip the x most similar samples\n",
    "        range_max=100,  # Consider only the x most similar samples\n",
    "        max_score=0.95,  # Only consider samples with a similarity score of at most x\n",
    "        margin=0.05,  # Similarity between query and negative samples should be x lower than query-positive similarity\n",
    "        sampling_strategy=\"top\",  # Randomly sample negatives from the range\n",
    "        batch_size=batch_size,  # Use a batch size of 4096 for the embedding model\n",
    "        output_format=\"labeled-pair\",  # The output format is (query, passage, label), as required by BinaryCrossEntropyLoss\n",
    "    )\n",
    "\n",
    "    print(\"======================\")\n",
    "    hard_eval_dataset = mine_hard_negatives(\n",
    "        dev_dataset,\n",
    "        embedding_model,\n",
    "        corpus=df_full[\"answer\"],  # Use the full dataset as the corpus\n",
    "        num_negatives=num_hard_negatives_eval,  # How many negatives per question-answer pair\n",
    "        batch_size=batch_size,  # Use a batch size of 4096 for the embedding model\n",
    "        output_format=\"labeled-pair\",  # The output format is (query, positive, negative1, negative2, ...) for the evaluator\n",
    "    )\n",
    "\n",
    "    print(\"======================\")\n",
    "    hard_eval_dataset_evaluator = mine_hard_negatives(\n",
    "        dev_dataset,\n",
    "        embedding_model,\n",
    "        corpus=df_full[\"answer\"],  # Use the full dataset as the corpus\n",
    "        num_negatives=num_hard_negatives_eval,  # How many negatives per question-answer pair\n",
    "        batch_size=batch_size,  # Use a batch size of 4096 for the embedding model\n",
    "        include_positives=True,  # Key: Include the positive answer in the list of negatives\n",
    "    )\n",
    "\n",
    "    return hard_train_dataset, hard_eval_dataset, hard_eval_dataset_evaluator\n",
    "\n",
    "\n",
    "class ExperimentRunner:\n",
    "    def __init__(self, model_to_finetune, train_batch_size, num_epochs, max_length, experiment_name):\n",
    "        self.experiment_name = experiment_name\n",
    "        self.model_to_finetune = model_to_finetune\n",
    "        self.train_batch_size = train_batch_size\n",
    "        self.num_epochs = num_epochs\n",
    "        self.max_length = max_length\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    def run_experiment(self, hard_train_dataset, hard_eval_dataset, hard_eval_dataset_evaluator, num_hard_negatives, trust_remote_code=False, eval_steps=None):\n",
    "\n",
    "        if eval_steps is None:\n",
    "            eval_steps = int(20000/self.train_batch_size)\n",
    "        \n",
    "        print(f\"Eval steps: {eval_steps}\")\n",
    "        model = CrossEncoder(self.model_to_finetune, max_length=self.max_length, device=self.device, trust_remote_code=trust_remote_code)\n",
    "\n",
    "        args = CrossEncoderTrainingArguments(\n",
    "            # Required parameter:\n",
    "            output_dir=f\"model/{self.model_to_finetune.split(\"/\")[-1]}{self.experiment_name}\",\n",
    "            # Optional training parameters:\n",
    "            num_train_epochs=self.num_epochs,\n",
    "            per_device_train_batch_size=self.train_batch_size,\n",
    "            per_device_eval_batch_size=self.train_batch_size,\n",
    "            learning_rate=2e-5,\n",
    "            warmup_ratio=0.1,\n",
    "            fp16=True,  \n",
    "            bf16=False, \n",
    "            batch_sampler=BatchSamplers.NO_DUPLICATES, \n",
    "            eval_strategy=\"steps\",\n",
    "            eval_steps=eval_steps,\n",
    "            save_strategy=\"steps\",\n",
    "            save_steps=eval_steps,\n",
    "            save_total_limit=10,\n",
    "            logging_steps=eval_steps,\n",
    "            run_name=self.model_to_finetune.split(\"/\")[-1],\n",
    "            load_best_model_at_end=True,\n",
    "            metric_for_best_model=\"eval_loss\",\n",
    "            greater_is_better=False,\n",
    "        )\n",
    "        \n",
    "        reranking_evaluator = CrossEncoderRerankingEvaluator(\n",
    "            samples=[\n",
    "                {\n",
    "                    \"query\": sample[\"query\"],\n",
    "                    \"positive\": [sample[\"document\"]],\n",
    "                    \"documents\": [sample[column_name] for column_name in hard_eval_dataset_evaluator.column_names if 'negative' in column_name],\n",
    "                }\n",
    "                for sample in hard_eval_dataset_evaluator\n",
    "            ],\n",
    "            batch_size=self.train_batch_size,\n",
    "            name=\"dev_set\",\n",
    "            show_progress_bar=True,\n",
    "        )\n",
    "\n",
    "        loss = BinaryCrossEntropyLoss(model=model, pos_weight=torch.tensor(num_hard_negatives))\n",
    "        # loss = MultipleNegativesRankingLoss(model=model, num_negatives=num_hard_negatives)\n",
    "        # loss = LambdaLoss(model=model, k=5)\n",
    "\n",
    "        trainer = CrossEncoderTrainer(\n",
    "            model=model,\n",
    "            args=args,\n",
    "            train_dataset=hard_train_dataset,\n",
    "            eval_dataset=hard_eval_dataset,\n",
    "            loss=loss,\n",
    "            evaluator=reranking_evaluator,\n",
    "    \n",
    "        )\n",
    "\n",
    "        # Train the model\n",
    "        trainer.train()\n",
    "\n",
    "        model.save(f\"models/{self.model_to_finetune.split('/')[-1]}-finetuned{self.experiment_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "afccf474",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 2\n",
    "# embedding_model_hard_negatives = \"sentence-transformers/static-retrieval-mrl-en-v1\"\n",
    "# embedding_model_hard_negatives = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "# embedding_model_hard_negatives = \"sentence-transformers/all-MiniLM-L12-v2\"\n",
    "embedding_model_hard_negatives = \"BAAI/bge-small-en-v1.5\"\n",
    "\n",
    "\n",
    "experiment_name = f\"_{embedding_model_hard_negatives.split('/')[-1]}_epochs{num_epochs}_crossentropyloss_stricter embedding\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "23062379",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `margin` parameter is deprecated. Use the `absolute_margin` and/or `relative_margin` parameter instead. Setting `absolute_margin` to `0.05`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12842 unique queries out of 12853 total queries.\n",
      "Found an average of 1.001 positives per query.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 109/109 [00:25<00:00,  4.32it/s]\n",
      "Batches: 100%|██████████| 201/201 [00:05<00:00, 33.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric       Positive       Negative     Difference\n",
      "Count          12,853         42,838               \n",
      "Mean           0.8195         0.7795         0.0796\n",
      "Median         0.8329         0.7911         0.0650\n",
      "Std            0.0826         0.0525         0.0355\n",
      "Min            0.3809         0.5041        -0.0251\n",
      "25%            0.7696         0.7488         0.0544\n",
      "50%            0.8329         0.7911         0.0650\n",
      "75%            0.8834         0.8169         0.0924\n",
      "Max            0.9881         0.8966         0.2992\n",
      "Skipped 561,618 potential negatives (42.46%) due to the absolute_margin of 0.05.\n",
      "Could not find enough negatives for 21427 samples (33.34%). Consider adjusting the range_max, range_min, absolute_margin and max_score parameters if you'd like to find more valid negatives.\n",
      "======================\n",
      "Setting range_max to 7 based on the provided parameters.\n",
      "Found 1399 unique queries out of 1400 total queries.\n",
      "Found an average of 1.001 positives per query.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 121/121 [00:28<00:00,  4.32it/s]\n",
      "Batches: 100%|██████████| 22/22 [00:00<00:00, 34.62it/s]\n",
      "When using `include_positives=True`, `output_format` will be set to `\"n-tuple\"` to ensure that the ranking order is preserved.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric       Positive       Negative     Difference\n",
      "Count           1,400          7,000               \n",
      "Mean           0.8219         0.8033         0.0186\n",
      "Median         0.8323         0.8101         0.0168\n",
      "Std            0.0783         0.0505         0.0640\n",
      "Min            0.4977         0.5529        -0.1856\n",
      "25%            0.7717         0.7739        -0.0220\n",
      "50%            0.8323         0.8101         0.0168\n",
      "75%            0.8846         0.8388         0.0593\n",
      "Max            0.9681         0.9451         0.2385\n",
      "======================\n",
      "Setting range_max to 7 based on the provided parameters.\n",
      "Found 1399 unique queries out of 1400 total queries.\n",
      "Found an average of 1.001 positives per query.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 121/121 [00:28<00:00,  4.31it/s]\n",
      "Batches: 100%|██████████| 22/22 [00:00<00:00, 34.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric       Positive       Negative     Difference\n",
      "Count           1,400          7,000               \n",
      "Mean           0.8219         0.8117         0.0102\n",
      "Median         0.8323         0.8156         0.0000\n",
      "Std            0.0783         0.0543         0.0593\n",
      "Min            0.4977         0.5593        -0.1856\n",
      "25%            0.7717         0.7790        -0.0220\n",
      "50%            0.8323         0.8156         0.0000\n",
      "75%            0.8846         0.8466         0.0443\n",
      "Max            0.9681         0.9681         0.2377\n"
     ]
    }
   ],
   "source": [
    "num_hard_negatives = 5\n",
    "hard_train_dataset, hard_eval_dataset, hard_eval_dataset_evaluator = get_hard_negatives(embedding_model_hard_negatives, num_hard_negatives=num_hard_negatives, num_hard_negatives_eval=5, train_dataset=train_dataset, dev_dataset=dev_dataset, df_full=df_full, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d0b31039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval steps: 156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (618 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='870' max='870' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [870/870 02:49, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Dev Set Map</th>\n",
       "      <th>Dev Set Mrr@10</th>\n",
       "      <th>Dev Set Ndcg@10</th>\n",
       "      <th>Dev Set Base Map</th>\n",
       "      <th>Dev Set Base Mrr@10</th>\n",
       "      <th>Dev Set Base Ndcg@10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>156</td>\n",
       "      <td>1.238900</td>\n",
       "      <td>0.797737</td>\n",
       "      <td>0.762452</td>\n",
       "      <td>0.762452</td>\n",
       "      <td>0.820094</td>\n",
       "      <td>0.568988</td>\n",
       "      <td>0.568988</td>\n",
       "      <td>0.595057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>312</td>\n",
       "      <td>0.547500</td>\n",
       "      <td>0.650652</td>\n",
       "      <td>0.768679</td>\n",
       "      <td>0.768679</td>\n",
       "      <td>0.824927</td>\n",
       "      <td>0.568988</td>\n",
       "      <td>0.568988</td>\n",
       "      <td>0.595057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>468</td>\n",
       "      <td>0.454700</td>\n",
       "      <td>0.594442</td>\n",
       "      <td>0.768143</td>\n",
       "      <td>0.768143</td>\n",
       "      <td>0.824545</td>\n",
       "      <td>0.568988</td>\n",
       "      <td>0.568988</td>\n",
       "      <td>0.595057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>624</td>\n",
       "      <td>0.442400</td>\n",
       "      <td>0.636502</td>\n",
       "      <td>0.768929</td>\n",
       "      <td>0.768929</td>\n",
       "      <td>0.825240</td>\n",
       "      <td>0.568988</td>\n",
       "      <td>0.568988</td>\n",
       "      <td>0.595057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>0.440600</td>\n",
       "      <td>0.589987</td>\n",
       "      <td>0.770226</td>\n",
       "      <td>0.770226</td>\n",
       "      <td>0.826212</td>\n",
       "      <td>0.568988</td>\n",
       "      <td>0.568988</td>\n",
       "      <td>0.595057</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    }
   ],
   "source": [
    "train_batch_size = 128\n",
    "max_length = 512\n",
    "model_to_finetune = \"cross-encoder/ms-marco-TinyBERT-L2-v2\"\n",
    "\n",
    "exp_runner = ExperimentRunner(\n",
    "    model_to_finetune,\n",
    "    train_batch_size,\n",
    "    num_epochs,\n",
    "    max_length,\n",
    "    experiment_name=experiment_name\n",
    ")\n",
    "exp_runner.run_experiment(hard_train_dataset, hard_eval_dataset, hard_eval_dataset_evaluator, num_hard_negatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d051f523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval steps: 5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (618 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='27832' max='27832' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [27832/27832 27:11, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Dev Set Map</th>\n",
       "      <th>Dev Set Mrr@10</th>\n",
       "      <th>Dev Set Ndcg@10</th>\n",
       "      <th>Dev Set Base Map</th>\n",
       "      <th>Dev Set Base Mrr@10</th>\n",
       "      <th>Dev Set Base Ndcg@10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.834100</td>\n",
       "      <td>0.595259</td>\n",
       "      <td>0.822738</td>\n",
       "      <td>0.822738</td>\n",
       "      <td>0.865859</td>\n",
       "      <td>0.568988</td>\n",
       "      <td>0.568988</td>\n",
       "      <td>0.595057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.611300</td>\n",
       "      <td>0.613535</td>\n",
       "      <td>0.839667</td>\n",
       "      <td>0.839667</td>\n",
       "      <td>0.878715</td>\n",
       "      <td>0.568988</td>\n",
       "      <td>0.568988</td>\n",
       "      <td>0.595057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.503200</td>\n",
       "      <td>0.673446</td>\n",
       "      <td>0.826536</td>\n",
       "      <td>0.826536</td>\n",
       "      <td>0.869118</td>\n",
       "      <td>0.568988</td>\n",
       "      <td>0.568988</td>\n",
       "      <td>0.595057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.313300</td>\n",
       "      <td>0.654007</td>\n",
       "      <td>0.838845</td>\n",
       "      <td>0.838845</td>\n",
       "      <td>0.878276</td>\n",
       "      <td>0.568988</td>\n",
       "      <td>0.568988</td>\n",
       "      <td>0.595057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25000</td>\n",
       "      <td>0.322200</td>\n",
       "      <td>0.663786</td>\n",
       "      <td>0.806810</td>\n",
       "      <td>0.806810</td>\n",
       "      <td>0.854552</td>\n",
       "      <td>0.568988</td>\n",
       "      <td>0.568988</td>\n",
       "      <td>0.595057</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    }
   ],
   "source": [
    "train_batch_size = 4\n",
    "max_length = 512\n",
    "model_to_finetune = \"cross-encoder/ms-marco-MiniLM-L12-v2\"\n",
    "\n",
    "exp_runner = ExperimentRunner(\n",
    "    model_to_finetune,\n",
    "    train_batch_size,\n",
    "    num_epochs,\n",
    "    max_length,\n",
    "    experiment_name=experiment_name\n",
    ")\n",
    "\n",
    "exp_runner.run_experiment(hard_train_dataset, hard_eval_dataset, hard_eval_dataset_evaluator, num_hard_negatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "64dcc1a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval steps: 2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (618 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13916' max='13916' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13916/13916 12:20, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Dev Set Map</th>\n",
       "      <th>Dev Set Mrr@10</th>\n",
       "      <th>Dev Set Ndcg@10</th>\n",
       "      <th>Dev Set Base Map</th>\n",
       "      <th>Dev Set Base Mrr@10</th>\n",
       "      <th>Dev Set Base Ndcg@10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.717600</td>\n",
       "      <td>0.572058</td>\n",
       "      <td>0.816583</td>\n",
       "      <td>0.816583</td>\n",
       "      <td>0.861199</td>\n",
       "      <td>0.568988</td>\n",
       "      <td>0.568988</td>\n",
       "      <td>0.595057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.535300</td>\n",
       "      <td>0.584391</td>\n",
       "      <td>0.828524</td>\n",
       "      <td>0.828524</td>\n",
       "      <td>0.870347</td>\n",
       "      <td>0.568988</td>\n",
       "      <td>0.568988</td>\n",
       "      <td>0.595057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.458400</td>\n",
       "      <td>0.649886</td>\n",
       "      <td>0.825321</td>\n",
       "      <td>0.825321</td>\n",
       "      <td>0.868094</td>\n",
       "      <td>0.568988</td>\n",
       "      <td>0.568988</td>\n",
       "      <td>0.595057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.345800</td>\n",
       "      <td>0.628598</td>\n",
       "      <td>0.832000</td>\n",
       "      <td>0.832000</td>\n",
       "      <td>0.872891</td>\n",
       "      <td>0.568988</td>\n",
       "      <td>0.568988</td>\n",
       "      <td>0.595057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>0.346300</td>\n",
       "      <td>0.602163</td>\n",
       "      <td>0.835476</td>\n",
       "      <td>0.835476</td>\n",
       "      <td>0.875564</td>\n",
       "      <td>0.568988</td>\n",
       "      <td>0.568988</td>\n",
       "      <td>0.595057</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    }
   ],
   "source": [
    "train_batch_size = 8\n",
    "max_length = 512\n",
    "model_to_finetune = \"cross-encoder/ms-marco-MiniLM-L6-v2\"\n",
    "\n",
    "exp_runner = ExperimentRunner(\n",
    "    model_to_finetune,\n",
    "    train_batch_size,\n",
    "    num_epochs,\n",
    "    max_length,\n",
    "    experiment_name=experiment_name\n",
    ")\n",
    "\n",
    "exp_runner.run_experiment(hard_train_dataset, hard_eval_dataset, hard_eval_dataset_evaluator, num_hard_negatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5f8f9fef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval steps: 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (618 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='55662' max='55662' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [55662/55662 1:27:23, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Dev Set Map</th>\n",
       "      <th>Dev Set Mrr@10</th>\n",
       "      <th>Dev Set Ndcg@10</th>\n",
       "      <th>Dev Set Base Map</th>\n",
       "      <th>Dev Set Base Mrr@10</th>\n",
       "      <th>Dev Set Base Ndcg@10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>1.126400</td>\n",
       "      <td>0.896045</td>\n",
       "      <td>0.828440</td>\n",
       "      <td>0.828798</td>\n",
       "      <td>0.870594</td>\n",
       "      <td>0.568988</td>\n",
       "      <td>0.568988</td>\n",
       "      <td>0.595057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.889300</td>\n",
       "      <td>1.002589</td>\n",
       "      <td>0.806786</td>\n",
       "      <td>0.806786</td>\n",
       "      <td>0.854178</td>\n",
       "      <td>0.568988</td>\n",
       "      <td>0.568988</td>\n",
       "      <td>0.595057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>0.636200</td>\n",
       "      <td>0.830475</td>\n",
       "      <td>0.770869</td>\n",
       "      <td>0.774440</td>\n",
       "      <td>0.830385</td>\n",
       "      <td>0.568988</td>\n",
       "      <td>0.568988</td>\n",
       "      <td>0.595057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40000</td>\n",
       "      <td>0.425400</td>\n",
       "      <td>0.968997</td>\n",
       "      <td>0.824286</td>\n",
       "      <td>0.825833</td>\n",
       "      <td>0.868394</td>\n",
       "      <td>0.568988</td>\n",
       "      <td>0.568988</td>\n",
       "      <td>0.595057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50000</td>\n",
       "      <td>0.404600</td>\n",
       "      <td>0.935117</td>\n",
       "      <td>0.758476</td>\n",
       "      <td>0.765560</td>\n",
       "      <td>0.823031</td>\n",
       "      <td>0.568988</td>\n",
       "      <td>0.568988</td>\n",
       "      <td>0.595057</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    }
   ],
   "source": [
    "\n",
    "train_batch_size = 2\n",
    "max_length = 512\n",
    "model_to_finetune = \"cross-encoder/ms-marco-electra-base\"\n",
    "\n",
    "exp_runner = ExperimentRunner(\n",
    "    model_to_finetune,\n",
    "    train_batch_size,\n",
    "    num_epochs,\n",
    "    max_length,\n",
    "    experiment_name=experiment_name\n",
    ")\n",
    "\n",
    "exp_runner.run_experiment(hard_train_dataset, hard_eval_dataset, hard_eval_dataset_evaluator, num_hard_negatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "be5120df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval steps: 20000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (519 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='111322' max='111322' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [111322/111322 3:00:54, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Dev Set Map</th>\n",
       "      <th>Dev Set Mrr@10</th>\n",
       "      <th>Dev Set Ndcg@10</th>\n",
       "      <th>Dev Set Base Map</th>\n",
       "      <th>Dev Set Base Mrr@10</th>\n",
       "      <th>Dev Set Base Ndcg@10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.853200</td>\n",
       "      <td>0.792676</td>\n",
       "      <td>0.831083</td>\n",
       "      <td>0.831083</td>\n",
       "      <td>0.872434</td>\n",
       "      <td>0.568988</td>\n",
       "      <td>0.568988</td>\n",
       "      <td>0.595057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40000</td>\n",
       "      <td>0.762000</td>\n",
       "      <td>0.719055</td>\n",
       "      <td>0.853679</td>\n",
       "      <td>0.853679</td>\n",
       "      <td>0.889632</td>\n",
       "      <td>0.568988</td>\n",
       "      <td>0.568988</td>\n",
       "      <td>0.595057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60000</td>\n",
       "      <td>0.545600</td>\n",
       "      <td>0.808621</td>\n",
       "      <td>0.852714</td>\n",
       "      <td>0.854143</td>\n",
       "      <td>0.889363</td>\n",
       "      <td>0.568988</td>\n",
       "      <td>0.568988</td>\n",
       "      <td>0.595057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80000</td>\n",
       "      <td>0.231100</td>\n",
       "      <td>0.742888</td>\n",
       "      <td>0.851798</td>\n",
       "      <td>0.851798</td>\n",
       "      <td>0.888238</td>\n",
       "      <td>0.568988</td>\n",
       "      <td>0.568988</td>\n",
       "      <td>0.595057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100000</td>\n",
       "      <td>0.190500</td>\n",
       "      <td>0.733588</td>\n",
       "      <td>0.859536</td>\n",
       "      <td>0.859893</td>\n",
       "      <td>0.894252</td>\n",
       "      <td>0.568988</td>\n",
       "      <td>0.568988</td>\n",
       "      <td>0.595057</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    }
   ],
   "source": [
    "train_batch_size = 1\n",
    "max_length = 512\n",
    "model_to_finetune = \"Alibaba-NLP/gte-reranker-modernbert-base\"\n",
    "\n",
    "exp_runner = ExperimentRunner(\n",
    "    model_to_finetune,\n",
    "    train_batch_size,\n",
    "    num_epochs,\n",
    "    max_length,\n",
    "    experiment_name=experiment_name\n",
    ")\n",
    "\n",
    "exp_runner.run_experiment(hard_train_dataset, hard_eval_dataset, hard_eval_dataset_evaluator, num_hard_negatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "57515d65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `margin` parameter is deprecated. Use the `absolute_margin` and/or `relative_margin` parameter instead. Setting `absolute_margin` to `0.05`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12842 unique queries out of 12853 total queries.\n",
      "Found an average of 1.001 positives per query.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 109/109 [00:24<00:00,  4.39it/s]\n",
      "Batches: 100%|██████████| 201/201 [00:05<00:00, 33.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric       Positive       Negative     Difference\n",
      "Count          12,853         25,740               \n",
      "Mean           0.8195         0.7811         0.0779\n",
      "Median         0.8329         0.7925         0.0631\n",
      "Std            0.0826         0.0525         0.0346\n",
      "Min            0.3809         0.5051        -0.0251\n",
      "25%            0.7696         0.7506         0.0537\n",
      "50%            0.8329         0.7925         0.0631\n",
      "75%            0.8834         0.8186         0.0897\n",
      "Max            0.9881         0.8966         0.2938\n",
      "Skipped 561,618 potential negatives (42.46%) due to the absolute_margin of 0.05.\n",
      "Could not find enough negatives for 12819 samples (33.25%). Consider adjusting the range_max, range_min, absolute_margin and max_score parameters if you'd like to find more valid negatives.\n",
      "======================\n",
      "Setting range_max to 5 based on the provided parameters.\n",
      "Found 1399 unique queries out of 1400 total queries.\n",
      "Found an average of 1.001 positives per query.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 121/121 [00:27<00:00,  4.38it/s]\n",
      "Batches: 100%|██████████| 22/22 [00:00<00:00, 34.80it/s]\n",
      "When using `include_positives=True`, `output_format` will be set to `\"n-tuple\"` to ensure that the ranking order is preserved.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric       Positive       Negative     Difference\n",
      "Count           1,400          4,200               \n",
      "Mean           0.8219         0.8090         0.0129\n",
      "Median         0.8323         0.8151         0.0112\n",
      "Std            0.0783         0.0501         0.0631\n",
      "Min            0.4977         0.5685        -0.1856\n",
      "25%            0.7717         0.7798        -0.0264\n",
      "50%            0.8323         0.8151         0.0113\n",
      "75%            0.8846         0.8437         0.0524\n",
      "Max            0.9681         0.9451         0.2224\n",
      "======================\n",
      "Setting range_max to 5 based on the provided parameters.\n",
      "Found 1399 unique queries out of 1400 total queries.\n",
      "Found an average of 1.001 positives per query.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 121/121 [00:27<00:00,  4.33it/s]\n",
      "Batches: 100%|██████████| 22/22 [00:00<00:00, 35.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric       Positive       Negative     Difference\n",
      "Count           1,400          4,200               \n",
      "Mean           0.8219         0.8213         0.0006\n",
      "Median         0.8323         0.8252        -0.0000\n",
      "Std            0.0783         0.0552         0.0550\n",
      "Min            0.4977         0.5707        -0.1856\n",
      "25%            0.7717         0.7878        -0.0264\n",
      "50%            0.8323         0.8252        -0.0000\n",
      "75%            0.8846         0.8577         0.0252\n",
      "Max            0.9681         0.9681         0.2158\n"
     ]
    }
   ],
   "source": [
    "num_hard_negatives = 3\n",
    "num_hard_negatives_eval = 3\n",
    "hard_train_dataset, hard_eval_dataset, hard_eval_dataset_evaluator = get_hard_negatives(embedding_model_hard_negatives, num_hard_negatives=num_hard_negatives, num_hard_negatives_eval=num_hard_negatives_eval, train_dataset=train_dataset, dev_dataset=dev_dataset, df_full=df_full, batch_size=64)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15f90a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval steps: 20000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (674 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='60001' max='77150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [60001/77150 1:50:06 < 31:28, 9.08 it/s, Epoch 1.56/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Dev Set Map</th>\n",
       "      <th>Dev Set Mrr@10</th>\n",
       "      <th>Dev Set Ndcg@10</th>\n",
       "      <th>Dev Set Base Map</th>\n",
       "      <th>Dev Set Base Mrr@10</th>\n",
       "      <th>Dev Set Base Ndcg@10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.731900</td>\n",
       "      <td>0.803203</td>\n",
       "      <td>0.817083</td>\n",
       "      <td>0.819583</td>\n",
       "      <td>0.872392</td>\n",
       "      <td>0.559881</td>\n",
       "      <td>0.559881</td>\n",
       "      <td>0.578612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40000</td>\n",
       "      <td>0.621300</td>\n",
       "      <td>0.703173</td>\n",
       "      <td>0.792976</td>\n",
       "      <td>0.794405</td>\n",
       "      <td>0.852109</td>\n",
       "      <td>0.559881</td>\n",
       "      <td>0.559881</td>\n",
       "      <td>0.578612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60000</td>\n",
       "      <td>0.412000</td>\n",
       "      <td>0.794674</td>\n",
       "      <td>0.838869</td>\n",
       "      <td>0.838869</td>\n",
       "      <td>0.879841</td>\n",
       "      <td>0.559881</td>\n",
       "      <td>0.559881</td>\n",
       "      <td>0.578612</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    }
   ],
   "source": [
    "train_batch_size = 1\n",
    "max_length = 512\n",
    "model_to_finetune = \"Alibaba-NLP/gte-multilingual-reranker-base\"\n",
    "\n",
    "exp_runner = ExperimentRunner(\n",
    "    model_to_finetune,\n",
    "    train_batch_size,\n",
    "    num_epochs,\n",
    "    max_length,\n",
    "    experiment_name=experiment_name\n",
    ")\n",
    "exp_runner.run_experiment(hard_train_dataset, hard_eval_dataset, hard_eval_dataset_evaluator, num_hard_negatives, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8cf480d",
   "metadata": {},
   "source": [
    "Note that the metrics in the following cells are overly optimistic, since we evaluate on the whole data, which includes the training data. We do this on the whole data so that we have enough data for the ensemble learning part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c2afedbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reranking: 100%|██████████| 1400/1400 [05:55<00:00,  3.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 1\n",
      "Number of queries in top 1: 940\n",
      "Number of queries not in top 1: 460\n",
      "k = 5\n",
      "Number of queries in top 5: 1088\n",
      "Number of queries not in top 5: 312\n",
      "k = 10\n",
      "Number of queries in top 10: 1117\n",
      "Number of queries not in top 10: 283\n",
      "Evaluation results: {1: np.float64(0.6714285714285714), 5: np.float64(0.715642857142857), 10: np.float64(0.7184308390022676)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df_query_single = experiment_single_bm25(df_collection, df_query_dev, stemmer=stemmer, k=30)\n",
    "model_name = f\"models/gte-reranker-modernbert-base-finetuned{experiment_name}\"\n",
    "tokenizer, model = initialize_reranker(model_name)\n",
    "df_query = rerank_with_alibaba(df_query_single, df_collection, tokenizer, model, k=10, batch_size=100)\n",
    "df_query.to_parquet(f'data/reranked_results_alibaba_finetuned{experiment_name}.parquet')\n",
    "results = evaluate_reranked_results(df_query)\n",
    "print(f\"Evaluation results: {results}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1871660",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reranking: 100%|██████████| 1400/1400 [05:33<00:00,  4.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 1\n",
      "Number of queries in top 1: 905\n",
      "Number of queries not in top 1: 495\n",
      "k = 5\n",
      "Number of queries in top 5: 1065\n",
      "Number of queries not in top 5: 335\n",
      "k = 10\n",
      "Number of queries in top 10: 1107\n",
      "Number of queries not in top 10: 293\n",
      "Evaluation results: {1: np.float64(0.6464285714285715), 5: np.float64(0.6916547619047618), 10: np.float64(0.695531179138322)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df_query_dev_single = experiment_single_bm25(df_collection, df_query_dev, stemmer=stemmer, k=30)\n",
    "model_name = f\"models/gte-multilingual-reranker-base-finetuned{experiment_name}\"\n",
    "tokenizer, model = initialize_reranker(model_name)\n",
    "df_query = rerank_with_alibaba(df_query_dev_single, df_collection, tokenizer, model, k=10, batch_size=100)\n",
    "df_query.to_parquet(f'data/reranked_results_alibaba_multilingual_finetuned{experiment_name}.parquet')\n",
    "results = evaluate_reranked_results(df_query)\n",
    "print(f\"Evaluation results: {results}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9f615c0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reranking: 100%|██████████| 1400/1400 [02:57<00:00,  7.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 1\n",
      "Number of queries in top 1: 916\n",
      "Number of queries not in top 1: 484\n",
      "k = 5\n",
      "Number of queries in top 5: 1073\n",
      "Number of queries not in top 5: 327\n",
      "k = 10\n",
      "Number of queries in top 10: 1105\n",
      "Number of queries not in top 10: 295\n",
      "Evaluation results: {1: np.float64(0.6542857142857142), 5: np.float64(0.6985357142857144), 10: np.float64(0.7015266439909298)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df_query_dev_single = experiment_single_bm25(df_collection, df_query_dev, stemmer=stemmer, k=30)\n",
    "model_name = f\"models/ms-marco-MiniLM-L12-v2-finetuned{experiment_name}\"\n",
    "tokenizer, model = initialize_reranker(model_name)\n",
    "df_query = rerank_with_alibaba(df_query_dev_single, df_collection, tokenizer, model, k=10, batch_size=100)\n",
    "df_query.to_parquet(f\"data/reranked_results_miniLM12_finetuned{experiment_name}.parquet\")\n",
    "results = evaluate_reranked_results(df_query)\n",
    "print(f\"Evaluation results: {results}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1726416c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reranking: 100%|██████████| 1400/1400 [02:32<00:00,  9.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 1\n",
      "Number of queries in top 1: 902\n",
      "Number of queries not in top 1: 498\n",
      "k = 5\n",
      "Number of queries in top 5: 1068\n",
      "Number of queries not in top 5: 332\n",
      "k = 10\n",
      "Number of queries in top 10: 1102\n",
      "Number of queries not in top 10: 298\n",
      "Evaluation results: {1: np.float64(0.6442857142857142), 5: np.float64(0.6916785714285715), 10: np.float64(0.6949016439909298)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df_query_dev_single = experiment_single_bm25(df_collection, df_query_dev, stemmer=stemmer, k=30)\n",
    "model_name = f\"models/ms-marco-MiniLM-L6-v2-finetuned{experiment_name}\"\n",
    "tokenizer, model = initialize_reranker(model_name)\n",
    "df_query = rerank_with_alibaba(df_query_dev_single, df_collection, tokenizer, model, k=10, batch_size=100)\n",
    "df_query.to_parquet(f\"data/reranked_results_miniLM6_finetuned.parquet{experiment_name}\")\n",
    "results = evaluate_reranked_results(df_query)\n",
    "print(f\"Evaluation results: {results}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e1bc22bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reranking: 100%|██████████| 1400/1400 [02:06<00:00, 11.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 1\n",
      "Number of queries in top 1: 789\n",
      "Number of queries not in top 1: 611\n",
      "k = 5\n",
      "Number of queries in top 5: 1003\n",
      "Number of queries not in top 5: 397\n",
      "k = 10\n",
      "Number of queries in top 10: 1070\n",
      "Number of queries not in top 10: 330\n",
      "Evaluation results: {1: np.float64(0.5635714285714286), 5: np.float64(0.6248452380952381), 10: np.float64(0.6315274943310658)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df_query_dev_single = experiment_single_bm25(df_collection, df_query_dev, stemmer=stemmer, k=30)\n",
    "model_name = f\"models/ms-marco-TinyBERT-L2-v2-finetuned{experiment_name}\"\n",
    "tokenizer, model = initialize_reranker(model_name)\n",
    "df_query = rerank_with_alibaba(df_query_dev_single, df_collection, tokenizer, model, k=10, batch_size=100)\n",
    "df_query.to_parquet(f\"data/reranked_results_tinyBERT_finetuned{experiment_name}.parquet\")\n",
    "results = evaluate_reranked_results(df_query)\n",
    "print(f\"Evaluation results: {results}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2b096aa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reranking: 100%|██████████| 1400/1400 [05:22<00:00,  4.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 1\n",
      "Number of queries in top 1: 734\n",
      "Number of queries not in top 1: 666\n",
      "k = 5\n",
      "Number of queries in top 5: 1055\n",
      "Number of queries not in top 5: 345\n",
      "k = 10\n",
      "Number of queries in top 10: 1105\n",
      "Number of queries not in top 10: 295\n",
      "Evaluation results: {1: np.float64(0.5242857142857142), 5: np.float64(0.6165119047619046), 10: np.float64(0.6216179138321996)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df_query_dev_single = experiment_single_bm25(df_collection, df_query_dev, stemmer=stemmer, k=30)\n",
    "model_name = f\"models/ms-marco-electra-base-finetuned{experiment_name}\"\n",
    "tokenizer, model = initialize_reranker(model_name)\n",
    "df_query = rerank_with_alibaba(df_query_dev_single, df_collection, tokenizer, model, k=10, batch_size=50, max_length=None )\n",
    "df_query.to_parquet(f\"data/reranked_results_electra_finetuned.parquet{experiment_name}\")\n",
    "results = evaluate_reranked_results(df_query)\n",
    "print(f\"Evaluation results: {results}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd9ba0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
