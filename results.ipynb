{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "62d694f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "01b62ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_performance_mrr(data, col_gold, col_pred, list_k = [1, 5, 10]):\n",
    "    d_performance = {}\n",
    "    for k in list_k:\n",
    "        data[\"in_topx\"] = data.apply(lambda x: (1/([i for i in x[col_pred][:k]].index(x[col_gold]) + 1) if x[col_gold] in [i for i in x[col_pred][:k]] else 0), axis=1)\n",
    "        d_performance[k] = data[\"in_topx\"].mean()\n",
    "        print(f\"{k = }\")\n",
    "        in_topx = data[\"in_topx\"] > 0\n",
    "        print(f\"Number of queries in top {k}: {in_topx.sum()}\")\n",
    "        print(f\"Number of queries not in top {k}: {len(data) - in_topx.sum()}\")\n",
    "    return d_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1bc091d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_reranked_results(df_query, col_gold='cord_uid', col_pred='reranked_topk', list_k=[1, 5, 10]):\n",
    "    return get_performance_mrr(df_query, col_gold, col_pred, list_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1858a4f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: reranked_results_alibaba_finetuned_bge-small-en-v1.5_epochs2_crossentropyloss.parquet\n",
      "k = 1\n",
      "Number of queries in top 1: 912\n",
      "Number of queries not in top 1: 488\n",
      "k = 5\n",
      "Number of queries in top 5: 1078\n",
      "Number of queries not in top 5: 322\n",
      "k = 10\n",
      "Number of queries in top 10: 1111\n",
      "Number of queries not in top 10: 289\n",
      "Processing file: reranked_results_miniLM12_finetuned_bge-small-en-v1.5_epochs2_crossentropyloss.parquet\n",
      "k = 1\n",
      "Number of queries in top 1: 912\n",
      "Number of queries not in top 1: 488\n",
      "k = 5\n",
      "Number of queries in top 5: 1072\n",
      "Number of queries not in top 5: 328\n",
      "k = 10\n",
      "Number of queries in top 10: 1109\n",
      "Number of queries not in top 10: 291\n",
      "Processing file: reranked_results_tinyBERT_finetuned_bge-small-en-v1.5_epochs2_crossentropyloss.parquet\n",
      "k = 1\n",
      "Number of queries in top 1: 788\n",
      "Number of queries not in top 1: 612\n",
      "k = 5\n",
      "Number of queries in top 5: 1010\n",
      "Number of queries not in top 5: 390\n",
      "k = 10\n",
      "Number of queries in top 10: 1071\n",
      "Number of queries not in top 10: 329\n",
      "Processing file: reranked_results_alibaba_multilingual_finetuned_bge-small-en-v1.5_epochs1_crossentropyloss.parquet\n",
      "k = 1\n",
      "Number of queries in top 1: 905\n",
      "Number of queries not in top 1: 495\n",
      "k = 5\n",
      "Number of queries in top 5: 1065\n",
      "Number of queries not in top 5: 335\n",
      "k = 10\n",
      "Number of queries in top 10: 1107\n",
      "Number of queries not in top 10: 293\n",
      "Processing file: reranked_results_alibaba_finetuned_bge-small-en-v1.5_epochs2_crossentropyloss_stricter embedding.parquet\n",
      "k = 1\n",
      "Number of queries in top 1: 940\n",
      "Number of queries not in top 1: 460\n",
      "k = 5\n",
      "Number of queries in top 5: 1088\n",
      "Number of queries not in top 5: 312\n",
      "k = 10\n",
      "Number of queries in top 10: 1117\n",
      "Number of queries not in top 10: 283\n",
      "Processing file: reranked_results_miniLM12_finetuned_bge-small-en-v1.5_epochs2_crossentropyloss_stricter embedding.parquet\n",
      "k = 1\n",
      "Number of queries in top 1: 916\n",
      "Number of queries not in top 1: 484\n",
      "k = 5\n",
      "Number of queries in top 5: 1073\n",
      "Number of queries not in top 5: 327\n",
      "k = 10\n",
      "Number of queries in top 10: 1105\n",
      "Number of queries not in top 10: 295\n",
      "Processing file: reranked_results_tinyBERT_finetuned_bge-small-en-v1.5_epochs2_crossentropyloss_stricter embedding.parquet\n",
      "k = 1\n",
      "Number of queries in top 1: 789\n",
      "Number of queries not in top 1: 611\n",
      "k = 5\n",
      "Number of queries in top 5: 1003\n",
      "Number of queries not in top 5: 397\n",
      "k = 10\n",
      "Number of queries in top 10: 1070\n",
      "Number of queries not in top 10: 330\n",
      "Processing file: reranked_results_electra_finetuned_bge-small-en-v1.5_epochs2_crossentropyloss.parquet\n",
      "k = 1\n",
      "Number of queries in top 1: 900\n",
      "Number of queries not in top 1: 500\n",
      "k = 5\n",
      "Number of queries in top 5: 1077\n",
      "Number of queries not in top 5: 323\n",
      "k = 10\n",
      "Number of queries in top 10: 1112\n",
      "Number of queries not in top 10: 288\n",
      "Processing file: reranked_results_electra_finetuned_bge-small-en-v1.5_epochs2_crossentropyloss_stricter embedding.parquet\n",
      "k = 1\n",
      "Number of queries in top 1: 734\n",
      "Number of queries not in top 1: 666\n",
      "k = 5\n",
      "Number of queries in top 5: 1055\n",
      "Number of queries not in top 5: 345\n",
      "k = 10\n",
      "Number of queries in top 10: 1105\n",
      "Number of queries not in top 10: 295\n",
      "Processing file: reranked_results_miniLM6_finetuned_bge-small-en-v1.5_epochs2_crossentropyloss.parquet\n",
      "k = 1\n",
      "Number of queries in top 1: 892\n",
      "Number of queries not in top 1: 508\n",
      "k = 5\n",
      "Number of queries in top 5: 1071\n",
      "Number of queries not in top 5: 329\n",
      "k = 10\n",
      "Number of queries in top 10: 1102\n",
      "Number of queries not in top 10: 298\n",
      "Processing file: reranked_results_miniLM6_finetuned_bge-small-en-v1.5_epochs2_crossentropyloss_stricter embedding.parquet\n",
      "k = 1\n",
      "Number of queries in top 1: 902\n",
      "Number of queries not in top 1: 498\n",
      "k = 5\n",
      "Number of queries in top 5: 1068\n",
      "Number of queries not in top 5: 332\n",
      "k = 10\n",
      "Number of queries in top 10: 1102\n",
      "Number of queries not in top 10: 298\n",
      "Processing file: reranked_results_alibaba.parquet\n",
      "k = 1\n",
      "Number of queries in top 1: 945\n",
      "Number of queries not in top 1: 455\n",
      "k = 5\n",
      "Number of queries in top 5: 1092\n",
      "Number of queries not in top 5: 308\n",
      "k = 10\n",
      "Number of queries in top 10: 1120\n",
      "Number of queries not in top 10: 280\n",
      "Processing file: reranked_results_alibaba_finetuned_bge-small-en-v1.5_epochs2_lambdaloss.parquet\n",
      "k = 1\n",
      "Number of queries in top 1: 951\n",
      "Number of queries not in top 1: 449\n",
      "k = 5\n",
      "Number of queries in top 5: 1094\n",
      "Number of queries not in top 5: 306\n",
      "k = 10\n",
      "Number of queries in top 10: 1120\n",
      "Number of queries not in top 10: 280\n",
      "Processing file: reranked_results_alibaba_finetuned_bge-small-en-v1.5_epochs2_lambdaloss_learningrate.parquet\n",
      "k = 1\n",
      "Number of queries in top 1: 980\n",
      "Number of queries not in top 1: 420\n",
      "k = 5\n",
      "Number of queries in top 5: 1113\n",
      "Number of queries not in top 5: 287\n",
      "k = 10\n",
      "Number of queries in top 10: 1123\n",
      "Number of queries not in top 10: 277\n",
      "Processing file: reranked_results_alibaba_finetuned_bge-small-en-v1.5_epochs2_lambdaloss_learningrate_k100.parquet\n",
      "k = 1\n",
      "Number of queries in top 1: 997\n",
      "Number of queries not in top 1: 403\n",
      "k = 5\n",
      "Number of queries in top 5: 1145\n",
      "Number of queries not in top 5: 255\n",
      "k = 10\n",
      "Number of queries in top 10: 1176\n",
      "Number of queries not in top 10: 224\n",
      "Processing file: reranked_results_alibaba_finetuned_bge-small-en-v1.5_epochs2_lambdaloss_learningrate_k1000.parquet\n",
      "k = 1\n",
      "Number of queries in top 1: 1014\n",
      "Number of queries not in top 1: 386\n",
      "k = 5\n",
      "Number of queries in top 5: 1181\n",
      "Number of queries not in top 5: 219\n",
      "k = 10\n",
      "Number of queries in top 10: 1215\n",
      "Number of queries not in top 10: 185\n",
      "Processing file: reranked_results_alibaba_finetuned_bge-small-en-v1.5_epochs2_lambdaloss_learningrate_testset.parquet\n",
      "Column 'cord_uid' not found in reranked_results_alibaba_finetuned_bge-small-en-v1.5_epochs2_lambdaloss_learningrate_testset.parquet. Skipping evaluation.\n",
      "Processing file: reranked_results_alibaba_finetuned_static-retrieval-mrl-en-v1_epochs2_crossentropyloss.parquet\n",
      "k = 1\n",
      "Number of queries in top 1: 943\n",
      "Number of queries not in top 1: 457\n",
      "k = 5\n",
      "Number of queries in top 5: 1088\n",
      "Number of queries not in top 5: 312\n",
      "k = 10\n",
      "Number of queries in top 10: 1114\n",
      "Number of queries not in top 10: 286\n",
      "Processing file: reranked_results_alibaba_multilingual.parquet\n",
      "k = 1\n",
      "Number of queries in top 1: 898\n",
      "Number of queries not in top 1: 502\n",
      "k = 5\n",
      "Number of queries in top 5: 1068\n",
      "Number of queries not in top 5: 332\n",
      "k = 10\n",
      "Number of queries in top 10: 1100\n",
      "Number of queries not in top 10: 300\n",
      "Processing file: reranked_results_alibaba_multilingual_finetuned_bge-small-en-v1.5_epochs2_lambdaloss.parquet\n",
      "k = 1\n",
      "Number of queries in top 1: 890\n",
      "Number of queries not in top 1: 510\n",
      "k = 5\n",
      "Number of queries in top 5: 1088\n",
      "Number of queries not in top 5: 312\n",
      "k = 10\n",
      "Number of queries in top 10: 1118\n",
      "Number of queries not in top 10: 282\n",
      "Processing file: reranked_results_alibaba_multilingual_finetuned_static-retrieval-mrl-en-v1_epochs2_crossentropyloss.parquet\n",
      "k = 1\n",
      "Number of queries in top 1: 882\n",
      "Number of queries not in top 1: 518\n",
      "k = 5\n",
      "Number of queries in top 5: 1069\n",
      "Number of queries not in top 5: 331\n",
      "k = 10\n",
      "Number of queries in top 10: 1107\n",
      "Number of queries not in top 10: 293\n",
      "Processing file: reranked_results_electra.parquet\n",
      "k = 1\n",
      "Number of queries in top 1: 717\n",
      "Number of queries not in top 1: 683\n",
      "k = 5\n",
      "Number of queries in top 5: 932\n",
      "Number of queries not in top 5: 468\n",
      "k = 10\n",
      "Number of queries in top 10: 1031\n",
      "Number of queries not in top 10: 369\n",
      "Processing file: reranked_results_miniLM12.parquet\n",
      "k = 1\n",
      "Number of queries in top 1: 778\n",
      "Number of queries not in top 1: 622\n",
      "k = 5\n",
      "Number of queries in top 5: 978\n",
      "Number of queries not in top 5: 422\n",
      "k = 10\n",
      "Number of queries in top 10: 1047\n",
      "Number of queries not in top 10: 353\n",
      "Processing file: reranked_results_miniLM12_finetuned_bge-small-en-v1.5_epochs2_lambdaloss.parquet\n",
      "k = 1\n",
      "Number of queries in top 1: 874\n",
      "Number of queries not in top 1: 526\n",
      "k = 5\n",
      "Number of queries in top 5: 1036\n",
      "Number of queries not in top 5: 364\n",
      "k = 10\n",
      "Number of queries in top 10: 1088\n",
      "Number of queries not in top 10: 312\n",
      "Processing file: reranked_results_miniLM12_finetuned_static-retrieval-mrl-en-v1_epochs2_crossentropyloss.parquet\n",
      "k = 1\n",
      "Number of queries in top 1: 925\n",
      "Number of queries not in top 1: 475\n",
      "k = 5\n",
      "Number of queries in top 5: 1061\n",
      "Number of queries not in top 5: 339\n",
      "k = 10\n",
      "Number of queries in top 10: 1104\n",
      "Number of queries not in top 10: 296\n",
      "Processing file: reranked_results_miniLM6.parquet\n",
      "k = 1\n",
      "Number of queries in top 1: 807\n",
      "Number of queries not in top 1: 593\n",
      "k = 5\n",
      "Number of queries in top 5: 1008\n",
      "Number of queries not in top 5: 392\n",
      "k = 10\n",
      "Number of queries in top 10: 1068\n",
      "Number of queries not in top 10: 332\n",
      "Processing file: reranked_results_mxbai.parquet\n",
      "k = 1\n",
      "Number of queries in top 1: 963\n",
      "Number of queries not in top 1: 437\n",
      "k = 5\n",
      "Number of queries in top 5: 1100\n",
      "Number of queries not in top 5: 300\n",
      "k = 10\n",
      "Number of queries in top 10: 1123\n",
      "Number of queries not in top 10: 277\n",
      "Processing file: reranked_results_tinyBERT.parquet\n",
      "k = 1\n",
      "Number of queries in top 1: 784\n",
      "Number of queries not in top 1: 616\n",
      "k = 5\n",
      "Number of queries in top 5: 993\n",
      "Number of queries not in top 5: 407\n",
      "k = 10\n",
      "Number of queries in top 10: 1057\n",
      "Number of queries not in top 10: 343\n",
      "Processing file: reranked_results_tinyBERT_finetuned_bge-small-en-v1.5_epochs2_lambdaloss.parquet\n",
      "k = 1\n",
      "Number of queries in top 1: 794\n",
      "Number of queries not in top 1: 606\n",
      "k = 5\n",
      "Number of queries in top 5: 995\n",
      "Number of queries not in top 5: 405\n",
      "k = 10\n",
      "Number of queries in top 10: 1059\n",
      "Number of queries not in top 10: 341\n",
      "Processing file: reranked_results_tinyBERT_finetuned_static-retrieval-mrl-en-v1_epochs2_crossentropyloss.parquet\n",
      "k = 1\n",
      "Number of queries in top 1: 786\n",
      "Number of queries not in top 1: 614\n",
      "k = 5\n",
      "Number of queries in top 5: 1015\n",
      "Number of queries not in top 5: 385\n",
      "k = 10\n",
      "Number of queries in top 10: 1078\n",
      "Number of queries not in top 10: 322\n",
      "Processing file: reranked_results_electra_finetuned_bge-small-en-v1.5_epochs2_lambdaloss.parquet\n",
      "k = 1\n",
      "Number of queries in top 1: 872\n",
      "Number of queries not in top 1: 528\n",
      "k = 5\n",
      "Number of queries in top 5: 1055\n",
      "Number of queries not in top 5: 345\n",
      "k = 10\n",
      "Number of queries in top 10: 1106\n",
      "Number of queries not in top 10: 294\n",
      "Processing file: reranked_results_electra_finetuned_static-retrieval-mrl-en-v1_epochs2_crossentropyloss.parquet\n",
      "k = 1\n",
      "Number of queries in top 1: 900\n",
      "Number of queries not in top 1: 500\n",
      "k = 5\n",
      "Number of queries in top 5: 1080\n",
      "Number of queries not in top 5: 320\n",
      "k = 10\n",
      "Number of queries in top 10: 1107\n",
      "Number of queries not in top 10: 293\n",
      "Processing file: reranked_results_miniLM6_finetuned_bge-small-en-v1.5_epochs2_lambdaloss.parquet\n",
      "k = 1\n",
      "Number of queries in top 1: 861\n",
      "Number of queries not in top 1: 539\n",
      "k = 5\n",
      "Number of queries in top 5: 1037\n",
      "Number of queries not in top 5: 363\n",
      "k = 10\n",
      "Number of queries in top 10: 1090\n",
      "Number of queries not in top 10: 310\n",
      "Processing file: reranked_results_miniLM6_finetuned_static-retrieval-mrl-en-v1_epochs2_crossentropyloss.parquet\n",
      "k = 1\n",
      "Number of queries in top 1: 914\n",
      "Number of queries not in top 1: 486\n",
      "k = 5\n",
      "Number of queries in top 5: 1073\n",
      "Number of queries not in top 5: 327\n",
      "k = 10\n",
      "Number of queries in top 10: 1108\n",
      "Number of queries not in top 10: 292\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>MRR@1</th>\n",
       "      <th>MRR@5</th>\n",
       "      <th>MRR@10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>reranked_results_alibaba_finetuned_bge-small-e...</td>\n",
       "      <td>0.651429</td>\n",
       "      <td>0.698833</td>\n",
       "      <td>0.702113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>reranked_results_miniLM12_finetuned_bge-small-...</td>\n",
       "      <td>0.651429</td>\n",
       "      <td>0.697357</td>\n",
       "      <td>0.700896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>reranked_results_tinyBERT_finetuned_bge-small-...</td>\n",
       "      <td>0.562857</td>\n",
       "      <td>0.625786</td>\n",
       "      <td>0.631567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>reranked_results_alibaba_multilingual_finetune...</td>\n",
       "      <td>0.646429</td>\n",
       "      <td>0.691655</td>\n",
       "      <td>0.695531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>reranked_results_alibaba_finetuned_bge-small-e...</td>\n",
       "      <td>0.671429</td>\n",
       "      <td>0.715643</td>\n",
       "      <td>0.718431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>reranked_results_miniLM12_finetuned_bge-small-...</td>\n",
       "      <td>0.654286</td>\n",
       "      <td>0.698536</td>\n",
       "      <td>0.701527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>reranked_results_tinyBERT_finetuned_bge-small-...</td>\n",
       "      <td>0.563571</td>\n",
       "      <td>0.624845</td>\n",
       "      <td>0.631527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>reranked_results_electra_finetuned_bge-small-e...</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.692107</td>\n",
       "      <td>0.695505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>reranked_results_electra_finetuned_bge-small-e...</td>\n",
       "      <td>0.524286</td>\n",
       "      <td>0.616512</td>\n",
       "      <td>0.621618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>reranked_results_miniLM6_finetuned_bge-small-e...</td>\n",
       "      <td>0.637143</td>\n",
       "      <td>0.688429</td>\n",
       "      <td>0.691478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>reranked_results_miniLM6_finetuned_bge-small-e...</td>\n",
       "      <td>0.644286</td>\n",
       "      <td>0.691679</td>\n",
       "      <td>0.694902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>reranked_results_alibaba.parquet</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>0.717571</td>\n",
       "      <td>0.720374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>reranked_results_alibaba_finetuned_bge-small-e...</td>\n",
       "      <td>0.679286</td>\n",
       "      <td>0.720357</td>\n",
       "      <td>0.722709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>reranked_results_alibaba_finetuned_bge-small-e...</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.739810</td>\n",
       "      <td>0.740792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>reranked_results_alibaba_finetuned_bge-small-e...</td>\n",
       "      <td>0.712143</td>\n",
       "      <td>0.756560</td>\n",
       "      <td>0.759488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>reranked_results_alibaba_finetuned_bge-small-e...</td>\n",
       "      <td>0.724286</td>\n",
       "      <td>0.772524</td>\n",
       "      <td>0.775613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>reranked_results_alibaba_finetuned_static-retr...</td>\n",
       "      <td>0.673571</td>\n",
       "      <td>0.716905</td>\n",
       "      <td>0.719349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>reranked_results_alibaba_multilingual.parquet</td>\n",
       "      <td>0.641429</td>\n",
       "      <td>0.691750</td>\n",
       "      <td>0.694914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>reranked_results_alibaba_multilingual_finetune...</td>\n",
       "      <td>0.635714</td>\n",
       "      <td>0.693952</td>\n",
       "      <td>0.696824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>reranked_results_alibaba_multilingual_finetune...</td>\n",
       "      <td>0.630000</td>\n",
       "      <td>0.683357</td>\n",
       "      <td>0.687158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>reranked_results_electra.parquet</td>\n",
       "      <td>0.512143</td>\n",
       "      <td>0.571131</td>\n",
       "      <td>0.580312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>reranked_results_miniLM12.parquet</td>\n",
       "      <td>0.555714</td>\n",
       "      <td>0.610750</td>\n",
       "      <td>0.617365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>reranked_results_miniLM12_finetuned_bge-small-...</td>\n",
       "      <td>0.624286</td>\n",
       "      <td>0.671500</td>\n",
       "      <td>0.676541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>reranked_results_miniLM12_finetuned_static-ret...</td>\n",
       "      <td>0.660714</td>\n",
       "      <td>0.701810</td>\n",
       "      <td>0.706007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>reranked_results_miniLM6.parquet</td>\n",
       "      <td>0.576429</td>\n",
       "      <td>0.630452</td>\n",
       "      <td>0.636363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>reranked_results_mxbai.parquet</td>\n",
       "      <td>0.687857</td>\n",
       "      <td>0.726619</td>\n",
       "      <td>0.728757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>reranked_results_tinyBERT.parquet</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.617786</td>\n",
       "      <td>0.624103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>reranked_results_tinyBERT_finetuned_bge-small-...</td>\n",
       "      <td>0.567143</td>\n",
       "      <td>0.622262</td>\n",
       "      <td>0.628581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>reranked_results_tinyBERT_finetuned_static-ret...</td>\n",
       "      <td>0.561429</td>\n",
       "      <td>0.627048</td>\n",
       "      <td>0.633067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>reranked_results_electra_finetuned_bge-small-e...</td>\n",
       "      <td>0.622857</td>\n",
       "      <td>0.675036</td>\n",
       "      <td>0.679935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>reranked_results_electra_finetuned_static-retr...</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.695310</td>\n",
       "      <td>0.697880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>reranked_results_miniLM6_finetuned_bge-small-e...</td>\n",
       "      <td>0.615000</td>\n",
       "      <td>0.665238</td>\n",
       "      <td>0.670477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>reranked_results_miniLM6_finetuned_static-retr...</td>\n",
       "      <td>0.652857</td>\n",
       "      <td>0.698857</td>\n",
       "      <td>0.702219</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 name     MRR@1     MRR@5  \\\n",
       "0   reranked_results_alibaba_finetuned_bge-small-e...  0.651429  0.698833   \n",
       "1   reranked_results_miniLM12_finetuned_bge-small-...  0.651429  0.697357   \n",
       "2   reranked_results_tinyBERT_finetuned_bge-small-...  0.562857  0.625786   \n",
       "3   reranked_results_alibaba_multilingual_finetune...  0.646429  0.691655   \n",
       "4   reranked_results_alibaba_finetuned_bge-small-e...  0.671429  0.715643   \n",
       "5   reranked_results_miniLM12_finetuned_bge-small-...  0.654286  0.698536   \n",
       "6   reranked_results_tinyBERT_finetuned_bge-small-...  0.563571  0.624845   \n",
       "7   reranked_results_electra_finetuned_bge-small-e...  0.642857  0.692107   \n",
       "8   reranked_results_electra_finetuned_bge-small-e...  0.524286  0.616512   \n",
       "9   reranked_results_miniLM6_finetuned_bge-small-e...  0.637143  0.688429   \n",
       "10  reranked_results_miniLM6_finetuned_bge-small-e...  0.644286  0.691679   \n",
       "11                   reranked_results_alibaba.parquet  0.675000  0.717571   \n",
       "12  reranked_results_alibaba_finetuned_bge-small-e...  0.679286  0.720357   \n",
       "13  reranked_results_alibaba_finetuned_bge-small-e...  0.700000  0.739810   \n",
       "14  reranked_results_alibaba_finetuned_bge-small-e...  0.712143  0.756560   \n",
       "15  reranked_results_alibaba_finetuned_bge-small-e...  0.724286  0.772524   \n",
       "16  reranked_results_alibaba_finetuned_static-retr...  0.673571  0.716905   \n",
       "17      reranked_results_alibaba_multilingual.parquet  0.641429  0.691750   \n",
       "18  reranked_results_alibaba_multilingual_finetune...  0.635714  0.693952   \n",
       "19  reranked_results_alibaba_multilingual_finetune...  0.630000  0.683357   \n",
       "20                   reranked_results_electra.parquet  0.512143  0.571131   \n",
       "21                  reranked_results_miniLM12.parquet  0.555714  0.610750   \n",
       "22  reranked_results_miniLM12_finetuned_bge-small-...  0.624286  0.671500   \n",
       "23  reranked_results_miniLM12_finetuned_static-ret...  0.660714  0.701810   \n",
       "24                   reranked_results_miniLM6.parquet  0.576429  0.630452   \n",
       "25                     reranked_results_mxbai.parquet  0.687857  0.726619   \n",
       "26                  reranked_results_tinyBERT.parquet  0.560000  0.617786   \n",
       "27  reranked_results_tinyBERT_finetuned_bge-small-...  0.567143  0.622262   \n",
       "28  reranked_results_tinyBERT_finetuned_static-ret...  0.561429  0.627048   \n",
       "29  reranked_results_electra_finetuned_bge-small-e...  0.622857  0.675036   \n",
       "30  reranked_results_electra_finetuned_static-retr...  0.642857  0.695310   \n",
       "31  reranked_results_miniLM6_finetuned_bge-small-e...  0.615000  0.665238   \n",
       "32  reranked_results_miniLM6_finetuned_static-retr...  0.652857  0.698857   \n",
       "\n",
       "      MRR@10  \n",
       "0   0.702113  \n",
       "1   0.700896  \n",
       "2   0.631567  \n",
       "3   0.695531  \n",
       "4   0.718431  \n",
       "5   0.701527  \n",
       "6   0.631527  \n",
       "7   0.695505  \n",
       "8   0.621618  \n",
       "9   0.691478  \n",
       "10  0.694902  \n",
       "11  0.720374  \n",
       "12  0.722709  \n",
       "13  0.740792  \n",
       "14  0.759488  \n",
       "15  0.775613  \n",
       "16  0.719349  \n",
       "17  0.694914  \n",
       "18  0.696824  \n",
       "19  0.687158  \n",
       "20  0.580312  \n",
       "21  0.617365  \n",
       "22  0.676541  \n",
       "23  0.706007  \n",
       "24  0.636363  \n",
       "25  0.728757  \n",
       "26  0.624103  \n",
       "27  0.628581  \n",
       "28  0.633067  \n",
       "29  0.679935  \n",
       "30  0.697880  \n",
       "31  0.670477  \n",
       "32  0.702219  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = Path('data')\n",
    "files = list(path.glob('*.parquet'))\n",
    "\n",
    "results = []\n",
    "for file in files:\n",
    "    print(f\"Processing file: {file.name}\")\n",
    "    df_query = pd.read_parquet(file)\n",
    "    if 'reranked_topk' in df_query.columns:\n",
    "        if 'cord_uid' not in df_query.columns:\n",
    "            print(f\"Column 'cord_uid' not found in {file.name}. Skipping evaluation.\")\n",
    "            continue\n",
    "        performance = evaluate_reranked_results(df_query, col_gold='cord_uid', col_pred='reranked_topk', list_k=[1, 5, 10])\n",
    "        results.append({\n",
    "            'name': file.name,\n",
    "            \"MRR@1\": performance[1],\n",
    "            \"MRR@5\": performance[5],\n",
    "            \"MRR@10\": performance[10]\n",
    "        })\n",
    "    else:\n",
    "        print(f\"Column 'reranked_topk' not found in {file.name}. Skipping evaluation.\")\n",
    "\n",
    "df_eval = pd.DataFrame(results, columns=['name', \"MRR@1\", \"MRR@5\", \"MRR@10\"])\n",
    "df_eval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "fc5fc966",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_eval.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8013f031",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['is_finetuned'] = df['name'].apply(lambda x: 'finetuned' in x)\n",
    "df\n",
    "# remove 'finetuned from name\n",
    "df['name'] = df['name'].apply(lambda x: x.replace('finetuned', '').replace('.parquet', '').replace('reranked_results_', '').strip('_'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ccaca5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_loss_type(filename):\n",
    "    if 'lambdaloss' in filename:\n",
    "        return 'lambda'\n",
    "    elif 'crossentropyloss' in filename:\n",
    "        return 'crossentropy'\n",
    "    else:\n",
    "        return 'unknown'\n",
    "    \n",
    "df['loss_type'] = df['name'].apply(extract_loss_type)\n",
    "\n",
    "# remove 'lambdaloss' and 'crossentropyloss' from name\n",
    "df['name'] = df['name'].apply(lambda x: x.replace('lambdaloss', '').replace('crossentropyloss', '').strip('_'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "caa69a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_embedding_model(filename):\n",
    "    if 'static-retrieval-mrl-en-v1' in filename:\n",
    "        return 'static-retrieval-mrl-en-v1'\n",
    "    elif 'bge-small-en-v1.5' in filename:\n",
    "        return 'bge-small-en-v1.5'\n",
    "    else:\n",
    "        return 'unknown'\n",
    "    \n",
    "df['embedding_model'] = df['name'].apply(extract_embedding_model)\n",
    "\n",
    "\n",
    "# remove 'retrieval-mrl-en-v1' and 'bge-small-en-v1.5' from name\n",
    "df['name'] = df['name'].apply(lambda x: x.replace('static-retrieval-mrl-en-v1', '').replace('bge-small-en-v1.5', '').strip('_'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b9f3637e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_num_epochs_model(filename):\n",
    "    if 'epochs2' in filename:\n",
    "        return 'epochs2'\n",
    "    elif 'epochs1' in filename:\n",
    "        return 'epochs1'\n",
    "    else:\n",
    "        return 'unknown'\n",
    "    \n",
    "df['epochs'] = df['name'].apply(extract_num_epochs_model)\n",
    "\n",
    "\n",
    "# remove 'retrieval-mrl-en-v1' and 'bge-small-en-v1.5' from name\n",
    "df['name'] = df['name'].apply(lambda x: x.replace('epochs2', '').replace('epochs1', '').strip('_'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0f47aa6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['has_stricter_embedding'] = df['name'].apply(lambda x: 'stricter embedding' in x)\n",
    "df\n",
    "# remove 'finetuned from name\n",
    "df['name'] = df['name'].apply(lambda x: x.replace('stricter embedding', '').strip('_'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "58736883",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['learningrate'] = df['name'].apply(lambda x: 'learningrate' in x)\n",
    "df\n",
    "# remove 'finetuned from name\n",
    "df['name'] = df['name'].apply(lambda x: x.replace('learningrate', '').strip('_'))\n",
    "\n",
    "\n",
    "\n",
    "# learning rate has stricter embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5720cefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractk(filename):\n",
    "    if 'k1000' in filename:\n",
    "        return '1000'\n",
    "    elif 'k100' in filename:\n",
    "        return '100'\n",
    "    else:\n",
    "        return '30'\n",
    "    \n",
    "df['k'] = df['name'].apply(extractk)\n",
    "\n",
    "\n",
    "# remove 'retrieval-mrl-en-v1' and 'bge-small-en-v1.5' from name\n",
    "df['name'] = df['name'].apply(lambda x: x.replace('k1000', '').replace('k100', '').strip('_'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e1a6819c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>MRR@1</th>\n",
       "      <th>MRR@5</th>\n",
       "      <th>MRR@10</th>\n",
       "      <th>is_finetuned</th>\n",
       "      <th>loss_type</th>\n",
       "      <th>embedding_model</th>\n",
       "      <th>epochs</th>\n",
       "      <th>has_stricter_embedding</th>\n",
       "      <th>learningrate</th>\n",
       "      <th>k</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>alibaba</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>0.717571</td>\n",
       "      <td>0.720374</td>\n",
       "      <td>False</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>alibaba_multilingual</td>\n",
       "      <td>0.641429</td>\n",
       "      <td>0.691750</td>\n",
       "      <td>0.694914</td>\n",
       "      <td>False</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>electra</td>\n",
       "      <td>0.512143</td>\n",
       "      <td>0.571131</td>\n",
       "      <td>0.580312</td>\n",
       "      <td>False</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>miniLM12</td>\n",
       "      <td>0.555714</td>\n",
       "      <td>0.610750</td>\n",
       "      <td>0.617365</td>\n",
       "      <td>False</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>miniLM6</td>\n",
       "      <td>0.576429</td>\n",
       "      <td>0.630452</td>\n",
       "      <td>0.636363</td>\n",
       "      <td>False</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mxbai</td>\n",
       "      <td>0.687857</td>\n",
       "      <td>0.726619</td>\n",
       "      <td>0.728757</td>\n",
       "      <td>False</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tinyBERT</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.617786</td>\n",
       "      <td>0.624103</td>\n",
       "      <td>False</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   name     MRR@1     MRR@5    MRR@10  is_finetuned loss_type  \\\n",
       "0               alibaba  0.675000  0.717571  0.720374         False   unknown   \n",
       "1  alibaba_multilingual  0.641429  0.691750  0.694914         False   unknown   \n",
       "2               electra  0.512143  0.571131  0.580312         False   unknown   \n",
       "3              miniLM12  0.555714  0.610750  0.617365         False   unknown   \n",
       "4               miniLM6  0.576429  0.630452  0.636363         False   unknown   \n",
       "5                 mxbai  0.687857  0.726619  0.728757         False   unknown   \n",
       "6              tinyBERT  0.560000  0.617786  0.624103         False   unknown   \n",
       "\n",
       "  embedding_model   epochs  has_stricter_embedding  learningrate   k  \n",
       "0         unknown  unknown                   False         False  30  \n",
       "1         unknown  unknown                   False         False  30  \n",
       "2         unknown  unknown                   False         False  30  \n",
       "3         unknown  unknown                   False         False  30  \n",
       "4         unknown  unknown                   False         False  30  \n",
       "5         unknown  unknown                   False         False  30  \n",
       "6         unknown  unknown                   False         False  30  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get only lines where is_finetuned is false\n",
    "df_base = df[df['is_finetuned'] == False].reset_index(drop=True).sort_values(by=['name'])\n",
    "df_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2048323a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>MRR@1</th>\n",
       "      <th>MRR@5</th>\n",
       "      <th>MRR@10</th>\n",
       "      <th>is_finetuned</th>\n",
       "      <th>loss_type</th>\n",
       "      <th>embedding_model</th>\n",
       "      <th>epochs</th>\n",
       "      <th>has_stricter_embedding</th>\n",
       "      <th>learningrate</th>\n",
       "      <th>k</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>alibaba</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>0.717571</td>\n",
       "      <td>0.720374</td>\n",
       "      <td>False</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>alibaba</td>\n",
       "      <td>0.673571</td>\n",
       "      <td>0.716905</td>\n",
       "      <td>0.719349</td>\n",
       "      <td>True</td>\n",
       "      <td>crossentropy</td>\n",
       "      <td>static-retrieval-mrl-en-v1</td>\n",
       "      <td>epochs2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>alibaba_multilingual</td>\n",
       "      <td>0.641429</td>\n",
       "      <td>0.691750</td>\n",
       "      <td>0.694914</td>\n",
       "      <td>False</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>alibaba_multilingual</td>\n",
       "      <td>0.630000</td>\n",
       "      <td>0.683357</td>\n",
       "      <td>0.687158</td>\n",
       "      <td>True</td>\n",
       "      <td>crossentropy</td>\n",
       "      <td>static-retrieval-mrl-en-v1</td>\n",
       "      <td>epochs2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>electra</td>\n",
       "      <td>0.512143</td>\n",
       "      <td>0.571131</td>\n",
       "      <td>0.580312</td>\n",
       "      <td>False</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>electra</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.695310</td>\n",
       "      <td>0.697880</td>\n",
       "      <td>True</td>\n",
       "      <td>crossentropy</td>\n",
       "      <td>static-retrieval-mrl-en-v1</td>\n",
       "      <td>epochs2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>miniLM12</td>\n",
       "      <td>0.555714</td>\n",
       "      <td>0.610750</td>\n",
       "      <td>0.617365</td>\n",
       "      <td>False</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>miniLM12</td>\n",
       "      <td>0.660714</td>\n",
       "      <td>0.701810</td>\n",
       "      <td>0.706007</td>\n",
       "      <td>True</td>\n",
       "      <td>crossentropy</td>\n",
       "      <td>static-retrieval-mrl-en-v1</td>\n",
       "      <td>epochs2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>miniLM6</td>\n",
       "      <td>0.576429</td>\n",
       "      <td>0.630452</td>\n",
       "      <td>0.636363</td>\n",
       "      <td>False</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>miniLM6</td>\n",
       "      <td>0.652857</td>\n",
       "      <td>0.698857</td>\n",
       "      <td>0.702219</td>\n",
       "      <td>True</td>\n",
       "      <td>crossentropy</td>\n",
       "      <td>static-retrieval-mrl-en-v1</td>\n",
       "      <td>epochs2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>mxbai</td>\n",
       "      <td>0.687857</td>\n",
       "      <td>0.726619</td>\n",
       "      <td>0.728757</td>\n",
       "      <td>False</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>tinyBERT</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.617786</td>\n",
       "      <td>0.624103</td>\n",
       "      <td>False</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>tinyBERT</td>\n",
       "      <td>0.561429</td>\n",
       "      <td>0.627048</td>\n",
       "      <td>0.633067</td>\n",
       "      <td>True</td>\n",
       "      <td>crossentropy</td>\n",
       "      <td>static-retrieval-mrl-en-v1</td>\n",
       "      <td>epochs2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    name     MRR@1     MRR@5    MRR@10  is_finetuned  \\\n",
       "0                alibaba  0.675000  0.717571  0.720374         False   \n",
       "1                alibaba  0.673571  0.716905  0.719349          True   \n",
       "2   alibaba_multilingual  0.641429  0.691750  0.694914         False   \n",
       "3   alibaba_multilingual  0.630000  0.683357  0.687158          True   \n",
       "4                electra  0.512143  0.571131  0.580312         False   \n",
       "5                electra  0.642857  0.695310  0.697880          True   \n",
       "6               miniLM12  0.555714  0.610750  0.617365         False   \n",
       "7               miniLM12  0.660714  0.701810  0.706007          True   \n",
       "8                miniLM6  0.576429  0.630452  0.636363         False   \n",
       "9                miniLM6  0.652857  0.698857  0.702219          True   \n",
       "10                 mxbai  0.687857  0.726619  0.728757         False   \n",
       "11              tinyBERT  0.560000  0.617786  0.624103         False   \n",
       "12              tinyBERT  0.561429  0.627048  0.633067          True   \n",
       "\n",
       "       loss_type             embedding_model   epochs  has_stricter_embedding  \\\n",
       "0        unknown                     unknown  unknown                   False   \n",
       "1   crossentropy  static-retrieval-mrl-en-v1  epochs2                   False   \n",
       "2        unknown                     unknown  unknown                   False   \n",
       "3   crossentropy  static-retrieval-mrl-en-v1  epochs2                   False   \n",
       "4        unknown                     unknown  unknown                   False   \n",
       "5   crossentropy  static-retrieval-mrl-en-v1  epochs2                   False   \n",
       "6        unknown                     unknown  unknown                   False   \n",
       "7   crossentropy  static-retrieval-mrl-en-v1  epochs2                   False   \n",
       "8        unknown                     unknown  unknown                   False   \n",
       "9   crossentropy  static-retrieval-mrl-en-v1  epochs2                   False   \n",
       "10       unknown                     unknown  unknown                   False   \n",
       "11       unknown                     unknown  unknown                   False   \n",
       "12  crossentropy  static-retrieval-mrl-en-v1  epochs2                   False   \n",
       "\n",
       "    learningrate   k  \n",
       "0          False  30  \n",
       "1          False  30  \n",
       "2          False  30  \n",
       "3          False  30  \n",
       "4          False  30  \n",
       "5          False  30  \n",
       "6          False  30  \n",
       "7          False  30  \n",
       "8          False  30  \n",
       "9          False  30  \n",
       "10         False  30  \n",
       "11         False  30  \n",
       "12         False  30  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get only lines where has_stricter_embedding is False, embedding_model is unknown or static-retrieval-mrl-en-v1\n",
    "df_finetuning = df[(~df['has_stricter_embedding']) & (df['embedding_model'].isin(['unknown', 'static-retrieval-mrl-en-v1']))].sort_values(by=['name', 'is_finetuned']).reset_index(drop=True)\n",
    "df_finetuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "bbad9180",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>MRR@1</th>\n",
       "      <th>MRR@5</th>\n",
       "      <th>MRR@10</th>\n",
       "      <th>is_finetuned</th>\n",
       "      <th>loss_type</th>\n",
       "      <th>embedding_model</th>\n",
       "      <th>epochs</th>\n",
       "      <th>has_stricter_embedding</th>\n",
       "      <th>learningrate</th>\n",
       "      <th>k</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>alibaba</td>\n",
       "      <td>0.651429</td>\n",
       "      <td>0.698833</td>\n",
       "      <td>0.702113</td>\n",
       "      <td>True</td>\n",
       "      <td>crossentropy</td>\n",
       "      <td>bge-small-en-v1.5</td>\n",
       "      <td>epochs2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>alibaba</td>\n",
       "      <td>0.673571</td>\n",
       "      <td>0.716905</td>\n",
       "      <td>0.719349</td>\n",
       "      <td>True</td>\n",
       "      <td>crossentropy</td>\n",
       "      <td>static-retrieval-mrl-en-v1</td>\n",
       "      <td>epochs2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>alibaba_multilingual</td>\n",
       "      <td>0.646429</td>\n",
       "      <td>0.691655</td>\n",
       "      <td>0.695531</td>\n",
       "      <td>True</td>\n",
       "      <td>crossentropy</td>\n",
       "      <td>bge-small-en-v1.5</td>\n",
       "      <td>epochs1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>alibaba_multilingual</td>\n",
       "      <td>0.630000</td>\n",
       "      <td>0.683357</td>\n",
       "      <td>0.687158</td>\n",
       "      <td>True</td>\n",
       "      <td>crossentropy</td>\n",
       "      <td>static-retrieval-mrl-en-v1</td>\n",
       "      <td>epochs2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>electra</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.692107</td>\n",
       "      <td>0.695505</td>\n",
       "      <td>True</td>\n",
       "      <td>crossentropy</td>\n",
       "      <td>bge-small-en-v1.5</td>\n",
       "      <td>epochs2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>electra</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.695310</td>\n",
       "      <td>0.697880</td>\n",
       "      <td>True</td>\n",
       "      <td>crossentropy</td>\n",
       "      <td>static-retrieval-mrl-en-v1</td>\n",
       "      <td>epochs2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>miniLM12</td>\n",
       "      <td>0.651429</td>\n",
       "      <td>0.697357</td>\n",
       "      <td>0.700896</td>\n",
       "      <td>True</td>\n",
       "      <td>crossentropy</td>\n",
       "      <td>bge-small-en-v1.5</td>\n",
       "      <td>epochs2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>miniLM12</td>\n",
       "      <td>0.660714</td>\n",
       "      <td>0.701810</td>\n",
       "      <td>0.706007</td>\n",
       "      <td>True</td>\n",
       "      <td>crossentropy</td>\n",
       "      <td>static-retrieval-mrl-en-v1</td>\n",
       "      <td>epochs2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>miniLM6</td>\n",
       "      <td>0.637143</td>\n",
       "      <td>0.688429</td>\n",
       "      <td>0.691478</td>\n",
       "      <td>True</td>\n",
       "      <td>crossentropy</td>\n",
       "      <td>bge-small-en-v1.5</td>\n",
       "      <td>epochs2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>miniLM6</td>\n",
       "      <td>0.652857</td>\n",
       "      <td>0.698857</td>\n",
       "      <td>0.702219</td>\n",
       "      <td>True</td>\n",
       "      <td>crossentropy</td>\n",
       "      <td>static-retrieval-mrl-en-v1</td>\n",
       "      <td>epochs2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>tinyBERT</td>\n",
       "      <td>0.562857</td>\n",
       "      <td>0.625786</td>\n",
       "      <td>0.631567</td>\n",
       "      <td>True</td>\n",
       "      <td>crossentropy</td>\n",
       "      <td>bge-small-en-v1.5</td>\n",
       "      <td>epochs2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>tinyBERT</td>\n",
       "      <td>0.561429</td>\n",
       "      <td>0.627048</td>\n",
       "      <td>0.633067</td>\n",
       "      <td>True</td>\n",
       "      <td>crossentropy</td>\n",
       "      <td>static-retrieval-mrl-en-v1</td>\n",
       "      <td>epochs2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    name     MRR@1     MRR@5    MRR@10  is_finetuned  \\\n",
       "0                alibaba  0.651429  0.698833  0.702113          True   \n",
       "1                alibaba  0.673571  0.716905  0.719349          True   \n",
       "2   alibaba_multilingual  0.646429  0.691655  0.695531          True   \n",
       "3   alibaba_multilingual  0.630000  0.683357  0.687158          True   \n",
       "4                electra  0.642857  0.692107  0.695505          True   \n",
       "5                electra  0.642857  0.695310  0.697880          True   \n",
       "6               miniLM12  0.651429  0.697357  0.700896          True   \n",
       "7               miniLM12  0.660714  0.701810  0.706007          True   \n",
       "8                miniLM6  0.637143  0.688429  0.691478          True   \n",
       "9                miniLM6  0.652857  0.698857  0.702219          True   \n",
       "10              tinyBERT  0.562857  0.625786  0.631567          True   \n",
       "11              tinyBERT  0.561429  0.627048  0.633067          True   \n",
       "\n",
       "       loss_type             embedding_model   epochs  has_stricter_embedding  \\\n",
       "0   crossentropy           bge-small-en-v1.5  epochs2                   False   \n",
       "1   crossentropy  static-retrieval-mrl-en-v1  epochs2                   False   \n",
       "2   crossentropy           bge-small-en-v1.5  epochs1                   False   \n",
       "3   crossentropy  static-retrieval-mrl-en-v1  epochs2                   False   \n",
       "4   crossentropy           bge-small-en-v1.5  epochs2                   False   \n",
       "5   crossentropy  static-retrieval-mrl-en-v1  epochs2                   False   \n",
       "6   crossentropy           bge-small-en-v1.5  epochs2                   False   \n",
       "7   crossentropy  static-retrieval-mrl-en-v1  epochs2                   False   \n",
       "8   crossentropy           bge-small-en-v1.5  epochs2                   False   \n",
       "9   crossentropy  static-retrieval-mrl-en-v1  epochs2                   False   \n",
       "10  crossentropy           bge-small-en-v1.5  epochs2                   False   \n",
       "11  crossentropy  static-retrieval-mrl-en-v1  epochs2                   False   \n",
       "\n",
       "    learningrate   k  \n",
       "0          False  30  \n",
       "1          False  30  \n",
       "2          False  30  \n",
       "3          False  30  \n",
       "4          False  30  \n",
       "5          False  30  \n",
       "6          False  30  \n",
       "7          False  30  \n",
       "8          False  30  \n",
       "9          False  30  \n",
       "10         False  30  \n",
       "11         False  30  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_embedding = df[(df['is_finetuned'] == True) & (df['loss_type'] == \"crossentropy\") & (~df[\"has_stricter_embedding\"])].sort_values(by=['name']).reset_index(drop=True)\n",
    "df_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a2dcdfdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>MRR@1</th>\n",
       "      <th>MRR@5</th>\n",
       "      <th>MRR@10</th>\n",
       "      <th>is_finetuned</th>\n",
       "      <th>loss_type</th>\n",
       "      <th>embedding_model</th>\n",
       "      <th>epochs</th>\n",
       "      <th>has_stricter_embedding</th>\n",
       "      <th>learningrate</th>\n",
       "      <th>k</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>alibaba</td>\n",
       "      <td>0.651429</td>\n",
       "      <td>0.698833</td>\n",
       "      <td>0.702113</td>\n",
       "      <td>True</td>\n",
       "      <td>crossentropy</td>\n",
       "      <td>bge-small-en-v1.5</td>\n",
       "      <td>epochs2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>alibaba</td>\n",
       "      <td>0.679286</td>\n",
       "      <td>0.720357</td>\n",
       "      <td>0.722709</td>\n",
       "      <td>True</td>\n",
       "      <td>lambda</td>\n",
       "      <td>bge-small-en-v1.5</td>\n",
       "      <td>epochs2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>alibaba_multilingual</td>\n",
       "      <td>0.646429</td>\n",
       "      <td>0.691655</td>\n",
       "      <td>0.695531</td>\n",
       "      <td>True</td>\n",
       "      <td>crossentropy</td>\n",
       "      <td>bge-small-en-v1.5</td>\n",
       "      <td>epochs1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>alibaba_multilingual</td>\n",
       "      <td>0.635714</td>\n",
       "      <td>0.693952</td>\n",
       "      <td>0.696824</td>\n",
       "      <td>True</td>\n",
       "      <td>lambda</td>\n",
       "      <td>bge-small-en-v1.5</td>\n",
       "      <td>epochs2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>electra</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.692107</td>\n",
       "      <td>0.695505</td>\n",
       "      <td>True</td>\n",
       "      <td>crossentropy</td>\n",
       "      <td>bge-small-en-v1.5</td>\n",
       "      <td>epochs2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>electra</td>\n",
       "      <td>0.622857</td>\n",
       "      <td>0.675036</td>\n",
       "      <td>0.679935</td>\n",
       "      <td>True</td>\n",
       "      <td>lambda</td>\n",
       "      <td>bge-small-en-v1.5</td>\n",
       "      <td>epochs2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>miniLM12</td>\n",
       "      <td>0.651429</td>\n",
       "      <td>0.697357</td>\n",
       "      <td>0.700896</td>\n",
       "      <td>True</td>\n",
       "      <td>crossentropy</td>\n",
       "      <td>bge-small-en-v1.5</td>\n",
       "      <td>epochs2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>miniLM12</td>\n",
       "      <td>0.624286</td>\n",
       "      <td>0.671500</td>\n",
       "      <td>0.676541</td>\n",
       "      <td>True</td>\n",
       "      <td>lambda</td>\n",
       "      <td>bge-small-en-v1.5</td>\n",
       "      <td>epochs2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>miniLM6</td>\n",
       "      <td>0.637143</td>\n",
       "      <td>0.688429</td>\n",
       "      <td>0.691478</td>\n",
       "      <td>True</td>\n",
       "      <td>crossentropy</td>\n",
       "      <td>bge-small-en-v1.5</td>\n",
       "      <td>epochs2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>miniLM6</td>\n",
       "      <td>0.615000</td>\n",
       "      <td>0.665238</td>\n",
       "      <td>0.670477</td>\n",
       "      <td>True</td>\n",
       "      <td>lambda</td>\n",
       "      <td>bge-small-en-v1.5</td>\n",
       "      <td>epochs2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>tinyBERT</td>\n",
       "      <td>0.562857</td>\n",
       "      <td>0.625786</td>\n",
       "      <td>0.631567</td>\n",
       "      <td>True</td>\n",
       "      <td>crossentropy</td>\n",
       "      <td>bge-small-en-v1.5</td>\n",
       "      <td>epochs2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>tinyBERT</td>\n",
       "      <td>0.567143</td>\n",
       "      <td>0.622262</td>\n",
       "      <td>0.628581</td>\n",
       "      <td>True</td>\n",
       "      <td>lambda</td>\n",
       "      <td>bge-small-en-v1.5</td>\n",
       "      <td>epochs2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    name     MRR@1     MRR@5    MRR@10  is_finetuned  \\\n",
       "0                alibaba  0.651429  0.698833  0.702113          True   \n",
       "1                alibaba  0.679286  0.720357  0.722709          True   \n",
       "2   alibaba_multilingual  0.646429  0.691655  0.695531          True   \n",
       "3   alibaba_multilingual  0.635714  0.693952  0.696824          True   \n",
       "4                electra  0.642857  0.692107  0.695505          True   \n",
       "5                electra  0.622857  0.675036  0.679935          True   \n",
       "6               miniLM12  0.651429  0.697357  0.700896          True   \n",
       "7               miniLM12  0.624286  0.671500  0.676541          True   \n",
       "8                miniLM6  0.637143  0.688429  0.691478          True   \n",
       "9                miniLM6  0.615000  0.665238  0.670477          True   \n",
       "10              tinyBERT  0.562857  0.625786  0.631567          True   \n",
       "11              tinyBERT  0.567143  0.622262  0.628581          True   \n",
       "\n",
       "       loss_type    embedding_model   epochs  has_stricter_embedding  \\\n",
       "0   crossentropy  bge-small-en-v1.5  epochs2                   False   \n",
       "1         lambda  bge-small-en-v1.5  epochs2                   False   \n",
       "2   crossentropy  bge-small-en-v1.5  epochs1                   False   \n",
       "3         lambda  bge-small-en-v1.5  epochs2                   False   \n",
       "4   crossentropy  bge-small-en-v1.5  epochs2                   False   \n",
       "5         lambda  bge-small-en-v1.5  epochs2                   False   \n",
       "6   crossentropy  bge-small-en-v1.5  epochs2                   False   \n",
       "7         lambda  bge-small-en-v1.5  epochs2                   False   \n",
       "8   crossentropy  bge-small-en-v1.5  epochs2                   False   \n",
       "9         lambda  bge-small-en-v1.5  epochs2                   False   \n",
       "10  crossentropy  bge-small-en-v1.5  epochs2                   False   \n",
       "11        lambda  bge-small-en-v1.5  epochs2                   False   \n",
       "\n",
       "    learningrate   k  \n",
       "0          False  30  \n",
       "1          False  30  \n",
       "2          False  30  \n",
       "3          False  30  \n",
       "4          False  30  \n",
       "5          False  30  \n",
       "6          False  30  \n",
       "7          False  30  \n",
       "8          False  30  \n",
       "9          False  30  \n",
       "10         False  30  \n",
       "11         False  30  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_loss = df[(df['is_finetuned'] == True) & (~df[\"has_stricter_embedding\"]) & (df['embedding_model'] == 'bge-small-en-v1.5') & (~df[\"learningrate\"])].sort_values(by=['name']).reset_index(drop=True)\n",
    "df_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "649b5bd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>MRR@1</th>\n",
       "      <th>MRR@5</th>\n",
       "      <th>MRR@10</th>\n",
       "      <th>is_finetuned</th>\n",
       "      <th>loss_type</th>\n",
       "      <th>embedding_model</th>\n",
       "      <th>epochs</th>\n",
       "      <th>has_stricter_embedding</th>\n",
       "      <th>learningrate</th>\n",
       "      <th>k</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>alibaba</td>\n",
       "      <td>0.651429</td>\n",
       "      <td>0.698833</td>\n",
       "      <td>0.702113</td>\n",
       "      <td>True</td>\n",
       "      <td>crossentropy</td>\n",
       "      <td>bge-small-en-v1.5</td>\n",
       "      <td>epochs2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>alibaba</td>\n",
       "      <td>0.671429</td>\n",
       "      <td>0.715643</td>\n",
       "      <td>0.718431</td>\n",
       "      <td>True</td>\n",
       "      <td>crossentropy</td>\n",
       "      <td>bge-small-en-v1.5</td>\n",
       "      <td>epochs2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>electra</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.692107</td>\n",
       "      <td>0.695505</td>\n",
       "      <td>True</td>\n",
       "      <td>crossentropy</td>\n",
       "      <td>bge-small-en-v1.5</td>\n",
       "      <td>epochs2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>electra</td>\n",
       "      <td>0.524286</td>\n",
       "      <td>0.616512</td>\n",
       "      <td>0.621618</td>\n",
       "      <td>True</td>\n",
       "      <td>crossentropy</td>\n",
       "      <td>bge-small-en-v1.5</td>\n",
       "      <td>epochs2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>miniLM12</td>\n",
       "      <td>0.651429</td>\n",
       "      <td>0.697357</td>\n",
       "      <td>0.700896</td>\n",
       "      <td>True</td>\n",
       "      <td>crossentropy</td>\n",
       "      <td>bge-small-en-v1.5</td>\n",
       "      <td>epochs2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>miniLM12</td>\n",
       "      <td>0.654286</td>\n",
       "      <td>0.698536</td>\n",
       "      <td>0.701527</td>\n",
       "      <td>True</td>\n",
       "      <td>crossentropy</td>\n",
       "      <td>bge-small-en-v1.5</td>\n",
       "      <td>epochs2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>miniLM6</td>\n",
       "      <td>0.637143</td>\n",
       "      <td>0.688429</td>\n",
       "      <td>0.691478</td>\n",
       "      <td>True</td>\n",
       "      <td>crossentropy</td>\n",
       "      <td>bge-small-en-v1.5</td>\n",
       "      <td>epochs2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>miniLM6</td>\n",
       "      <td>0.644286</td>\n",
       "      <td>0.691679</td>\n",
       "      <td>0.694902</td>\n",
       "      <td>True</td>\n",
       "      <td>crossentropy</td>\n",
       "      <td>bge-small-en-v1.5</td>\n",
       "      <td>epochs2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>tinyBERT</td>\n",
       "      <td>0.562857</td>\n",
       "      <td>0.625786</td>\n",
       "      <td>0.631567</td>\n",
       "      <td>True</td>\n",
       "      <td>crossentropy</td>\n",
       "      <td>bge-small-en-v1.5</td>\n",
       "      <td>epochs2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>tinyBERT</td>\n",
       "      <td>0.563571</td>\n",
       "      <td>0.624845</td>\n",
       "      <td>0.631527</td>\n",
       "      <td>True</td>\n",
       "      <td>crossentropy</td>\n",
       "      <td>bge-small-en-v1.5</td>\n",
       "      <td>epochs2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       name     MRR@1     MRR@5    MRR@10  is_finetuned     loss_type  \\\n",
       "0   alibaba  0.651429  0.698833  0.702113          True  crossentropy   \n",
       "1   alibaba  0.671429  0.715643  0.718431          True  crossentropy   \n",
       "2   electra  0.642857  0.692107  0.695505          True  crossentropy   \n",
       "3   electra  0.524286  0.616512  0.621618          True  crossentropy   \n",
       "4  miniLM12  0.651429  0.697357  0.700896          True  crossentropy   \n",
       "5  miniLM12  0.654286  0.698536  0.701527          True  crossentropy   \n",
       "6   miniLM6  0.637143  0.688429  0.691478          True  crossentropy   \n",
       "7   miniLM6  0.644286  0.691679  0.694902          True  crossentropy   \n",
       "8  tinyBERT  0.562857  0.625786  0.631567          True  crossentropy   \n",
       "9  tinyBERT  0.563571  0.624845  0.631527          True  crossentropy   \n",
       "\n",
       "     embedding_model   epochs  has_stricter_embedding  learningrate   k  \n",
       "0  bge-small-en-v1.5  epochs2                   False         False  30  \n",
       "1  bge-small-en-v1.5  epochs2                    True         False  30  \n",
       "2  bge-small-en-v1.5  epochs2                   False         False  30  \n",
       "3  bge-small-en-v1.5  epochs2                    True         False  30  \n",
       "4  bge-small-en-v1.5  epochs2                   False         False  30  \n",
       "5  bge-small-en-v1.5  epochs2                    True         False  30  \n",
       "6  bge-small-en-v1.5  epochs2                   False         False  30  \n",
       "7  bge-small-en-v1.5  epochs2                    True         False  30  \n",
       "8  bge-small-en-v1.5  epochs2                   False         False  30  \n",
       "9  bge-small-en-v1.5  epochs2                    True         False  30  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_strict_embeddings = df[(df['is_finetuned'] == True) & (df['loss_type'] == 'crossentropy') & (~df['learningrate']) & (df['embedding_model'] == 'bge-small-en-v1.5') & (df['name'] != 'alibaba_multilingual')].sort_values(by=['name']).reset_index(drop=True)\n",
    "df_strict_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "39bbe645",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>MRR@1</th>\n",
       "      <th>MRR@5</th>\n",
       "      <th>MRR@10</th>\n",
       "      <th>is_finetuned</th>\n",
       "      <th>loss_type</th>\n",
       "      <th>embedding_model</th>\n",
       "      <th>epochs</th>\n",
       "      <th>has_stricter_embedding</th>\n",
       "      <th>learningrate</th>\n",
       "      <th>k</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>alibaba</td>\n",
       "      <td>0.679286</td>\n",
       "      <td>0.720357</td>\n",
       "      <td>0.722709</td>\n",
       "      <td>True</td>\n",
       "      <td>lambda</td>\n",
       "      <td>bge-small-en-v1.5</td>\n",
       "      <td>epochs2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>alibaba</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.739810</td>\n",
       "      <td>0.740792</td>\n",
       "      <td>True</td>\n",
       "      <td>lambda</td>\n",
       "      <td>bge-small-en-v1.5</td>\n",
       "      <td>epochs2</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      name     MRR@1     MRR@5    MRR@10  is_finetuned loss_type  \\\n",
       "0  alibaba  0.679286  0.720357  0.722709          True    lambda   \n",
       "1  alibaba  0.700000  0.739810  0.740792          True    lambda   \n",
       "\n",
       "     embedding_model   epochs  has_stricter_embedding  learningrate   k  \n",
       "0  bge-small-en-v1.5  epochs2                   False         False  30  \n",
       "1  bge-small-en-v1.5  epochs2                   False          True  30  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_learning_rate = df[(df['is_finetuned'] == True) & (df['loss_type'] == 'lambda')  & (df['embedding_model'] == 'bge-small-en-v1.5') & (df['name'] == 'alibaba') & (df['k'] == '30')].sort_values(by=['name']).reset_index(drop=True)\n",
    "df_learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f5b4aaa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>MRR@1</th>\n",
       "      <th>MRR@5</th>\n",
       "      <th>MRR@10</th>\n",
       "      <th>is_finetuned</th>\n",
       "      <th>loss_type</th>\n",
       "      <th>embedding_model</th>\n",
       "      <th>epochs</th>\n",
       "      <th>has_stricter_embedding</th>\n",
       "      <th>learningrate</th>\n",
       "      <th>k</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>alibaba</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.739810</td>\n",
       "      <td>0.740792</td>\n",
       "      <td>True</td>\n",
       "      <td>lambda</td>\n",
       "      <td>bge-small-en-v1.5</td>\n",
       "      <td>epochs2</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>alibaba</td>\n",
       "      <td>0.712143</td>\n",
       "      <td>0.756560</td>\n",
       "      <td>0.759488</td>\n",
       "      <td>True</td>\n",
       "      <td>lambda</td>\n",
       "      <td>bge-small-en-v1.5</td>\n",
       "      <td>epochs2</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>alibaba</td>\n",
       "      <td>0.724286</td>\n",
       "      <td>0.772524</td>\n",
       "      <td>0.775613</td>\n",
       "      <td>True</td>\n",
       "      <td>lambda</td>\n",
       "      <td>bge-small-en-v1.5</td>\n",
       "      <td>epochs2</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      name     MRR@1     MRR@5    MRR@10  is_finetuned loss_type  \\\n",
       "0  alibaba  0.700000  0.739810  0.740792          True    lambda   \n",
       "1  alibaba  0.712143  0.756560  0.759488          True    lambda   \n",
       "2  alibaba  0.724286  0.772524  0.775613          True    lambda   \n",
       "\n",
       "     embedding_model   epochs  has_stricter_embedding  learningrate     k  \n",
       "0  bge-small-en-v1.5  epochs2                   False          True    30  \n",
       "1  bge-small-en-v1.5  epochs2                   False          True   100  \n",
       "2  bge-small-en-v1.5  epochs2                   False          True  1000  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_k = df[(df['is_finetuned'] == True) & (df['loss_type'] == 'lambda')  & (df['embedding_model'] == 'bge-small-en-v1.5') & (df['name'] == 'alibaba') & (df['learningrate'])].sort_values(by=['name']).reset_index(drop=True)\n",
    "df_k"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
